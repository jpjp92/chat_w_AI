import urllib.request
import urllib.parse
import json
import re
import logging
from datetime import datetime
import uuid
import streamlit as st

logger = logging.getLogger(__name__)

class WebSearchAPI:
    def __init__(self, client_id, client_secret, cache_handler, cache_ttl=3600, daily_limit=25000):
        self.client_id = client_id
        self.client_secret = client_secret
        self.cache = cache_handler
        self.cache_ttl = cache_ttl
        self.daily_limit = daily_limit
        self.request_count = 0
        self.base_url = "https://openapi.naver.com/v1/search/webkr"
    
    def get_request_count(self):
        """í˜„ì¬ ìš”ì²­ íšŸìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.request_count
    
    def increment_request_count(self):
        """ìš”ì²­ íšŸìˆ˜ë¥¼ ì¦ê°€ì‹œí‚µë‹ˆë‹¤."""
        self.request_count += 1
    
    def is_over_limit(self):
        """ì¼ì¼ í•œë„ ì´ˆê³¼ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
        return self.request_count >= self.daily_limit
    
    def search_web(self, query, display=5, sort="date"):
        """Naver APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        cache_key = f"naver:{query}:{display}:{sort}"
        cached = self.cache.get(cache_key)
        if cached:
            return cached
        
        if self.is_over_limit():
            return "ê²€ìƒ‰ í•œë„ ì´ˆê³¼ë¡œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ˜“"
        
        try:
            enc_text = urllib.parse.quote(query)
            url = f"{self.base_url}?query={enc_text}&display={display}&sort={sort}"
            
            request = urllib.request.Request(url)
            request.add_header("X-Naver-Client-Id", self.client_id)
            request.add_header("X-Naver-Client-Secret", self.client_secret)
            
            response = urllib.request.urlopen(request, timeout=3)
            self.increment_request_count()
            
            if response.getcode() == 200:
                data = json.loads(response.read().decode('utf-8'))
                results = data.get('items', [])
                
                if not results:
                    return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ğŸ˜“"
                
                formatted_result = self.format_search_results(results)
                self.cache.setex(cache_key, self.cache_ttl, formatted_result)
                return formatted_result
            else:
                return f"ê²€ìƒ‰ API ì˜¤ë¥˜ (ì½”ë“œ: {response.getcode()}) ğŸ˜“"
                
        except Exception as e:
            logger.error(f"Naver API ì˜¤ë¥˜: {str(e)}")
            return "ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ğŸ˜“"
    
    def format_search_results(self, results):
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
        response_text = "ğŸŒ **ì›¹ ê²€ìƒ‰ ê²°ê³¼** \n\n"
        
        formatted_results = []
        for i, item in enumerate(results, 1):
            # HTML íƒœê·¸ ì œê±°
            clean_title = re.sub(r'<b>|</b>', '', item.get('title', 'ì œëª© ì—†ìŒ'))
            clean_description = re.sub(r'<b>|</b>', '', item.get('description', 'ë‚´ìš© ì—†ìŒ'))
            
            # ì„¤ëª… ê¸¸ì´ ì œí•œ
            description_preview = clean_description[:100] + "..." if len(clean_description) > 100 else clean_description
            
            formatted_result = (
                f"**ê²°ê³¼ {i}**\n\n"
                f"ğŸ“„ **ì œëª©**: {clean_title}\n\n"
                f"ğŸ“ **ë‚´ìš©**: {description_preview}\n\n"
                f"ğŸ”— **ë§í¬**: {item.get('link', '')}"
            )
            formatted_results.append(formatted_result)
        
        response_text += "\n\n".join(formatted_results)
        response_text += "\n\në” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”? ğŸ˜Š"
        
        return response_text
    
    def search_and_create_context(self, query, session_state=None):
        """ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        # ì¿¼ë¦¬ì—ì„œ 'ê²€ìƒ‰' í‚¤ì›Œë“œ ì œê±°
        clean_query = query.lower().replace("ê²€ìƒ‰", "").strip()
        
        # ê²€ìƒ‰ ìˆ˜í–‰
        search_result = self.search_web(clean_query)
        
        # ì„¸ì…˜ ìƒíƒœê°€ ìˆëŠ” ê²½ìš° ì»¨í…ìŠ¤íŠ¸ ì €ì¥
        if session_state and hasattr(session_state, 'search_contexts'):
            context_id = str(uuid.uuid4())
            session_state.search_contexts[context_id] = {
                "type": "naver_search",
                "query": clean_query,
                "result": search_result,
                "timestamp": datetime.now().isoformat()
            }
            session_state.current_context = context_id
            
            # ë¡œê·¸ ì¶”ê°€
            logger.info(f"ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {context_id}")
            logger.info(f"ì €ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ìˆ˜: {len(session_state.search_contexts)}")
        else:
            logger.warning("ì„¸ì…˜ ìƒíƒœê°€ ì—†ê±°ë‚˜ search_contextsê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë©€í‹°í„´ ëŒ€í™”ë¥¼ ìœ„í•œ ì•ˆë‚´ ì¶”ê°€
        enhanced_result = search_result + "\n\nğŸ’¡ ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•´ ë” ì§ˆë¬¸í•˜ì‹œë©´ ë‹µë³€í•´ë“œë¦´ê²Œìš”. ì˜ˆë¥¼ ë“¤ì–´:\n"
        enhanced_result += "- 'ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš”ì•½í•´'\n"
        enhanced_result += "- 'ì²« ë²ˆì§¸ ê²°ê³¼ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì¤˜'\n"
        enhanced_result += "- '3ë²ˆì§¸ ë§í¬ ìš”ì•½í•´ì¤˜' (í•´ë‹¹ ìˆœì„œ ì›¹í˜ì´ì§€ ì „ì²´ ë‚´ìš© ìš”ì•½)\n"
        enhanced_result += "- 'URL ìš”ì•½í•´ì¤˜' (íŠ¹ì • ë§í¬ì˜ ì „ì²´ ë‚´ìš© í™•ì¸)"
        
        return enhanced_result
    
    def get_search_stats(self):
        """ê²€ìƒ‰ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            "request_count": self.request_count,
            "daily_limit": self.daily_limit,
            "remaining": self.daily_limit - self.request_count,
            "usage_percentage": round((self.request_count / self.daily_limit) * 100, 2)
        }
    
    def reset_daily_count(self):
        """ì¼ì¼ ì¹´ìš´íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.request_count = 0
        logger.info("Naver API ì¼ì¼ ìš”ì²­ ì¹´ìš´íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")