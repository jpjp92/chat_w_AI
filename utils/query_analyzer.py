# # utils/query_analyzer.py
# import re
# from functools import lru_cache
# import logging

# logger = logging.getLogger(__name__)

# # ë„ì‹œ ë° ì‹œê°„ ì¶”ì¶œ
# CITY_PATTERNS = [
#     re.compile(r'(?:ì˜¤ëŠ˜|ë‚´ì¼|ëª¨ë ˆ|ì´ë²ˆ ì£¼|ì£¼ê°„)?\s*([ê°€-í£a-zA-Z\s]{2,20}(?:ì‹œ|êµ°|city)?)ì˜?\s*ë‚ ì”¨', re.IGNORECASE),
#     re.compile(r'(?:ì˜¤ëŠ˜|ë‚´ì¼|ëª¨ë ˆ|ì´ë²ˆ ì£¼|ì£¼ê°„)?\s*([ê°€-í£a-zA-Z\s]{2,20}(?:ì‹œ|êµ°|city)?)\s*ë‚ ì”¨', re.IGNORECASE),
# ]

# TIME_CITY_PATTERNS = [
#     re.compile(r'([ê°€-í£a-zA-Z]{2,20}(?:ì‹œ|êµ°)?)ì˜?\s*ì‹œê°„'),
#     re.compile(r'([ê°€-í£a-zA-Z]{2,20}(?:ì‹œ|êµ°)?)\s*ì‹œê°„'),
# ]

# GREETINGS = ["ì•ˆë…•", "í•˜ì´", "í—¬ë¡œ", "ã…ã…‡", "ì™“ì—…", "í• ë¡±", "í—¤ì´"]

# def extract_city_from_query(query):
#     for pattern in CITY_PATTERNS:
#         match = pattern.search(query)
#         if match:
#             city = match.group(1).strip()
#             if city not in ["ì˜¤ëŠ˜", "ë‚´ì¼", "ëª¨ë ˆ", "ì´ë²ˆ ì£¼", "ì£¼ê°„", "í˜„ì¬"]:
#                 return city
#     return "ì„œìš¸"

# def extract_city_from_time_query(query):
#     for pattern in TIME_CITY_PATTERNS:
#         match = pattern.search(query)
#         if match:
#             city = match.group(1).strip()
#             if city != "í˜„ì¬":
#                 return city
#     return "ì„œìš¸"

# # ì¶•êµ¬ë¦¬ê·¸ 
# LEAGUE_MAPPING = {
#     "epl": {"name": "í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ (ì˜êµ­)", "code": "PL"},
#     "laliga": {"name": "ë¼ë¦¬ê°€ (ìŠ¤í˜ì¸)", "code": "PD"},
#     "bundesliga": {"name": "ë¶„ë°ìŠ¤ë¦¬ê°€ (ë…ì¼)", "code": "BL1"},
#     "seriea": {"name": "ì„¸ë¦¬ì— A (ì´íƒˆë¦¬ì•„)", "code": "SA"},
#     "ligue1": {"name": "ë¦¬ê·¸ 1 (í”„ë‘ìŠ¤)", "code": "FL1"},
#     "championsleague": {"name": "ì±”í”¼ì–¸ìŠ¤ ë¦¬ê·¸", "code": "CL"}
# }

# def extract_league_from_query(query):
#     query_lower = query.lower().replace(" ", "")
#     league_keywords = {
#         "epl": ["epl", "í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸"],
#         "laliga": ["laliga", "ë¼ë¦¬ê°€"],
#         "bundesliga": ["bundesliga", "ë¶„ë°ìŠ¤ë¦¬ê°€"],
#         "seriea": ["seriea", "ì„¸ë¦¬ì—a"],
#         "ligue1": ["ligue1", "ë¦¬ê·¸1"],
#         "championsleague": ["championsleague", "ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸", "ucl"]
#     }
#     for league_key, keywords in league_keywords.items():
#         if any(keyword in query_lower for keyword in keywords):
#             return league_key
#     return None

# def is_time_query(query):
#     """ì‹œê°„ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ ì •í™•í•˜ê²Œ íŒë‹¨"""
    
#     # ê¸ì •ì  ì‹œê°„ íŒ¨í„´ë“¤
#     positive_patterns = [
#         r'(ì„œìš¸|ë„ì¿„|ë‰´ìš•|ëŸ°ë˜|íŒŒë¦¬|ë² ë¥¼ë¦°|ë§ˆë“œë¦¬ë“œ|ë¡œë§ˆ|ë°€ë¼ë…¸|ì‹œë“œë‹ˆ|í™ì½©|ì‹±ê°€í¬ë¥´|ëª¨ìŠ¤í¬ë°”|ë‘ë°”ì´|ë¼ìŠ¤ë² ì´ê±°ìŠ¤|ì‹œì¹´ê³ |í† ë¡ í† |ë©œë²„ë¥¸)\s*(ì‹œê°„|time)',
#         r'(í˜„ì¬|ì§€ê¸ˆ)\s*(ì‹œê°„|time)',
#         r'ëª‡\s*ì‹œ',
#         r'(ì˜¤ëŠ˜|í˜„ì¬|ì§€ê¸ˆ|ê¸ˆì¼)\s*(ë‚ ì§œ|date)',
#         r'what\s*time',
#         r'ì‹œê°„\s*(ì•Œë ¤|ê¶ê¸ˆ)',
#         r'ëª‡ì‹œì¸ì§€',
#         r'time\s*in'
#     ]
    
#     # ë¶€ì •ì  ì»¨í…ìŠ¤íŠ¸
#     negative_patterns = [
#         r'ì‹¤ì‹œê°„.*?(ì¶•êµ¬|ì•¼êµ¬|ë†êµ¬|ê²½ê¸°|ìŠ¤í¬ì¸ |ë‰´ìŠ¤|ì£¼ì‹|ì½”ì¸|ì •ë³´)',
#         r'ì‹œê°„.*?(ë¶€ì¡±|ì—†ì–´|ëª¨ìë¼|ë¶€ì¡±í•´|ì—†ë‹¤|ë‚¨ì•„)',
#         r'ì–¸ì œ.*?ì‹œê°„',
#         r'ì‹œê°„ëŒ€.*?ë‚ ì”¨',
#         r'ì‹œê°„ë‹¹',
#         r'ì‹œê°„.*?(ê±¸ë ¤|ì†Œìš”|í•„ìš”)',
#         r'ëª‡.*?ì‹œê°„.*?(í›„|ë’¤|ì „)',
#         r'ì‹œê°„.*?(ë§ì¶°|ë§ì¶”|ì¡°ì •)',
#         r'ì‹œê°„í‘œ',
#         r'ì‹œê°„.*?(ì˜ˆì•½|ì•½ì†|ì¼ì •)'
#     ]
    
#     # ë¶€ì •ì  ì»¨í…ìŠ¤íŠ¸ í™•ì¸
#     for pattern in negative_patterns:
#         if re.search(pattern, query):
#             return False
    
#     # ê¸ì •ì  íŒ¨í„´ í™•ì¸
#     for pattern in positive_patterns:
#         if re.search(pattern, query):
#             return True
    
#     return False

# @lru_cache(maxsize=100)
# def needs_search(query):
#     """ì¿¼ë¦¬ íƒ€ì…ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ê²€ìƒ‰ íƒ€ì…ì„ ë°˜í™˜"""
#     query_lower = query.strip().lower()
    
#     logger.info(f"ğŸ” ì¿¼ë¦¬ ë¶„ì„: '{query}' -> '{query_lower}'")
    
#     # ğŸ”´ ì•½êµ­ ê²€ìƒ‰ ì¶”ê°€ (ìµœìš°ì„  ì²´í¬)
#     if is_pharmacy_search(query):
#         logger.info("âœ… ì•½êµ­ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "pharmacy_search"
    
#     # ğŸ”´ ë¬¸í™”í–‰ì‚¬ ê²€ìƒ‰ ì¶”ê°€ (ìš°ì„ ìˆœìœ„ ë†’ì„)
#     if "ë¬¸í™”í–‰ì‚¬" in query_lower or "ë¬¸í™”ì´ë²¤íŠ¸" in query_lower:
#         logger.info("âœ… ë¬¸í™”í–‰ì‚¬ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "cultural_event"
    
#     # ë‚ ì”¨ ê´€ë ¨ ì¿¼ë¦¬
#     if "ë‚ ì”¨" in query_lower:
#         logger.info("âœ… ë‚ ì”¨ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "weather" if "ë‚´ì¼" not in query_lower else "tomorrow_weather"
    
#     # ì‹œê°„ ê´€ë ¨ ì¿¼ë¦¬
#     if "ì‹œê°„" in query_lower or "ë‚ ì§œ" in query_lower:
#         if is_time_query(query_lower):
#             logger.info("âœ… ì‹œê°„ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#             return "time"
    
#     # ì¶•êµ¬ ë¦¬ê·¸ ìˆœìœ„
#     if "ë¦¬ê·¸ìˆœìœ„" in query_lower:
#         logger.info("âœ… ë¦¬ê·¸ìˆœìœ„ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "league_standings"
    
#     # ì¶•êµ¬ ë“ì  ìˆœìœ„
#     if "ë¦¬ê·¸ë“ì ìˆœìœ„" in query_lower or "ë“ì ìˆœìœ„" in query_lower:
#         logger.info("âœ… ë“ì ìˆœìœ„ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "league_scorers"
    
#     # ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ ê´€ë ¨
#     if ("ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸" in query_lower or "ucl" in query_lower) and (
#         "í† ë„ˆë¨¼íŠ¸" in query_lower or "knockout" in query_lower or "16ê°•" in query_lower or "8ê°•" in query_lower or "4ê°•" in query_lower or "ê²°ìŠ¹" in query_lower):
#         logger.info("âœ… ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ í† ë„ˆë¨¼íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "cl_knockout"
    
#     # ì•½í’ˆ ê²€ìƒ‰
#     if "ì•½í’ˆê²€ìƒ‰" in query_lower:
#         logger.info("âœ… ì•½í’ˆ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "drug"
    
#     # ë…¼ë¬¸ ê²€ìƒ‰
#     if "ê³µí•™ë…¼ë¬¸" in query_lower or "arxiv" in query_lower:
#         logger.info("âœ… ê³µí•™ë…¼ë¬¸ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "arxiv_search"
#     if "ì˜í•™ë…¼ë¬¸" in query_lower:
#         logger.info("âœ… ì˜í•™ë…¼ë¬¸ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "pubmed_search"
    
#     # ì¼ë°˜ ê²€ìƒ‰
#     if "ê²€ìƒ‰í•´ì¤˜" in query_lower or "ê²€ìƒ‰í•´" in query_lower:
#         logger.info("âœ… ë„¤ì´ë²„ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "naver_search"

#     # MBTI ê´€ë ¨
#     if "mbtiê²€ì‚¬" in query_lower:
#         logger.info("âœ… MBTI ê²€ì‚¬ë¡œ ë¶„ë¥˜ë¨")
#         return "mbti"
#     if "mbtiìœ í˜•ì„¤ëª…" in query_lower or "mbtiìœ í˜•" in query_lower or "mbtiì„¤ëª…" in query_lower:
#         logger.info("âœ… MBTI ìœ í˜• ì„¤ëª…ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "mbti_types"
    
#     # ë‹¤ì¤‘ì§€ëŠ¥ ê´€ë ¨
#     if "ë‹¤ì¤‘ì§€ëŠ¥ìœ í˜•ì„¤ëª…" in query_lower or "ë‹¤ì¤‘ì§€ëŠ¥ìœ í˜•" in query_lower or "ë‹¤ì¤‘ì§€ëŠ¥ì„¤ëª…" in query_lower or \
#        "ë‹¤ì¤‘ì§€ëŠ¥ ìœ í˜• ì„¤ëª…" in query.strip().lower() or "ë‹¤ì¤‘ì§€ëŠ¥ ìœ í˜•" in query.strip().lower():
#         logger.info("âœ… ë‹¤ì¤‘ì§€ëŠ¥ ìœ í˜• ì„¤ëª…ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "multi_iq_types"
#     if "ë‹¤ì¤‘ì§€ëŠ¥ì§ì—…" in query_lower or "ë‹¤ì¤‘ì§€ëŠ¥ì¶”ì²œ" in query_lower or \
#        "ë‹¤ì¤‘ì§€ëŠ¥ ì§ì—…" in query.strip().lower() or "ë‹¤ì¤‘ì§€ëŠ¥ ì¶”ì²œ" in query.strip().lower():
#         logger.info("âœ… ë‹¤ì¤‘ì§€ëŠ¥ ì§ì—… ì¶”ì²œìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "multi_iq_jobs"
#     if "ë‹¤ì¤‘ì§€ëŠ¥ê²€ì‚¬" in query_lower or "ë‹¤ì¤‘ì§€ëŠ¥ ê²€ì‚¬" in query.strip().lower():
#         logger.info("âœ… ë‹¤ì¤‘ì§€ëŠ¥ ê²€ì‚¬ë¡œ ë¶„ë¥˜ë¨")
#         return "multi_iq"
#     if "ë‹¤ì¤‘ì§€ëŠ¥" in query_lower:
#         logger.info("âœ… ë‹¤ì¤‘ì§€ëŠ¥ ì „ì²´ ì„¤ëª…ìœ¼ë¡œ ë¶„ë¥˜ë¨")
#         return "multi_iq_full"
    
#     # ì¸ì‚¬ë§
#     if any(greeting in query_lower for greeting in GREETINGS):
#         logger.info("âœ… ì¸ì‚¬ë§ë¡œ ë¶„ë¥˜ë¨")
#         return "conversation"
    
#     # ê¸°ë³¸ê°’: ëŒ€í™”
#     logger.info("âœ… ì¼ë°˜ ëŒ€í™”ë¡œ ë¶„ë¥˜ë¨")
#     return "conversation"

# def is_drug_inquiry(query):
#     """ì•½í’ˆ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸"""
#     query_lower = query.lower().replace(" ", "")
#     return "ì•½í’ˆê²€ìƒ‰" in query_lower

# def extract_drug_name(query):
#     """ì•½í’ˆ ì´ë¦„ ì¶”ì¶œ"""
#     import re
#     # "ì•½í’ˆê²€ìƒ‰ [ì•½í’ˆëª…]" íŒ¨í„´ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ
#     match = re.search(r'ì•½í’ˆê²€ìƒ‰\s+(.+)', query, re.IGNORECASE)
#     if match:
#         return match.group(1).strip()
#     return ""

# def is_paper_search(query):
#     """ë…¼ë¬¸ ê²€ìƒ‰ ìš”ì²­ì¸ì§€ í™•ì¸"""
#     query_lower = query.lower().replace(" ", "")
#     return "ê³µí•™ë…¼ë¬¸" in query_lower or "arxiv" in query_lower or "ì˜í•™ë…¼ë¬¸" in query_lower

# def extract_keywords_for_paper_search(query):
#     """ë…¼ë¬¸ ê²€ìƒ‰ì„ ìœ„í•œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
#     import re
#     # "ê³µí•™ë…¼ë¬¸ [í‚¤ì›Œë“œ]" ë˜ëŠ” "ì˜í•™ë…¼ë¬¸ [í‚¤ì›Œë“œ]" íŒ¨í„´ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
#     patterns = [
#         r'ê³µí•™ë…¼ë¬¸\s+(.+)',
#         r'ì˜í•™ë…¼ë¬¸\s+(.+)',
#         r'arxiv\s+(.+)'
#     ]
    
#     for pattern in patterns:
#         match = re.search(pattern, query, re.IGNORECASE)
#         if match:
#             return match.group(1).strip()
#     return ""

# def is_pharmacy_search(query):
#     """ì•½êµ­ ê²€ìƒ‰ ì¿¼ë¦¬ì¸ì§€ í™•ì¸"""
#     query_lower = query.lower().replace(" ", "")
    
#     logger.info(f"ğŸ” ì•½êµ­ ê²€ìƒ‰ ì²´í¬: '{query}' -> '{query_lower}'")
    
#     pharmacy_keywords = [
#         "ì•½êµ­", "ì•½êµ­ì •ë³´", "ì•½êµ­ê²€ìƒ‰", "ì•½êµ­ìš´ì˜", "ì•½êµ­ì‹œê°„",
#         "ì„œìš¸ì•½êµ­", "ì•½êµ­ì°¾ê¸°", "ì•½êµ­ìœ„ì¹˜", "ì•½êµ­ìš´ì˜ì‹œê°„"
#     ]
    
#     for keyword in pharmacy_keywords:
#         if keyword in query_lower:
#             logger.info(f"âœ… ì•½êµ­ í‚¤ì›Œë“œ '{keyword}' ë§¤ì¹­ë¨")
#             return True
    
#     # ì§€ì—­êµ¬ + ì•½êµ­ íŒ¨í„´
#     districts = [
#         "ê°•ë‚¨êµ¬", "ê°•ë™êµ¬", "ê°•ë¶êµ¬", "ê°•ì„œêµ¬", "ê´€ì•…êµ¬", "ê´‘ì§„êµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬",
#         "ë…¸ì›êµ¬", "ë„ë´‰êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ë™ì‘êµ¬", "ë§ˆí¬êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ì„œì´ˆêµ¬", "ì„±ë™êµ¬",
#         "ì„±ë¶êµ¬", "ì†¡íŒŒêµ¬", "ì–‘ì²œêµ¬", "ì˜ë“±í¬êµ¬", "ìš©ì‚°êµ¬", "ì€í‰êµ¬", "ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ì¤‘ë‘êµ¬"
#     ]
    
#     for district in districts:
#         if district in query and "ì•½êµ­" in query_lower:
#             logger.info(f"âœ… ì§€ì—­êµ¬ '{district}' + ì•½êµ­ íŒ¨í„´ ë§¤ì¹­ë¨")
#             return True
    
#     logger.info("âŒ ì•½êµ­ í‚¤ì›Œë“œ ë§¤ì¹­ ì•ˆë¨")
#     return False

# utils/query_analyzer.py
import re
from functools import lru_cache
import logging

logger = logging.getLogger(__name__)

# ë„ì‹œ ë° ì‹œê°„ ì¶”ì¶œ
CITY_PATTERNS = [
    re.compile(r'(?:ì˜¤ëŠ˜|ë‚´ì¼|ëª¨ë ˆ|ì´ë²ˆ ì£¼|ì£¼ê°„)?\s*([ê°€-í£a-zA-Z\s]{2,20}(?:ì‹œ|êµ°|city)?)ì˜?\s*ë‚ ì”¨', re.IGNORECASE),
    re.compile(r'(?:ì˜¤ëŠ˜|ë‚´ì¼|ëª¨ë ˆ|ì´ë²ˆ ì£¼|ì£¼ê°„)?\s*([ê°€-í£a-zA-Z\s]{2,20}(?:ì‹œ|êµ°|city)?)\s*ë‚ ì”¨', re.IGNORECASE),
]

TIME_CITY_PATTERNS = [
    re.compile(r'([ê°€-í£a-zA-Z]{2,20}(?:ì‹œ|êµ°)?)ì˜?\s*ì‹œê°„'),
    re.compile(r'([ê°€-í£a-zA-Z]{2,20}(?:ì‹œ|êµ°)?)\s*ì‹œê°„'),
]

GREETINGS = ["ì•ˆë…•", "í•˜ì´", "í—¬ë¡œ", "ã…ã…‡", "ì™“ì—…", "í• ë¡±", "í—¤ì´"]

def extract_city_from_query(query):
    for pattern in CITY_PATTERNS:
        match = pattern.search(query)
        if match:
            city = match.group(1).strip()
            if city not in ["ì˜¤ëŠ˜", "ë‚´ì¼", "ëª¨ë ˆ", "ì´ë²ˆ ì£¼", "ì£¼ê°„", "í˜„ì¬"]:
                return city
    return "ì„œìš¸"

def extract_city_from_time_query(query):
    for pattern in TIME_CITY_PATTERNS:
        match = pattern.search(query)
        if match:
            city = match.group(1).strip()
            if city != "í˜„ì¬":
                return city
    return "ì„œìš¸"

# ì¶•êµ¬ë¦¬ê·¸ 
LEAGUE_MAPPING = {
    "epl": {"name": "í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ (ì˜êµ­)", "code": "PL"},
    "laliga": {"name": "ë¼ë¦¬ê°€ (ìŠ¤í˜ì¸)", "code": "PD"},
    "bundesliga": {"name": "ë¶„ë°ìŠ¤ë¦¬ê°€ (ë…ì¼)", "code": "BL1"},
    "seriea": {"name": "ì„¸ë¦¬ì— A (ì´íƒˆë¦¬ì•„)", "code": "SA"},
    "ligue1": {"name": "ë¦¬ê·¸ 1 (í”„ë‘ìŠ¤)", "code": "FL1"},
    "championsleague": {"name": "ì±”í”¼ì–¸ìŠ¤ ë¦¬ê·¸", "code": "CL"}
}

def extract_league_from_query(query):
    query_lower = query.lower().replace(" ", "")
    league_keywords = {
        "epl": ["epl", "í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸"],
        "laliga": ["laliga", "ë¼ë¦¬ê°€"],
        "bundesliga": ["bundesliga", "ë¶„ë°ìŠ¤ë¦¬ê°€"],
        "seriea": ["seriea", "ì„¸ë¦¬ì—a"],
        "ligue1": ["ligue1", "ë¦¬ê·¸1"],
        "championsleague": ["championsleague", "ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸", "ucl"]
    }
    for league_key, keywords in league_keywords.items():
        if any(keyword in query_lower for keyword in keywords):
            return league_key
    return None

def is_time_query(query):
    """ì‹œê°„ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ ì •í™•í•˜ê²Œ íŒë‹¨"""
    
    # ê¸ì •ì  ì‹œê°„ íŒ¨í„´ë“¤
    positive_patterns = [
        r'(ì„œìš¸|ë„ì¿„|ë‰´ìš•|ëŸ°ë˜|íŒŒë¦¬|ë² ë¥¼ë¦°|ë§ˆë“œë¦¬ë“œ|ë¡œë§ˆ|ë°€ë¼ë…¸|ì‹œë“œë‹ˆ|í™ì½©|ì‹±ê°€í¬ë¥´|ëª¨ìŠ¤í¬ë°”|ë‘ë°”ì´|ë¼ìŠ¤ë² ì´ê±°ìŠ¤|ì‹œì¹´ê³ |í† ë¡ í† |ë©œë²„ë¥¸)\s*(ì‹œê°„|time)',
        r'(í˜„ì¬|ì§€ê¸ˆ)\s*(ì‹œê°„|time)',
        r'ëª‡\s*ì‹œ',
        r'(ì˜¤ëŠ˜|í˜„ì¬|ì§€ê¸ˆ|ê¸ˆì¼)\s*(ë‚ ì§œ|date)',
        r'what\s*time',
        r'ì‹œê°„\s*(ì•Œë ¤|ê¶ê¸ˆ)',
        r'ëª‡ì‹œì¸ì§€',
        r'time\s*in'
    ]
    
    # ë¶€ì •ì  ì»¨í…ìŠ¤íŠ¸
    negative_patterns = [
        r'ì‹¤ì‹œê°„.*?(ì¶•êµ¬|ì•¼êµ¬|ë†êµ¬|ê²½ê¸°|ìŠ¤í¬ì¸ |ë‰´ìŠ¤|ì£¼ì‹|ì½”ì¸|ì •ë³´)',
        r'ì‹œê°„.*?(ë¶€ì¡±|ì—†ì–´|ëª¨ìë¼|ë¶€ì¡±í•´|ì—†ë‹¤|ë‚¨ì•„)',
        r'ì–¸ì œ.*?ì‹œê°„',
        r'ì‹œê°„ëŒ€.*?ë‚ ì”¨',
        r'ì‹œê°„ë‹¹',
        r'ì‹œê°„.*?(ê±¸ë ¤|ì†Œìš”|í•„ìš”)',
        r'ëª‡.*?ì‹œê°„.*?(í›„|ë’¤|ì „)',
        r'ì‹œê°„.*?(ë§ì¶°|ë§ì¶”|ì¡°ì •)',
        r'ì‹œê°„í‘œ',
        r'ì‹œê°„.*?(ì˜ˆì•½|ì•½ì†|ì¼ì •)'
    ]
    
    # ë¶€ì •ì  ì»¨í…ìŠ¤íŠ¸ í™•ì¸
    for pattern in negative_patterns:
        if re.search(pattern, query):
            return False
    
    # ê¸ì •ì  íŒ¨í„´ í™•ì¸
    for pattern in positive_patterns:
        if re.search(pattern, query):
            return True
    
    return False

def is_hospital_search(query):
    """ë³‘ì› ê²€ìƒ‰ ì¿¼ë¦¬ì¸ì§€ í™•ì¸ (ê³µê³µ API ì‚¬ìš©)"""
    query_lower = query.lower().replace(" ", "")
    
    logger.info(f"ğŸ” ë³‘ì› ê²€ìƒ‰ ì²´í¬: '{query}' -> '{query_lower}'")
    
    # ëª…ì‹œì  ì›¹ ê²€ìƒ‰ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì œì™¸
    web_search_keywords = [
        "ë„¤ì´ë²„ê²€ìƒ‰", "ì›¹ê²€ìƒ‰", "ì¸í„°ë„·ê²€ìƒ‰", "ì˜¨ë¼ì¸ê²€ìƒ‰",
        "ê²€ìƒ‰í•´ì¤˜", "ê²€ìƒ‰í•´", "ì›¹ê²€ìƒ‰"
    ]
    
    for keyword in web_search_keywords:
        if keyword in query_lower:
            logger.info(f"âŒ ì›¹ ê²€ìƒ‰ í‚¤ì›Œë“œ '{keyword}'ë¡œ ì¸í•´ ë³‘ì› ê²€ìƒ‰ ì œì™¸")
            return False
    
    hospital_keywords = [
        "ë³‘ì›ì •ë³´", "ë³‘ì›ìš´ì˜", "ë³‘ì›ì‹œê°„", "ì„œìš¸ë³‘ì›", "ë³‘ì›ì°¾ê¸°", 
        "ë³‘ì›ìœ„ì¹˜", "ë³‘ì›ìš´ì˜ì‹œê°„", "ì˜ì›", "í´ë¦¬ë‹‰", "ì§„ë£Œì†Œ"
    ]
    
    for keyword in hospital_keywords:
        if keyword in query_lower:
            logger.info(f"âœ… ë³‘ì› í‚¤ì›Œë“œ '{keyword}' ë§¤ì¹­ë¨")
            return True
    
    # ì§€ì—­êµ¬ + ë³‘ì› íŒ¨í„´ (ë‹¨, ê²€ìƒ‰ í‚¤ì›Œë“œ ì—†ì„ ë•Œë§Œ)
    districts = [
        "ê°•ë‚¨êµ¬", "ê°•ë™êµ¬", "ê°•ë¶êµ¬", "ê°•ì„œêµ¬", "ê´€ì•…êµ¬", "ê´‘ì§„êµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬",
        "ë…¸ì›êµ¬", "ë„ë´‰êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ë™ì‘êµ¬", "ë§ˆí¬êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ì„œì´ˆêµ¬", "ì„±ë™êµ¬",
        "ì„±ë¶êµ¬", "ì†¡íŒŒêµ¬", "ì–‘ì²œêµ¬", "ì˜ë“±í¬êµ¬", "ìš©ì‚°êµ¬", "ì€í‰êµ¬", "ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ì¤‘ë‘êµ¬"
    ]
    
    for district in districts:
        if district in query and "ë³‘ì›" in query_lower:
            logger.info(f"âœ… ì§€ì—­êµ¬ '{district}' + ë³‘ì› íŒ¨í„´ ë§¤ì¹­ë¨")
            return True
    
    logger.info("âŒ ë³‘ì› í‚¤ì›Œë“œ ë§¤ì¹­ ì•ˆë¨")
    return False

def is_pharmacy_search(query):
    """ì•½êµ­ ê²€ìƒ‰ ì¿¼ë¦¬ì¸ì§€ í™•ì¸ (ê³µê³µ API ì‚¬ìš©)"""
    query_lower = query.lower().replace(" ", "")
    
    logger.info(f"ğŸ” ì•½êµ­ ê²€ìƒ‰ ì²´í¬: '{query}' -> '{query_lower}'")
    
    # ëª…ì‹œì  ì›¹ ê²€ìƒ‰ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì œì™¸
    web_search_keywords = [
        "ë„¤ì´ë²„ê²€ìƒ‰", "ì›¹ê²€ìƒ‰", "ì¸í„°ë„·ê²€ìƒ‰", "ì˜¨ë¼ì¸ê²€ìƒ‰",
        "ê²€ìƒ‰í•´ì¤˜", "ê²€ìƒ‰í•´", "ì›¹ê²€ìƒ‰"
    ]
    
    for keyword in web_search_keywords:
        if keyword in query_lower:
            logger.info(f"âŒ ì›¹ ê²€ìƒ‰ í‚¤ì›Œë“œ '{keyword}'ë¡œ ì¸í•´ ì•½êµ­ ê²€ìƒ‰ ì œì™¸")
            return False
    
    pharmacy_keywords = [
        "ì•½êµ­", "ì•½êµ­ì •ë³´", "ì•½êµ­ê²€ìƒ‰", "ì•½êµ­ìš´ì˜", "ì•½êµ­ì‹œê°„",
        "ì„œìš¸ì•½êµ­", "ì•½êµ­ì°¾ê¸°", "ì•½êµ­ìœ„ì¹˜", "ì•½êµ­ìš´ì˜ì‹œê°„"
    ]
    
    for keyword in pharmacy_keywords:
        if keyword in query_lower:
            logger.info(f"âœ… ì•½êµ­ í‚¤ì›Œë“œ '{keyword}' ë§¤ì¹­ë¨")
            return True
    
    # ì§€ì—­êµ¬ + ì•½êµ­ íŒ¨í„´ (ë‹¨, ê²€ìƒ‰ í‚¤ì›Œë“œ ì—†ì„ ë•Œë§Œ)
    districts = [
        "ê°•ë‚¨êµ¬", "ê°•ë™êµ¬", "ê°•ë¶êµ¬", "ê°•ì„œêµ¬", "ê´€ì•…êµ¬", "ê´‘ì§„êµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬",
        "ë…¸ì›êµ¬", "ë„ë´‰êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ë™ì‘êµ¬", "ë§ˆí¬êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ì„œì´ˆêµ¬", "ì„±ë™êµ¬",
        "ì„±ë¶êµ¬", "ì†¡íŒŒêµ¬", "ì–‘ì²œêµ¬", "ì˜ë“±í¬êµ¬", "ìš©ì‚°êµ¬", "ì€í‰êµ¬", "ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ì¤‘ë‘êµ¬"
    ]
    
    for district in districts:
        if district in query and "ì•½êµ­" in query_lower:
            logger.info(f"âœ… ì§€ì—­êµ¬ '{district}' + ì•½êµ­ íŒ¨í„´ ë§¤ì¹­ë¨")
            return True
    
    logger.info("âŒ ì•½êµ­ í‚¤ì›Œë“œ ë§¤ì¹­ ì•ˆë¨")
    return False

@lru_cache(maxsize=100)
def needs_search(query):
    """ì¿¼ë¦¬ íƒ€ì…ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ê²€ìƒ‰ íƒ€ì…ì„ ë°˜í™˜"""
    query_lower = query.strip().lower()
    
    logger.info(f"ğŸ” ì¿¼ë¦¬ ë¶„ì„: '{query}' -> '{query_lower}'")
    
    # ğŸ”´ ëª…ì‹œì  ì›¹ ê²€ìƒ‰ ìš”ì²­ (ìµœìš°ì„  ì²´í¬)
    if "ê²€ìƒ‰í•´ì¤˜" in query_lower or "ê²€ìƒ‰í•´" in query_lower:
        logger.info("âœ… ë„¤ì´ë²„ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨ (ê²€ìƒ‰ í‚¤ì›Œë“œ ëª…ì‹œ)")
        return "naver_search"
    
    # ğŸ”´ ì•½êµ­ ê²€ìƒ‰ (ê³µê³µ API)
    if is_pharmacy_search(query):
        logger.info("âœ… ì•½êµ­ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "pharmacy_search"
    
    # ğŸ”´ ë³‘ì› ê²€ìƒ‰ (ê³µê³µ API)
    if is_hospital_search(query):
        logger.info("âœ… ë³‘ì› ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "hospital_search"
    
    # ğŸ”´ ë¬¸í™”í–‰ì‚¬ ê²€ìƒ‰
    if "ë¬¸í™”í–‰ì‚¬" in query_lower or "ë¬¸í™”ì´ë²¤íŠ¸" in query_lower:
        logger.info("âœ… ë¬¸í™”í–‰ì‚¬ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "cultural_event"
    
    # ë‚ ì”¨ ê´€ë ¨ ì¿¼ë¦¬
    if "ë‚ ì”¨" in query_lower:
        logger.info("âœ… ë‚ ì”¨ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "weather" if "ë‚´ì¼" not in query_lower else "tomorrow_weather"
    
    # ì‹œê°„ ê´€ë ¨ ì¿¼ë¦¬
    if "ì‹œê°„" in query_lower or "ë‚ ì§œ" in query_lower:
        if is_time_query(query_lower):
            logger.info("âœ… ì‹œê°„ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
            return "time"
    
    # ì¶•êµ¬ ë¦¬ê·¸ ìˆœìœ„
    if "ë¦¬ê·¸ìˆœìœ„" in query_lower:
        logger.info("âœ… ë¦¬ê·¸ìˆœìœ„ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "league_standings"
    
    # ì¶•êµ¬ ë“ì  ìˆœìœ„
    if "ë¦¬ê·¸ë“ì ìˆœìœ„" in query_lower or "ë“ì ìˆœìœ„" in query_lower:
        logger.info("âœ… ë“ì ìˆœìœ„ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "league_scorers"
    
    # ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ ê´€ë ¨
    if ("ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸" in query_lower or "ucl" in query_lower) and (
        "í† ë„ˆë¨¼íŠ¸" in query_lower or "knockout" in query_lower or "16ê°•" in query_lower or "8ê°•" in query_lower or "4ê°•" in query_lower or "ê²°ìŠ¹" in query_lower):
        logger.info("âœ… ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ í† ë„ˆë¨¼íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "cl_knockout"
    
    # ì•½í’ˆ ê²€ìƒ‰
    if "ì•½í’ˆê²€ìƒ‰" in query_lower:
        logger.info("âœ… ì•½í’ˆ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "drug"
    
    # ë…¼ë¬¸ ê²€ìƒ‰
    if "ê³µí•™ë…¼ë¬¸" in query_lower or "arxiv" in query_lower:
        logger.info("âœ… ê³µí•™ë…¼ë¬¸ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "arxiv_search"
    if "ì˜í•™ë…¼ë¬¸" in query_lower:
        logger.info("âœ… ì˜í•™ë…¼ë¬¸ ê²€ìƒ‰ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "pubmed_search"
    
    # MBTI ê´€ë ¨
    if "mbtiê²€ì‚¬" in query_lower:
        logger.info("âœ… MBTI ê²€ì‚¬ë¡œ ë¶„ë¥˜ë¨")
        return "mbti"
    if "mbtiìœ í˜•ì„¤ëª…" in query_lower or "mbtiìœ í˜•" in query_lower or "mbtiì„¤ëª…" in query_lower:
        logger.info("âœ… MBTI ìœ í˜• ì„¤ëª…ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "mbti_types"
    
    # ë‹¤ì¤‘ì§€ëŠ¥ ê´€ë ¨
    if "ë‹¤ì¤‘ì§€ëŠ¥ìœ í˜•ì„¤ëª…" in query_lower or "ë‹¤ì¤‘ì§€ëŠ¥ìœ í˜•" in query_lower or "ë‹¤ì¤‘ì§€ëŠ¥ì„¤ëª…" in query_lower or \
       "ë‹¤ì¤‘ì§€ëŠ¥ ìœ í˜• ì„¤ëª…" in query.strip().lower() or "ë‹¤ì¤‘ì§€ëŠ¥ ìœ í˜•" in query.strip().lower():
        logger.info("âœ… ë‹¤ì¤‘ì§€ëŠ¥ ìœ í˜• ì„¤ëª…ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "multi_iq_types"
    if "ë‹¤ì¤‘ì§€ëŠ¥ì§ì—…" in query_lower or "ë‹¤ì¤‘ì§€ëŠ¥ì¶”ì²œ" in query_lower or \
       "ë‹¤ì¤‘ì§€ëŠ¥ ì§ì—…" in query.strip().lower() or "ë‹¤ì¤‘ì§€ëŠ¥ ì¶”ì²œ" in query.strip().lower():
        logger.info("âœ… ë‹¤ì¤‘ì§€ëŠ¥ ì§ì—… ì¶”ì²œìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "multi_iq_jobs"
    if "ë‹¤ì¤‘ì§€ëŠ¥ê²€ì‚¬" in query_lower or "ë‹¤ì¤‘ì§€ëŠ¥ ê²€ì‚¬" in query.strip().lower():
        logger.info("âœ… ë‹¤ì¤‘ì§€ëŠ¥ ê²€ì‚¬ë¡œ ë¶„ë¥˜ë¨")
        return "multi_iq"
    if "ë‹¤ì¤‘ì§€ëŠ¥" in query_lower:
        logger.info("âœ… ë‹¤ì¤‘ì§€ëŠ¥ ì „ì²´ ì„¤ëª…ìœ¼ë¡œ ë¶„ë¥˜ë¨")
        return "multi_iq_full"
    
    # ì¸ì‚¬ë§
    if any(greeting in query_lower for greeting in GREETINGS):
        logger.info("âœ… ì¸ì‚¬ë§ë¡œ ë¶„ë¥˜ë¨")
        return "conversation"
    
    # ê¸°ë³¸ê°’: ëŒ€í™”
    logger.info("âœ… ì¼ë°˜ ëŒ€í™”ë¡œ ë¶„ë¥˜ë¨")
    return "conversation"

def is_drug_inquiry(query):
    """ì•½í’ˆ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸"""
    query_lower = query.lower().replace(" ", "")
    return "ì•½í’ˆê²€ìƒ‰" in query_lower

def extract_drug_name(query):
    """ì•½í’ˆ ì´ë¦„ ì¶”ì¶œ"""
    import re
    # "ì•½í’ˆê²€ìƒ‰ [ì•½í’ˆëª…]" íŒ¨í„´ì—ì„œ ì•½í’ˆëª… ì¶”ì¶œ
    match = re.search(r'ì•½í’ˆê²€ìƒ‰\s+(.+)', query, re.IGNORECASE)
    if match:
        return match.group(1).strip()
    return ""

def is_paper_search(query):
    """ë…¼ë¬¸ ê²€ìƒ‰ ìš”ì²­ì¸ì§€ í™•ì¸"""
    query_lower = query.lower().replace(" ", "")
    return "ê³µí•™ë…¼ë¬¸" in query_lower or "arxiv" in query_lower or "ì˜í•™ë…¼ë¬¸" in query_lower

def extract_keywords_for_paper_search(query):
    """ë…¼ë¬¸ ê²€ìƒ‰ì„ ìœ„í•œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    import re
    # "ê³µí•™ë…¼ë¬¸ [í‚¤ì›Œë“œ]" ë˜ëŠ” "ì˜í•™ë…¼ë¬¸ [í‚¤ì›Œë“œ]" íŒ¨í„´ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    patterns = [
        r'ê³µí•™ë…¼ë¬¸\s+(.+)',
        r'ì˜í•™ë…¼ë¬¸\s+(.+)',
        r'arxiv\s+(.+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, query, re.IGNORECASE)
        if match:
            return match.group(1).strip()
    return ""