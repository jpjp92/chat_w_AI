# set lib
from config.imports import *
from config.env import *
# from streamlit.runtime.scriptrunner import add_script_run_ctx

# Import utils modules
from utils.webpage_analyzer import (
    fetch_webpage_content, 
    summarize_webpage_content, 
    extract_urls_from_text,
    is_url_summarization_request,
    is_numbered_link_request,
    is_followup_question
)
from utils.providers import (
    select_best_provider_with_priority,
    select_random_available_provider,
    get_client
)
from utils.query_analyzer import (
    needs_search,
    extract_city_from_query,
    extract_city_from_time_query,
    extract_league_from_query,
    is_drug_inquiry,
    extract_drug_name,
    is_paper_search,
    extract_keywords_for_paper_search,
    is_time_query,
    is_pharmacy_search,  # ğŸ”´ ì¶”ê°€
    LEAGUE_MAPPING
)
# Import weather, football, drug, paper search, culture event, and web search modules
from utils.weather import WeatherAPI
from utils.football import FootballAPI
from utils.drug_info import DrugAPI
from utils.paper_search import PaperSearchAPI
from utils.culture_event import CultureEventAPI
from utils.web_search import WebSearchAPI
from utils.drug_store import DrugStoreAPI  # ğŸ”´ ì¶”ê°€

# set logger
logging.basicConfig(level=logging.INFO)  # ë””ë²„ê¹…ì„ ìœ„í•´ INFO ë ˆë²¨ë¡œ ë³€ê²½
logger = logging.getLogger("HybridChat")
logging.getLogger("streamlit").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)

# set cach
cache = Cache("cache_directory")

class MemoryCache:
    def __init__(self, max_size=1000):
        self.cache = {}
        self.expiry = {}
        self.max_size = max_size
        self.access_count = {}
    
    def get(self, key):
        if key in self.cache and time.time() < self.expiry[key]:
            self.access_count[key] = self.access_count.get(key, 0) + 1
            return self.cache[key]
        return cache.get(key)
    
    def setex(self, key, ttl, value):
        # ìºì‹œ í¬ê¸° ì œí•œ
        if len(self.cache) >= self.max_size:
            self._evict_least_used()
        
        self.cache[key] = value
        self.expiry[key] = time.time() + ttl
        self.access_count[key] = 1
        cache.set(key, value, expire=ttl)
    
    def _evict_least_used(self):
        """ê°€ì¥ ì ê²Œ ì‚¬ìš©ëœ ìºì‹œ í•­ëª© ì œê±°"""
        if not self.access_count:
            return
        
        least_used_key = min(self.access_count, key=self.access_count.get)
        self.cache.pop(least_used_key, None)
        self.expiry.pop(least_used_key, None)
        self.access_count.pop(least_used_key, None)
        
cache_handler = MemoryCache()

# ë‚ ì§œ ì¼ê´„ì  ìˆ˜ì • 
def format_date(fordate):
    if fordate == 'No date':
        return 'ë‚ ì§œ ì—†ìŒ'
    try:
        date_obj = datetime.strptime(fordate, '%Y %b %d')
        return date_obj.strftime('%Y.%m.%d')
    except ValueError:
        return fordate

# JSON íŒŒì¼ì—ì„œ MBTI ë° ë‹¤ì¤‘ì§€ëŠ¥ ë°ì´í„° ë¡œë“œ (ìºì‹± ì ìš©)
def load_personality_data():
    """ì„±ê²© ê²€ì‚¬ ë°ì´í„° ë¡œë“œ (ê°œì„ ëœ ì—ëŸ¬ í•¸ë“¤ë§)"""
    cache_key = "personality_data"
    cached_data = cache_handler.get(cache_key)
    if cached_data:
        return cached_data
    
    try:
        config_path = "config/personality_multi_data.json"
        if not os.path.exists(config_path):
            logger.warning(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            # ê¸°ë³¸ ë°ì´í„° ë°˜í™˜
            return {
                "mbti_descriptions": {},
                "multi_iq_descriptions": {},
                "mbti_full_description": "MBTI ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "multi_iq_full_description": "ë‹¤ì¤‘ì§€ëŠ¥ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
        
        with open(config_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        # ë°ì´í„° ê²€ì¦
        required_keys = ["mbti_descriptions", "multi_iq_descriptions", "mbti_full_description", "multi_iq_full_description"]
        for key in required_keys:
            if key not in data:
                logger.warning(f"í•„ìˆ˜ í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {key}")
                data[key] = {} if "descriptions" in key else "ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        cache_handler.setex(cache_key, 86400, data)  # 24ì‹œê°„ ìºì‹±
        return data
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return {
            "mbti_descriptions": {},
            "multi_iq_descriptions": {},
            "mbti_full_description": "MBTI ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜",
            "multi_iq_full_description": "ë‹¤ì¤‘ì§€ëŠ¥ ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜"
        }
    except Exception as e:
        logger.error(f"ì„±ê²© ë°ì´í„° ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        return {
            "mbti_descriptions": {},
            "multi_iq_descriptions": {},
            "mbti_full_description": "MBTI ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨",
            "multi_iq_full_description": "ë‹¤ì¤‘ì§€ëŠ¥ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨"
        }

# ë°ì´í„° ë¡œë“œ
personality_data = load_personality_data()
mbti_descriptions = personality_data["mbti_descriptions"]
multi_iq_descriptions = personality_data["multi_iq_descriptions"]
mbti_full_description = personality_data["mbti_full_description"]
multi_iq_full_description = personality_data["multi_iq_full_description"]

# ì´ˆê¸°í™” - API í´ë˜ìŠ¤ë“¤ì„ utilsì—ì„œ importí•˜ì—¬ ì‚¬ìš©
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™” ìµœì í™”
@st.cache_resource
def initialize_apis():
    """API í´ë˜ìŠ¤ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤ (ìºì‹± ì ìš©)"""
    return {
        'weather': WeatherAPI(cache_handler=cache_handler, WEATHER_API_KEY=WEATHER_API_KEY),
        'football': FootballAPI(api_key=SPORTS_API_KEY, cache_handler=cache_handler),
        'drug': DrugAPI(api_key=DRUG_API_KEY, cache_handler=cache_handler),
        'drug_store': DrugStoreAPI(api_key=DRUG_STORE_KEY, cache_handler=cache_handler),  # ğŸ”´ ì¶”ê°€
        'paper_search': PaperSearchAPI(ncbi_key=NCBI_KEY, cache_handler=cache_handler),
        'culture_event': CultureEventAPI(api_key=CULTURE_API_KEY, cache_handler=cache_handler),
        'web_search': WebSearchAPI(client_id=NAVER_CLIENT_ID, client_secret=NAVER_CLIENT_SECRET, cache_handler=cache_handler)
    }

# ì „ì—­ ë³€ìˆ˜ ëŒ€ì‹  í•¨ìˆ˜ í˜¸ì¶œ
apis = initialize_apis()
weather_api = apis['weather']
football_api = apis['football']
drug_api = apis['drug']
paper_search_api = apis['paper_search']
culture_event_api = apis['culture_event']
web_search_api = apis['web_search']
drug_store_api = apis['drug_store']  # ğŸ”´ ì¶”ê°€

st.set_page_config(page_title="AI ì±—ë´‡", page_icon="ğŸ¤–")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ë¶€ë¶„ì— ê²€ìƒ‰ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
def init_session_state():
    if "is_logged_in" not in st.session_state:
        st.session_state.is_logged_in = False
    if "user_id" not in st.session_state:
        st.session_state.user_id = None
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?ğŸ˜Š"}]
    if "session_id" not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    
    # ğŸ”´ clientì™€ providerëŠ” í•œ ë²ˆë§Œ ì´ˆê¸°í™”
    if "client" not in st.session_state or "provider_name" not in st.session_state:
        client, provider_name = select_random_available_provider()
        st.session_state.client = client
        st.session_state.provider_name = provider_name
        logger.info(f"ì„¸ì…˜ ì´ˆê¸°í™” - ì„ íƒëœ í”„ë¡œë°”ì´ë”: {provider_name}")
    
    # ê²€ìƒ‰ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ ì €ì¥ì„ ìœ„í•œ ë³€ìˆ˜ ì¶”ê°€
    if "search_contexts" not in st.session_state:
        st.session_state.search_contexts = {}
    if "current_context" not in st.session_state:
        st.session_state.current_context = None

# ì‚¬ìš©ì ë° ì±„íŒ… ê¸°ë¡ ê´€ë¦¬
def create_or_get_user(nickname):
    user = supabase.table("users").select("*").eq("nickname", nickname).execute()
    if user.data:
        return user.data[0]["id"], True
    new_user = supabase.table("users").insert({"nickname": nickname, "created_at": datetime.now().isoformat()}).execute()
    return new_user.data[0]["id"], False

def save_chat_history(user_id, session_id, question, answer, time_taken):
    if isinstance(answer, dict) and "table" in answer and isinstance(answer["table"], pd.DataFrame):
        answer_to_save = {
            "header": answer["header"],
            "table": answer["table"].to_dict(orient="records"),
            "footer": answer["footer"]
        }
    else:
        answer_to_save = answer
    
    supabase.table("chat_history").insert({
        "user_id": user_id,
        "session_id": session_id,
        "question": question,
        "answer": answer_to_save,
        "time_taken": time_taken,
        "created_at": datetime.now().isoformat()
    }).execute()

def async_save_chat_history(user_id, session_id, question, answer, time_taken):
    threading.Thread(target=save_chat_history, args=(user_id, session_id, question, answer, time_taken)).start()

# ëŒ€í™”í˜• ì‘ë‹µ (ë¹„ë™ê¸°)
conversation_cache = MemoryCache()
_client_instance = None

# ëŒ€í™”í˜• ì‘ë‹µ í•¨ìˆ˜ ìˆ˜ì •
async def get_conversational_response(query, chat_history):
    logger.info(f"ëŒ€í™”í˜• ì‘ë‹µ ì‹œì‘ - ì¿¼ë¦¬: '{query}'")
    
    # ìºì‹œ í™•ì¸
    cache_key = f"conv:{needs_search(query)}:{query}"
    cached = conversation_cache.get(cache_key)
    if cached:
        return cached
    
    # í˜„ì¬ ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    current_context = None
    if hasattr(st, 'session_state') and 'current_context' in st.session_state:
        current_context_id = st.session_state.current_context
        if current_context_id and current_context_id in st.session_state.search_contexts:
            current_context = st.session_state.search_contexts[current_context_id]
    
    # ìˆœì„œ ê¸°ë°˜ ë§í¬ ìš”ì²­ í™•ì¸
    try:
        is_numbered_request, numbered_url = is_numbered_link_request(query, current_context)
        logger.info(f"ìˆœì„œ ê¸°ë°˜ ìš”ì²­: {is_numbered_request}, URL: {numbered_url}")
        
        if is_numbered_request and numbered_url:
            try:
                logger.info(f"ì›¹í˜ì´ì§€ ìš”ì•½ ì‹œì‘: {numbered_url}")
                # ğŸ”´ ì„¸ì…˜ ìƒíƒœì˜ client ì „ë‹¬
                summary = summarize_webpage_content(numbered_url, query, st.session_state.client)
                conversation_cache.setex(cache_key, 600, summary)
                return summary
            except Exception as e:
                logger.error(f"ì›¹í˜ì´ì§€ ìš”ì•½ ì˜¤ë¥˜: {str(e)}")
                return f"í•´ë‹¹ ë§í¬ì˜ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)} ğŸ˜“"
        
        # ì¼ë°˜ URL ìš”ì•½ ìš”ì²­ í™•ì¸
        is_url_request, url = is_url_summarization_request(query)
        logger.info(f"URL ìš”ì•½ ìš”ì²­: {is_url_request}, URL: {url}")
        
        if is_url_request and url:
            try:
                logger.info(f"ì§ì ‘ URL ìš”ì•½ ì‹œì‘: {url}")
                # ğŸ”´ ì„¸ì…˜ ìƒíƒœì˜ client ì „ë‹¬
                summary = summarize_webpage_content(url, query, st.session_state.client)
                conversation_cache.setex(cache_key, 600, summary)
                return summary
            except Exception as e:
                logger.error(f"URL ìš”ì•½ ì˜¤ë¥˜: {str(e)}")
                return f"í•´ë‹¹ ë§í¬ì˜ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)} ğŸ˜“"
    
    except Exception as e:
        logger.error(f"ë§í¬ ìš”ì•½ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    # ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬
    messages = [
        {"role": "system", "content": "ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤. ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©: âœ…(ì™„ë£Œ), â“(ì§ˆë¬¸), ğŸ˜Š(ì¹œì ˆ)"}
    ]
    
    # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    if current_context:
        context_type = current_context["type"]
        context_query = current_context["query"]
        context_result = current_context["result"]
        
        # ì»¨í…ìŠ¤íŠ¸ ìœ í˜•ì— ë”°ë¼ ë‹¤ë¥¸ ì§€ì‹œ ì¶”ê°€
        if context_type == "naver_search":
            # í…Œì´ë¸” ë°ì´í„°ì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(context_result, dict) and "table" in context_result:
                table_json = context_result["table"].to_json(orient="records")
                context_desc = f"ì‚¬ìš©ìê°€ '{context_query}'ì— ëŒ€í•´ ê²€ìƒ‰í–ˆê³ , ë‹¤ìŒ í…Œì´ë¸” í˜•íƒœì˜ ê²°ê³¼ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤: {table_json}"
            else:
                # ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë§Œ ì¶”ì¶œ
                cleaned_results = re.findall(r"\*\*ê²°ê³¼ \d+\*\*\s*\n\nğŸ“„ \*\*ì œëª©\*\*: (.*?)\n\nğŸ“ \*\*ë‚´ìš©\*\*: (.*?)(?=\n\nğŸ”—|\n\në” ê¶ê¸ˆí•œ)", context_result, re.DOTALL)
                context_desc = f"ì‚¬ìš©ìê°€ '{context_query}'ì— ëŒ€í•´ ì›¹ ê²€ìƒ‰ì„ í–ˆê³ , ë‹¤ìŒ ê²°ê³¼ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤:\n\n"
                for i, (title, content) in enumerate(cleaned_results, 1):
                    context_desc += f"{i}. ì œëª©: {title.strip()}\n   ë‚´ìš©: {content.strip()}\n\n"
                
                # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ URLì„ ì¶”ì¶œí•˜ì—¬ ì›¹í˜ì´ì§€ ìš”ì•½ ì œì•ˆ
                urls_in_context = extract_urls_from_text(context_result)
                logger.info(f"ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¶”ì¶œëœ URL ê°œìˆ˜: {len(urls_in_context)}")
                if urls_in_context:
                    context_desc += f"\n\nê²€ìƒ‰ ê²°ê³¼ì— ì´ {len(urls_in_context)}ê°œì˜ ë§í¬ê°€ ìˆìŠµë‹ˆë‹¤:\n"
                    for i, url in enumerate(urls_in_context, 1):
                        context_desc += f"{i}. {url}\n"
                    context_desc += "\níŠ¹ì • ë§í¬ì˜ ì „ì²´ ë‚´ìš©ì´ ê¶ê¸ˆí•˜ì‹œë©´ ë‹¤ìŒê³¼ ê°™ì´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”:\n"
                    context_desc += "- 'ì²« ë²ˆì§¸ ë§í¬ ìš”ì•½í•´ì¤˜' ë˜ëŠ” '3ë²ˆì§¸ ë§í¬ ìš”ì•½í•´ì¤˜'\n"
                    context_desc += "- 'URL + ìš”ì•½í•´ì¤˜' í˜•íƒœë¡œ ì§ì ‘ URL ì§€ì •"
        
        # ë‹¤ë¥¸ ìœ í˜•ì˜ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ (ì•½í’ˆ ì •ë³´, ë…¼ë¬¸ ë“±)
        elif context_type == "drug":
            context_desc = f"ì‚¬ìš©ìê°€ '{context_query}' ì•½í’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤. ì•½í’ˆ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."
        else:
            context_desc = f"ì‚¬ìš©ìê°€ '{context_query}'ì— ëŒ€í•´ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
        
        # ê³µí†µ ì§€ì‹œì‚¬í•­
        system_prompt = (
            "ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤. ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©: âœ…(ì™„ë£Œ), â“(ì§ˆë¬¸), ğŸ˜Š(ì¹œì ˆ).\n\n"
            f"{context_desc}\n\n"
            "ì‚¬ìš©ìì˜ í›„ì† ì§ˆë¬¸ì€ ì´ ê²€ìƒ‰ ê²°ê³¼ì— ê´€í•œ ê²ƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n"
            "ìš”ì•½ì„ ìš”ì²­ë°›ìœ¼ë©´ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ê³ , ì„¤ëª…ì„ ìš”ì²­ë°›ìœ¼ë©´ ë” ìì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.\n"
            "ê²€ìƒ‰ ê²°ê³¼ì— ê´€ë ¨ ì •ë³´ê°€ ì—†ë‹¤ë©´ ì •ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë‹µë³€í•˜ì„¸ìš”.\n"
            "ì‚¬ìš©ìê°€ 'ì²« ë²ˆì§¸ ë§í¬', '3ë²ˆì§¸ ë§í¬' ë“± ìˆœì„œë¡œ ë§í¬ë¥¼ ì–¸ê¸‰í•˜ë©´ í•´ë‹¹ ìˆœì„œì˜ ì›¹í˜ì´ì§€ ì „ì²´ ë‚´ìš©ì„ ìš”ì•½í•´ë“œë¦°ë‹¤ê³  ì•ˆë‚´í•˜ì„¸ìš”.\n"
            "URLì´ë‚˜ ë§í¬ì— ëŒ€í•œ ì§ˆë¬¸ì„ ë°›ìœ¼ë©´, í•´ë‹¹ ë§í¬ì˜ ì „ì²´ ë‚´ìš©ì„ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ 'ìˆœì„œ + ë§í¬ ìš”ì•½í•´ì¤˜' ë˜ëŠ” 'URL + ìš”ì•½í•´ì¤˜' í˜•íƒœë¡œ ì§ˆë¬¸í•˜ë¼ê³  ì•ˆë‚´í•´ì£¼ì„¸ìš”."
        )
        messages[0]["content"] = system_prompt
    
    # ìµœê·¼ ëŒ€í™” ê¸°ë¡ ì¶”ê°€
    messages.extend([{"role": msg["role"], "content": msg["content"]} 
                    for msg in chat_history[-4:] if "ë” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”?" not in msg["content"]])
    
    # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
    messages.append({"role": "user", "content": query})
    
    # ğŸ”´ ì„¸ì…˜ ìƒíƒœì˜ client ì‚¬ìš© (ìƒˆë¡œ ì„ íƒí•˜ì§€ ì•ŠìŒ)
    try:
        client = st.session_state.client
        logger.info(f"ê¸°ì¡´ ì„¸ì…˜ client ì‚¬ìš©: {st.session_state.provider_name}")
        
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None, lambda: client.chat.completions.create(
                model="gpt-4o-mini", messages=messages
            )
        )
        result = response.choices[0].message.content if response.choices else "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        logger.error(f"ëŒ€í™” ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        result = "ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    conversation_cache.setex(cache_key, 600, result)
    return result

GREETINGS = ["ì•ˆë…•", "í•˜ì´", "í—¬ë¡œ", "ã…ã…‡", "ì™“ì—…", "í• ë¡±", "í—¤ì´"]
GREETING_RESPONSE = "ì•ˆë…•í•˜ì„¸ìš”! ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š"

def process_query(query):
    cache_key = f"query:{hash(query)}"
    cached = cache_handler.get(cache_key)
    if cached is not None:
        return cached
    
    query_type = needs_search(query)
    query_lower = query.strip().lower().replace(" ", "")
    
    logger.info(f"ğŸ¯ ì¿¼ë¦¬ íƒ€ì…: {query_type}")
    
    # ğŸ”´ ì•½êµ­ ê²€ìƒ‰ ì¼€ì´ìŠ¤ ì¶”ê°€ (ìµœìš°ì„  ì²˜ë¦¬)
    if query_type == "pharmacy_search":
        result = drug_store_api.search_pharmacies(query)
        cache_handler.setex(cache_key, 600, result)
        return result
    
    # ğŸ”´ ë¬¸í™”í–‰ì‚¬ ê²€ìƒ‰ ì¼€ì´ìŠ¤ ì¶”ê°€
    elif query_type == "cultural_event":
        result = culture_event_api.search_cultural_events(query)
        cache_handler.setex(cache_key, 600, result)
        return result
    
    # ë‚ ì”¨ ê´€ë ¨ ì¿¼ë¦¬
    elif "ë‚ ì”¨" in query_lower:
        return weather_api.get_city_weather(extract_city_from_query(query))
    elif "ë‚´ì¼" in query_lower and "ë‚ ì”¨" in query_lower:
        return weather_api.get_forecast_by_day(extract_city_from_query(query), 1)
    
    # ì‹œê°„ ê´€ë ¨ ì¿¼ë¦¬
    elif "ì‹œê°„" in query_lower or "í˜„ì¬" in query_lower or "ë‚ ì§œ" in query_lower:
        if "ì˜¤ëŠ˜ë‚ ì§œ" in query_lower or "í˜„ì¬ë‚ ì§œ" in query_lower or "ê¸ˆì¼ë‚ ì§œ" in query_lower:
            return get_kst_time()
        else:
            city = extract_city_from_time_query(query)
            return get_time_by_city(city)
    
    # ì¶•êµ¬ ë¦¬ê·¸ ìˆœìœ„
    elif "ë¦¬ê·¸ìˆœìœ„" in query_lower:
        return football_api.fetch_league_standings(extract_league_from_query(query))
    # ì¶•êµ¬ ë“ì  ìˆœìœ„
    elif "ë“ì ìˆœìœ„" in query_lower:
        return football_api.fetch_league_scorers(extract_league_from_query(query))
    # ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ ê´€ë ¨
    elif "ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸" in query_lower or "ucl" in query_lower:
        return football_api.fetch_championsleague_knockout_matches()
    
    # ì•½í’ˆ ê²€ìƒ‰
    elif is_drug_inquiry(query):
        return drug_api.get_drug_info(query)
    
    # ë…¼ë¬¸ ê²€ìƒ‰
    elif "ë…¼ë¬¸" in query_lower:
        keywords = query.replace("ê³µí•™ë…¼ë¬¸", "").replace("arxiv", "").strip()
        return paper_search_api.get_arxiv_papers(keywords)
    
    elif query_type == "pubmed_search":
        keywords = query.replace("ì˜í•™ë…¼ë¬¸", "").strip()
        result = paper_search_api.get_pubmed_papers(keywords)
    elif query_type == "naver_search":
        # ì›¹ ê²€ìƒ‰ ì²˜ë¦¬ ë¡œì§ - ì§ì ‘ í˜¸ì¶œ (ì„¸ì…˜ ìƒíƒœ ì „ë‹¬ ë³´ì¥)
        logger.info(f"ë„¤ì´ë²„ ê²€ìƒ‰ ì§ì ‘ í˜¸ì¶œ: '{query}'")
        result = web_search_api.search_and_create_context(query, st.session_state)
        
        # ì»¨í…ìŠ¤íŠ¸ ì €ì¥ í™•ì¸ ë¡œê·¸
        logger.info(f"ê²€ìƒ‰ í›„ ì»¨í…ìŠ¤íŠ¸ ìƒíƒœ: {st.session_state.current_context}")
        if hasattr(st.session_state, 'search_contexts'):
            logger.info(f"ì €ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ìˆ˜: {len(st.session_state.search_contexts)}")
    elif query_type == "mbti":
        result = (
            "MBTI ê²€ì‚¬ë¥¼ ì›í•˜ì‹œë‚˜ìš”? âœ¨ ì•„ë˜ ì‚¬ì´íŠ¸ì—ì„œ ë¬´ë£Œë¡œ ì„±ê²© ìœ í˜• ê²€ì‚¬ë¥¼ í•  ìˆ˜ ìˆì–´ìš”! ğŸ˜Š\n"
            "[16Personalities MBTI ê²€ì‚¬](https://www.16personalities.com/ko/%EB%AC%B4%EB%A3%8C-%EC%84%B1%EA%B2%A9-%EC%9C%A0%ED%98%95-%EA%B2%80%EC%82%AC) ğŸŒŸ\n"
            "ì´ ì‚¬ì´íŠ¸ëŠ” 16ê°€ì§€ ì„±ê²© ìœ í˜•ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ í…ŒìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ë©°, ê²°ê³¼ì— ë”°ë¼ ì„±ê²© ì„¤ëª…ê³¼ ì¸ê°„ê´€ê³„ ì¡°ì–¸ ë“±ì„ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”! ğŸ’¡"
        )
    elif query_type == "mbti_types":
        specific_type = query_lower.replace("mbti", "").replace("ìœ í˜•", "").replace("ì„¤ëª…", "").strip().upper()
        if specific_type in mbti_descriptions:
            result = f"### ğŸ­ {specific_type} í•œ ì¤„ ì„¤ëª…\n- âœ… **{specific_type}** {mbti_descriptions[specific_type]}"
        else:
            result = mbti_full_description
    elif query_type == "multi_iq":
        result = (
            "ë‹¤ì¤‘ì§€ëŠ¥ ê²€ì‚¬ë¥¼ ì›í•˜ì‹œë‚˜ìš”? ğŸ‰ ì•„ë˜ ì‚¬ì´íŠ¸ì—ì„œ ë¬´ë£Œë¡œ ë‹¤ì¤‘ì§€ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³¼ ìˆ˜ ìˆì–´ìš”! ğŸ˜„\n"
            "[Multi IQ Test](https://multiiqtest.com/) ğŸš€\n"
            "ì´ ì‚¬ì´íŠ¸ëŠ” í•˜ì›Œë“œ ê°€ë“œë„ˆì˜ ë‹¤ì¤‘ì§€ëŠ¥ ì´ë¡ ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ í…ŒìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ë©°, ë‹¤ì–‘í•œ ì§€ëŠ¥ ì˜ì—­ì„ í‰ê°€í•´ì¤ë‹ˆë‹¤! ğŸ“šâœ¨"
        )
    elif query_type == "multi_iq_types":
        specific_type = query_lower.replace("ë‹¤ì¤‘ì§€ëŠ¥", "").replace("multi_iq", "").replace("ìœ í˜•", "").replace("ì„¤ëª…", "").strip().replace(" ", "")
        if specific_type in multi_iq_descriptions:
            result = f"### ğŸ¨ {specific_type.replace('ì§€ëŠ¥', ' ì§€ëŠ¥')} í•œ ì¤„ ì„¤ëª…\n- ğŸ“– **{specific_type.replace('ì§€ëŠ¥', ' ì§€ëŠ¥')}** {multi_iq_descriptions[specific_type]['description']}"
        else:
            result = multi_iq_full_description
    elif query_type == "multi_iq_jobs":
        specific_type = query_lower.replace("ë‹¤ì¤‘ì§€ëŠ¥", "").replace("multi_iq", "").replace("ì§ì—…", "").replace("ì¶”ì²œ", "").strip().replace(" ", "")
        if specific_type in multi_iq_descriptions:
            result = f"### ğŸ¨ {specific_type.replace('ì§€ëŠ¥', ' ì§€ëŠ¥')} ì¶”ì²œ ì§ì—…\n- ğŸ“– **{specific_type.replace('ì§€ëŠ¥', ' ì§€ëŠ¥')}**: {multi_iq_descriptions[specific_type]['description']}- **ì¶”ì²œ ì§ì—…**: {multi_iq_descriptions[specific_type]['jobs']}"
        else:
            result = multi_iq_full_description
    elif query_type == "multi_iq_full":
        result = multi_iq_full_description
    elif query_type == "conversation":
        if query_lower in GREETINGS:
            result = GREETING_RESPONSE
        else:
            result = asyncio.run(get_conversational_response(query, st.session_state.messages))
    else:
        result = "ì•„ì§ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê¸°ëŠ¥ì´ì—ìš”. ğŸ˜…"
    
    cache_handler.setex(cache_key, 600, result)
    return result

def get_kst_time():
    """KST ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    import pytz
    from datetime import datetime
    
    kst = pytz.timezone('Asia/Seoul')
    now = datetime.now(kst)
    return f"í˜„ì¬ í•œêµ­ ì‹œê°„: {now.strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')} ğŸ˜Š"

def get_time_by_city(city_name):
    """ë„ì‹œë³„ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # ë‚ ì”¨ APIì˜ ë„ì‹œ ê²€ìƒ‰ ê¸°ëŠ¥ í™œìš©
    try:
        city_info = weather_api.search_city_by_name(city_name)
        if city_info:
            import pytz
            from datetime import datetime
            
            # ì‹œê°„ëŒ€ ë§¤í•‘ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            timezone_map = {
                "KR": "Asia/Seoul",
                "US": "America/New_York", 
                "GB": "Europe/London",
                "JP": "Asia/Tokyo",
                "FR": "Europe/Paris",
                "DE": "Europe/Berlin"
            }
            
            country = city_info["country"]
            tz_name = timezone_map.get(country, "UTC")
            
            try:
                tz = pytz.timezone(tz_name)
                now = datetime.now(tz)
                return f"í˜„ì¬ {city_name} ì‹œê°„: {now.strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')} ğŸ˜Š"
            except:
                return f"{city_name}ì˜ ì‹œê°„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ˜“"
        else:
            return f"{city_name} ë„ì‹œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ˜“"
    except Exception as e:
        return f"{city_name}ì˜ ì‹œê°„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)} ğŸ˜“"

# ê¸°ì¡´ show_chat_dashboard í•¨ìˆ˜ ë‚´ì—ì„œ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë¶€ë¶„ ìˆ˜ì •
def show_chat_dashboard():
    st.title("Chat with AI ğŸ¤–")
    
    # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”ëŠ” init_session_state()ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨
    # ì¤‘ë³µ ì œê±°
    
    # ì‚¬ì´ë“œë°” ë„ì›€ë§ êµ¬ì„±
    with st.sidebar:
        st.header("ë„ì›€ë§ ğŸ“š")
        
        # ê¸°ë³¸ ê¸°ëŠ¥ ì•ˆë‚´
        with st.expander("ğŸŒŸ ê¸°ë³¸ ê¸°ëŠ¥"):
            st.markdown("""
            **ë‚ ì”¨ ì •ë³´** ğŸŒ¤ï¸
            - "ì„œìš¸ ë‚ ì”¨", "íŒŒë¦¬ ë‚ ì”¨ ì•Œë ¤ì¤˜"
            - "ë‚´ì¼ ì„œìš¸ ë‚ ì”¨", "ë‚´ì¼ ë‰´ìš• ë‚ ì”¨"
            
            **ì‹œê°„ ì •ë³´** ğŸ•’
            - "í˜„ì¬ ì‹œê°„", "ì˜¤ëŠ˜ ë‚ ì§œ"
            - "ëŸ°ë˜ ì‹œê°„", "íŒŒë¦¬ ì‹œê°„ ì•Œë ¤ì¤˜"
            
            **ì›¹ ê²€ìƒ‰** ğŸ”
            - "ChatGPT ì‚¬ìš©ë°©ë²• ê²€ìƒ‰í•´ì¤˜"
            - ê²€ìƒ‰ í›„ "3ë²ˆì§¸ ë§í¬ ìš”ì•½í•´ì¤˜"
            
            **ì›¹ í˜ì´ì§€ ìš”ì•½** ğŸ“ 
            - "https://www.aitimes.com ìš”ì•½í•´ì¤˜"
            
            """)
        
        # ì „ë¬¸ ì •ë³´ ì•ˆë‚´
        with st.expander("ğŸ¯ ì „ë¬¸ ì •ë³´"):
            st.markdown("""
            **ì˜ì•½í’ˆ ì •ë³´** ğŸ’Š
            - "ì•½í’ˆê²€ìƒ‰ íƒ€ì´ë ˆë†€", "ì•½í’ˆê²€ìƒ‰ ê²Œë³´ë¦°"
            - ì•½í’ˆëª…, ì œì¡°ì‚¬, íš¨ëŠ¥, ìš©ë²•ìš©ëŸ‰, ì£¼ì˜ì‚¬í•­ í™•ì¸ ê°€ëŠ¥
            
            **ì„œìš¸ì‹œ ì•½êµ­ ì •ë³´** ğŸ¥
            - "ê°•ë‚¨êµ¬ ì•½êµ­", "ì•½êµ­ ê²€ìƒ‰ ì„œì´ˆêµ¬"
            - ì•½êµ­ ìœ„ì¹˜, ìš´ì˜ì‹œê°„, ì—°ë½ì²˜ í™•ì¸ ê°€ëŠ¥
            
            **ë…¼ë¬¸ ê²€ìƒ‰** ğŸ“š
            - "ê³µí•™ë…¼ë¬¸ Transformers"
            - "ì˜í•™ë…¼ë¬¸ Gene Therapy"
            
            **ë¬¸í™”í–‰ì‚¬** ğŸ­
            - "ê°•ë‚¨êµ¬ ë¬¸í™”í–‰ì‚¬", "ë¬¸í™”í–‰ì‚¬"
            """)
        
        # ì¶•êµ¬ ì •ë³´ ì•ˆë‚´
        with st.expander("âš½ ì¶•êµ¬ ì •ë³´"):
            st.markdown("""
            **ë¦¬ê·¸ ìˆœìœ„** ğŸ†
            - "EPL ë¦¬ê·¸ìˆœìœ„", "ë¼ë¦¬ê°€ ë¦¬ê·¸ìˆœìœ„"
            - "ë¶„ë°ìŠ¤ë¦¬ê°€ ë¦¬ê·¸ìˆœìœ„", "ì„¸ë¦¬ì—A ë¦¬ê·¸ìˆœìœ„"
            
            **ë“ì  ìˆœìœ„** âš½
            - "EPL ë“ì ìˆœìœ„", "ë¼ë¦¬ê°€ ë“ì ìˆœìœ„"
            
            **ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸** ğŸ…
            - "ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ ë¦¬ê·¸ ìˆœìœ„", "UCL ë¦¬ê·¸ìˆœìœ„"
            - "ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ í† ë„ˆë¨¼íŠ¸"
            """)
        
        # ì„±ê²© ê²€ì‚¬ ì•ˆë‚´
        with st.expander("ğŸ§  ì„±ê²© ìœ í˜• ê²€ì‚¬"):
            st.markdown("""
            **MBTI** âœ¨
            - "MBTI ê²€ì‚¬", "MBTI ìœ í˜•", "MBTI ì„¤ëª…"
            - ì˜ˆ: "MBTI ê²€ì‚¬", "INTJ ì„¤ëª…"
            
            - "ê³µí•™ë…¼ë¬¸ Transformers"
            - "ì˜í•™ë…¼ë¬¸ Gene Therapy"
            
            **ë¬¸í™”í–‰ì‚¬** ğŸ­
            - "ê°•ë‚¨êµ¬ ë¬¸í™”í–‰ì‚¬", "ë¬¸í™”í–‰ì‚¬"
            """)
        
        # ì¶•êµ¬ ì •ë³´ ì•ˆë‚´
        with st.expander("âš½ ì¶•êµ¬ ì •ë³´"):
            st.markdown("""
            **ë¦¬ê·¸ ìˆœìœ„** ğŸ†
            - "EPL ë¦¬ê·¸ìˆœìœ„", "ë¼ë¦¬ê°€ ë¦¬ê·¸ìˆœìœ„"
            - "ë¶„ë°ìŠ¤ë¦¬ê°€ ë¦¬ê·¸ìˆœìœ„", "ì„¸ë¦¬ì—A ë¦¬ê·¸ìˆœìœ„"
            
            **ë“ì  ìˆœìœ„** âš½
            - "EPL ë“ì ìˆœìœ„", "ë¼ë¦¬ê°€ ë“ì ìˆœìœ„"
            
            **ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸** ğŸ…
            - "ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ ë¦¬ê·¸ ìˆœìœ„", "UCL ë¦¬ê·¸ìˆœìœ„"
            - "ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ í† ë„ˆë¨¼íŠ¸"
            """)
        
        # ì„±ê²© ê²€ì‚¬ ì•ˆë‚´
        with st.expander("ğŸ§  ì„±ê²© ìœ í˜• ê²€ì‚¬"):
            st.markdown("""
            **MBTI** âœ¨
            - "MBTI ê²€ì‚¬", "MBTI ìœ í˜•", "MBTI ì„¤ëª…"
            - ì˜ˆ: "MBTI ê²€ì‚¬", "INTJ ì„¤ëª…"
            
            **ë‹¤ì¤‘ì§€ëŠ¥** ğŸ‰
            - "ë‹¤ì¤‘ì§€ëŠ¥ ê²€ì‚¬", "ë‹¤ì¤‘ì§€ëŠ¥ ìœ í˜•", "ë‹¤ì¤‘ì§€ëŠ¥ ì§ì—…"
            - ì˜ˆ: "ë‹¤ì¤‘ì§€ëŠ¥ ê²€ì‚¬", "ì–¸ì–´ì§€ëŠ¥ ì§ì—…"
            """)
        
        # ì‚¬ìš© íŒ
        with st.expander("ğŸ’¡ ì‚¬ìš© íŒ"):
            st.markdown("""
            **ê²€ìƒ‰ í›„ í™œìš©** ğŸ”
            - ê²€ìƒ‰ í›„ "ìš”ì•½í•´ì¤˜"
            - "ì²« ë²ˆì§¸ ê²°ê³¼ ìì„¸íˆ ì„¤ëª…í•´ì¤˜"
            - "3ë²ˆì§¸ ë§í¬ ìš”ì•½í•´ì¤˜"
            
            **ëŒ€í™” ì—°ì†ì„±** ğŸ’¬
            - ì´ì „ ê²°ê³¼ì— ëŒ€í•œ ì¶”ê°€ ì§ˆë¬¸ ê°€ëŠ¥
            - ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ìƒì„¸ ì„¤ëª… ìš”ì²­
            
            **ì •í™•í•œ ê²€ìƒ‰** ğŸ¯
            - êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ ì‚¬ìš©
            - ë„ì‹œëª…ì€ í•œêµ­ì–´/ì˜ì–´ ëª¨ë‘ ê°€ëŠ¥
            """)
        
        # ì§€ì› ì–¸ì–´/ì§€ì—­
        with st.expander("ğŸŒ ì§€ì› ë²”ìœ„"):
            st.markdown("""
            **ë‚ ì”¨ ì§€ì›** ğŸŒ
            - ì „ì„¸ê³„ ì£¼ìš” ë„ì‹œ
            - í•œêµ­ì–´/ì˜ì–´ ë„ì‹œëª… ëª¨ë‘ ì§€ì›
            
            **ì¶•êµ¬ ë¦¬ê·¸** âš½
            - EPL, LaLiga, Bundesliga
            - SerieA, Ligue1, UEFA Champions League
            
            **ê²€ìƒ‰ ì–¸ì–´** ğŸ’¬
            - í•œêµ­ì–´ ìš°ì„  ì§€ì›
            - ì˜ì–´ ê²€ìƒ‰ ê°€ëŠ¥
            """)
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    display_chat_messages()
    handle_user_input()

def display_chat_messages():
    """ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ"""
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if isinstance(message["content"], dict) and "table" in message["content"]:
                st.markdown(message["content"]["header"])
                st.dataframe(message["content"]["table"])
                st.markdown(message["content"]["footer"])
            else:
                st.markdown(message["content"], unsafe_allow_html=True)

def handle_user_input():
    """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬"""
    if user_prompt := st.chat_input("ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!"):
        st.session_state.messages.append({"role": "user", "content": user_prompt})
        with st.chat_message("user"):
            st.markdown(user_prompt)

        with st.chat_message("assistant"):
            placeholder = st.empty()
            placeholder.markdown("ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤... ğŸ¤”")
            
            try:
                start_time = time.time()
                
                # í›„ì† ì§ˆë¬¸ì¸ì§€ í™•ì¸
                if is_followup_question(user_prompt) and st.session_state.current_context:
                    response = asyncio.run(get_conversational_response(user_prompt, st.session_state.messages))
                else:
                    if needs_search(user_prompt) is None:
                        st.session_state.current_context = None
                    response = process_query(user_prompt)
                
                end_time = time.time()
                time_taken = end_time - start_time
                
                placeholder.empty()
                
                if isinstance(response, dict) and "table" in response:
                    st.markdown(response["header"])
                    st.dataframe(response["table"])
                    st.markdown(response["footer"])
                else:
                    st.markdown(response, unsafe_allow_html=True)
                
                st.session_state.messages.append({"role": "assistant", "content": response})
                
                # ë¹„ë™ê¸°ë¡œ ì±„íŒ… ê¸°ë¡ ì €ì¥
                async_save_chat_history(
                    st.session_state.user_id,
                    st.session_state.session_id,
                    user_prompt,
                    response,
                    time_taken
                )
                
            except Exception as e:
                placeholder.empty()
                error_msg = f"ì‘ë‹µì„ ì¤€ë¹„í•˜ë‹¤ ë¬¸ì œ: {str(e)} ğŸ˜“"
                logger.error(f"ëŒ€í™” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
                st.markdown(error_msg, unsafe_allow_html=True)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})

def show_login_page():
    st.title("ë¡œê·¸ì¸ ğŸ¤—")
    
    # ğŸ”´ ë¡œê·¸ì¸ ì„±ê³µ ìƒíƒœ í‘œì‹œ
    if st.session_state.get('show_welcome'):
        st.success(f"í™˜ì˜í•©ë‹ˆë‹¤, {st.session_state.get('welcome_name', '')}ë‹˜! ğŸ‰")
        del st.session_state.show_welcome
        if 'welcome_name' in st.session_state:
            del st.session_state.welcome_name
    
    with st.form("login_form"):
        nickname = st.text_input("ë‹‰ë„¤ì„", placeholder="ì˜ˆ: í›„ì•ˆ")
        submit_button = st.form_submit_button("ì‹œì‘í•˜ê¸° ğŸš€")

        if submit_button and nickname:
            try:
                user_id, is_existing = create_or_get_user(nickname)
                st.session_state.user_id = user_id
                st.session_state.is_logged_in = True
                st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ë„ì›€ë§ë„ í™œìš©í•´ ë³´ì„¸ìš” ğŸ˜Š"}]
                st.session_state.session_id = str(uuid.uuid4())
                
                # ğŸ”´ ì„±ê³µ ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì €ì¥
                st.session_state.show_welcome = True
                st.session_state.welcome_name = nickname
                st.rerun()
            except Exception:
                st.error("ë¡œê·¸ì¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
def main():
    init_session_state()
    
    if not st.session_state.is_logged_in:
        show_login_page()
    else:
        show_chat_dashboard()

if __name__ == "__main__":
    main()