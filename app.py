# set lib
from config.imports import *
from config.env import *

# Import utils modules
from utils.webpage_analyzer import (
    fetch_webpage_content, 
    summarize_webpage_content, 
    extract_urls_from_text,
    is_url_summarization_request,
    is_numbered_link_request,
    is_followup_question
)
from utils.providers import (
    select_best_provider_with_priority,
    select_random_available_provider,
    get_client
)
from utils.query_analyzer import (
    needs_search,
    extract_city_from_query,
    extract_city_from_time_query,
    extract_league_from_query,
    is_drug_inquiry,
    extract_drug_name,
    is_paper_search,
    extract_keywords_for_paper_search,
    is_time_query,
    LEAGUE_MAPPING
)
# Import weather, football, drug, paper search, culture event, and web search modules
from utils.weather import WeatherAPI
from utils.football import FootballAPI
from utils.drug_info import DrugAPI
from utils.paper_search import PaperSearchAPI
from utils.culture_event import CultureEventAPI
from utils.web_search import WebSearchAPI

# set logger
logging.basicConfig(level=logging.WARNING if os.getenv("ENV") == "production" else logging.INFO)
logger = logging.getLogger("HybridChat")
logging.getLogger("streamlit").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)

# set cach
cache = Cache("cache_directory")

class MemoryCache:
    def __init__(self):
        self.cache = {}
        self.expiry = {}
    
    def get(self, key):
        if key in self.cache and time.time() < self.expiry[key]:
            return self.cache[key]
        return cache.get(key)
    
    def setex(self, key, ttl, value):
        self.cache[key] = value
        self.expiry[key] = time.time() + ttl
        cache.set(key, value, expire=ttl)

cache_handler = MemoryCache()

# ë‚ ì§œ ì¼ê´„ì  ìˆ˜ì • 
def format_date(fordate):
    if fordate == 'No date':
        return 'ë‚ ì§œ ì—†ìŒ'
    try:
        date_obj = datetime.strptime(fordate, '%Y %b %d')
        return date_obj.strftime('%Y.%m.%d')
    except ValueError:
        return fordate

# JSON íŒŒì¼ì—ì„œ MBTI ë° ë‹¤ì¤‘ì§€ëŠ¥ ë°ì´í„° ë¡œë“œ (ìºì‹± ì ìš©)
def load_personality_data():
    cache_key = "personality_data"
    cached_data = cache_handler.get(cache_key)
    if cached_data:
        return cached_data
    
    try:
        with open("config/personality_multi_data.json", "r", encoding="utf-8") as f:
            data = json.load(f)
        cache_handler.setex(cache_key, 86400, data)  # 24ì‹œê°„ ìºì‹±
        return data
    except FileNotFoundError:
        logger.error("personality_multi_data.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        raise
    except json.JSONDecodeError:
        logger.error("personality_multi_data.json íŒŒì¼ì˜ í˜•ì‹ì´ ìž˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
        raise

# ë°ì´í„° ë¡œë“œ
personality_data = load_personality_data()
mbti_descriptions = personality_data["mbti_descriptions"]
multi_iq_descriptions = personality_data["multi_iq_descriptions"]
mbti_full_description = personality_data["mbti_full_description"]
multi_iq_full_description = personality_data["multi_iq_full_description"]

# ì´ˆê¸°í™” - API í´ëž˜ìŠ¤ë“¤ì„ utilsì—ì„œ importí•˜ì—¬ ì‚¬ìš©
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
weather_api = WeatherAPI(cache_handler=cache_handler, WEATHER_API_KEY=WEATHER_API_KEY)
football_api = FootballAPI(api_key=SPORTS_API_KEY, cache_handler=cache_handler)
drug_api = DrugAPI(api_key=DRUG_API_KEY, cache_handler=cache_handler)
paper_search_api = PaperSearchAPI(ncbi_key=NCBI_KEY, cache_handler=cache_handler)
culture_event_api = CultureEventAPI(api_key=CULTURE_API_KEY, cache_handler=cache_handler)
web_search_api = WebSearchAPI(client_id=NAVER_CLIENT_ID, client_secret=NAVER_CLIENT_SECRET, cache_handler=cache_handler)  # ìƒˆë¡œ ì¶”ê°€

st.set_page_config(page_title="AI ì±—ë´‡", page_icon="ðŸ¤–")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ë¶€ë¶„ì— ê²€ìƒ‰ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
def init_session_state():
    if "is_logged_in" not in st.session_state:
        st.session_state.is_logged_in = False
    if "user_id" not in st.session_state:
        st.session_state.user_id = None
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?ðŸ˜Š"}]
    if "session_id" not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    if "client" not in st.session_state or "provider_name" not in st.session_state:
        client, provider_name = select_random_available_provider()
        st.session_state.client = client
        st.session_state.provider_name = provider_name
    # ê²€ìƒ‰ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ ì €ìž¥ì„ ìœ„í•œ ë³€ìˆ˜ ì¶”ê°€
    if "search_contexts" not in st.session_state:
        st.session_state.search_contexts = {}
    if "current_context" not in st.session_state:
        st.session_state.current_context = None

# ì‚¬ìš©ìž ë° ì±„íŒ… ê¸°ë¡ ê´€ë¦¬
def create_or_get_user(nickname):
    user = supabase.table("users").select("*").eq("nickname", nickname).execute()
    if user.data:
        return user.data[0]["id"], True
    new_user = supabase.table("users").insert({"nickname": nickname, "created_at": datetime.now().isoformat()}).execute()
    return new_user.data[0]["id"], False

def save_chat_history(user_id, session_id, question, answer, time_taken):
    if isinstance(answer, dict) and "table" in answer and isinstance(answer["table"], pd.DataFrame):
        answer_to_save = {
            "header": answer["header"],
            "table": answer["table"].to_dict(orient="records"),
            "footer": answer["footer"]
        }
    else:
        answer_to_save = answer
    
    supabase.table("chat_history").insert({
        "user_id": user_id,
        "session_id": session_id,
        "question": question,
        "answer": answer_to_save,
        "time_taken": time_taken,
        "created_at": datetime.now().isoformat()
    }).execute()

def async_save_chat_history(user_id, session_id, question, answer, time_taken):
    threading.Thread(target=save_chat_history, args=(user_id, session_id, question, answer, time_taken)).start()

# ëŒ€í™”í˜• ì‘ë‹µ (ë¹„ë™ê¸°)
conversation_cache = MemoryCache()
_client_instance = None

# ëŒ€í™”í˜• ì‘ë‹µ í•¨ìˆ˜ ìˆ˜ì •
async def get_conversational_response(query, chat_history):
    cache_key = f"conv:{needs_search(query)}:{query}"
    cached = conversation_cache.get(cache_key)
    if cached:
        return cached
    
    # í˜„ìž¬ ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    current_context = None
    if hasattr(st, 'session_state') and 'current_context' in st.session_state:
        current_context_id = st.session_state.current_context
        if current_context_id and current_context_id in st.session_state.search_contexts:
            current_context = st.session_state.search_contexts[current_context_id]
    
    # ìˆœì„œ ê¸°ë°˜ ë§í¬ ìš”ì²­ í™•ì¸ (ì˜ˆ: 3ë²ˆì§¸ ë§í¬ ìš”ì•½í•´ì¤˜)
    is_numbered_request, numbered_url = is_numbered_link_request(query, current_context)
    if is_numbered_request:
        summary = summarize_webpage_content(numbered_url, query)
        conversation_cache.setex(cache_key, 600, summary)
        return summary
    
    # ì¼ë°˜ URL ìš”ì•½ ìš”ì²­ í™•ì¸
    is_url_request, url = is_url_summarization_request(query)
    if is_url_request:
        # URL ìš”ì•½ ì²˜ë¦¬
        summary = summarize_webpage_content(url, query)
        conversation_cache.setex(cache_key, 600, summary)
        return summary
    
    messages = [
        {"role": "system", "content": "ì¹œì ˆí•œ AI ì±—ë´‡ìž…ë‹ˆë‹¤. ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©: âœ…(ì™„ë£Œ), â“(ì§ˆë¬¸), ðŸ˜Š(ì¹œì ˆ)"}
    ]
    
    # í˜„ìž¬ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ê°€ ìžˆëŠ”ì§€ í™•ì¸
    current_context = None
    if hasattr(st, 'session_state') and 'current_context' in st.session_state:
        current_context_id = st.session_state.current_context
        if current_context_id and current_context_id in st.session_state.search_contexts:
            current_context = st.session_state.search_contexts[current_context_id]
    
    # ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ê°€ ìžˆìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
    if current_context:
        context_type = current_context["type"]
        context_query = current_context["query"]
        context_result = current_context["result"]
        
        # ì»¨í…ìŠ¤íŠ¸ ìœ í˜•ì— ë”°ë¼ ë‹¤ë¥¸ ì§€ì‹œ ì¶”ê°€
        if context_type == "naver_search":
            # í…Œì´ë¸” ë°ì´í„°ì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(context_result, dict) and "table" in context_result:
                table_json = context_result["table"].to_json(orient="records")
                context_desc = f"ì‚¬ìš©ìžê°€ '{context_query}'ì— ëŒ€í•´ ê²€ìƒ‰í–ˆê³ , ë‹¤ìŒ í…Œì´ë¸” í˜•íƒœì˜ ê²°ê³¼ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤: {table_json}"
            else:
                # ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë§Œ ì¶”ì¶œ
                cleaned_results = re.findall(r"\*\*ê²°ê³¼ \d+\*\*\s*\n\nðŸ“„ \*\*ì œëª©\*\*: (.*?)\n\nðŸ“ \*\*ë‚´ìš©\*\*: (.*?)(?=\n\nðŸ”—|\n\në” ê¶ê¸ˆí•œ)", context_result, re.DOTALL)
                context_desc = f"ì‚¬ìš©ìžê°€ '{context_query}'ì— ëŒ€í•´ ì›¹ ê²€ìƒ‰ì„ í–ˆê³ , ë‹¤ìŒ ê²°ê³¼ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤:\n\n"
                for i, (title, content) in enumerate(cleaned_results, 1):
                    context_desc += f"{i}. ì œëª©: {title}\n   ë‚´ìš©: {content}\n\n"
                
                # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ URLì„ ì¶”ì¶œí•˜ì—¬ ì›¹íŽ˜ì´ì§€ ìš”ì•½ ì œì•ˆ
                urls_in_context = extract_urls_from_text(context_result)
                if urls_in_context:
                    context_desc += f"\n\nê²€ìƒ‰ ê²°ê³¼ì— ì´ {len(urls_in_context)}ê°œì˜ ë§í¬ê°€ ìžˆìŠµë‹ˆë‹¤.\n"
                    context_desc += "íŠ¹ì • ë§í¬ì˜ ì „ì²´ ë‚´ìš©ì´ ê¶ê¸ˆí•˜ì‹œë©´ ë‹¤ìŒê³¼ ê°™ì´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”:\n"
                    context_desc += "- 'ì²« ë²ˆì§¸ ë§í¬ ìš”ì•½í•´ì¤˜' ë˜ëŠ” '3ë²ˆì§¸ ë§í¬ ìš”ì•½í•´ì¤˜'\n"
                    context_desc += "- 'URL + ìš”ì•½í•´ì¤˜' í˜•íƒœë¡œ ì§ì ‘ URL ì§€ì •"
        
        # ë‹¤ë¥¸ ìœ í˜•ì˜ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ (ì•½í’ˆ ì •ë³´, ë…¼ë¬¸ ë“±)
        elif context_type == "drug":
            # ì•½í’ˆ ì •ë³´ì¼ ê²½ìš°
            context_desc = f"ì‚¬ìš©ìžê°€ '{context_query}' ì•½í’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤. ì•½í’ˆ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."
        
        # ê³µí†µ ì§€ì‹œì‚¬í•­
        system_prompt = (
            "ì¹œì ˆí•œ AI ì±—ë´‡ìž…ë‹ˆë‹¤. ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©: âœ…(ì™„ë£Œ), â“(ì§ˆë¬¸), ðŸ˜Š(ì¹œì ˆ).\n\n"
            f"{context_desc}\n\n"
            "ì‚¬ìš©ìžì˜ í›„ì† ì§ˆë¬¸ì€ ì´ ê²€ìƒ‰ ê²°ê³¼ì— ê´€í•œ ê²ƒì¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n"
            "ìš”ì•½ì„ ìš”ì²­ë°›ìœ¼ë©´ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ê³ , ì„¤ëª…ì„ ìš”ì²­ë°›ìœ¼ë©´ ë” ìžì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.\n"
            "ê²€ìƒ‰ ê²°ê³¼ì— ê´€ë ¨ ì •ë³´ê°€ ì—†ë‹¤ë©´ ì •ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë‹µë³€í•˜ì„¸ìš”.\n"
            "ì‚¬ìš©ìžê°€ 'ì²« ë²ˆì§¸ ë§í¬', '3ë²ˆì§¸ ë§í¬' ë“± ìˆœì„œë¡œ ë§í¬ë¥¼ ì–¸ê¸‰í•˜ë©´ í•´ë‹¹ ìˆœì„œì˜ ì›¹íŽ˜ì´ì§€ ì „ì²´ ë‚´ìš©ì„ ìš”ì•½í•´ë“œë¦°ë‹¤ê³  ì•ˆë‚´í•˜ì„¸ìš”.\n"
            "URLì´ë‚˜ ë§í¬ì— ëŒ€í•œ ì§ˆë¬¸ì„ ë°›ìœ¼ë©´, í•´ë‹¹ ë§í¬ì˜ ì „ì²´ ë‚´ìš©ì„ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ 'ìˆœì„œ + ë§í¬ ìš”ì•½í•´ì¤˜' ë˜ëŠ” 'URL + ìš”ì•½í•´ì¤˜' í˜•íƒœë¡œ ì§ˆë¬¸í•˜ë¼ê³  ì•ˆë‚´í•´ì£¼ì„¸ìš”."
        )
        messages[0]["content"] = system_prompt
    
    # ìµœê·¼ ëŒ€í™” ê¸°ë¡ ì¶”ê°€
    messages.extend([{"role": msg["role"], "content": msg["content"]} 
                    for msg in chat_history[-4:] if "ë” ê¶ê¸ˆí•œ ì  ìžˆë‚˜ìš”?" not in msg["content"]])
    
    # í˜„ìž¬ ì§ˆë¬¸ ì¶”ê°€
    messages.append({"role": "user", "content": query})
    
    # ë¹„ë™ê¸° ì‹¤í–‰ ì „ì— client ê°ì²´ë¥¼ ë¯¸ë¦¬ ê°€ì ¸ì˜´
    try:
        if not hasattr(st, 'session_state') or 'client' not in st.session_state:
            client, _ = select_random_available_provider()
        else:
            client = st.session_state.client
            
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None, lambda: client.chat.completions.create(
                model="gpt-4o-mini", messages=messages
            )
        )
        result = response.choices[0].message.content if response.choices else "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        logger.error(f"ëŒ€í™” ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        result = "ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    conversation_cache.setex(cache_key, 600, result)
    return result

GREETINGS = ["ì•ˆë…•", "í•˜ì´", "í—¬ë¡œ", "ã…Žã…‡", "ì™“ì—…", "í• ë¡±", "í—¤ì´"]
GREETING_RESPONSE = "ì•ˆë…•í•˜ì„¸ìš”! ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ðŸ˜Š"

def process_query(query):
    cache_key = f"query:{hash(query)}"
    cached = cache_handler.get(cache_key)
    if cached is not None:
        return cached
    
    query_type = needs_search(query)
    query_lower = query.strip().lower().replace(" ", "")
    
    with ThreadPoolExecutor() as executor:
        if query_type == "weather":
            future = executor.submit(weather_api.get_city_weather, extract_city_from_query(query))
            result = future.result()
        elif query_type == "tomorrow_weather":
            future = executor.submit(weather_api.get_forecast_by_day, extract_city_from_query(query), 1)
            result = future.result()
        elif query_type == "time":
            if "ì˜¤ëŠ˜ë‚ ì§œ" in query_lower or "í˜„ìž¬ë‚ ì§œ" in query_lower or "ê¸ˆì¼ë‚ ì§œ" in query_lower:
                result = get_kst_time()
            else:
                city = extract_city_from_time_query(query)
                future = executor.submit(get_time_by_city, city)
                result = future.result()
        elif query_type == "league_standings":
            league_key = extract_league_from_query(query)
            if league_key:
                league_info = LEAGUE_MAPPING[league_key]
                future = executor.submit(football_api.fetch_league_standings, league_info["code"], league_info["name"])
                result = future.result()
                result = result["error"] if "error" in result else {
                    "header": f"{result['league_name']} ë¦¬ê·¸ ìˆœìœ„",
                    "table": result["data"],
                    "footer": "ë” ê¶ê¸ˆí•œ ì  ìžˆë‚˜ìš”? ðŸ˜Š"
                }
            else:
                result = "ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¦¬ê·¸ìž…ë‹ˆë‹¤. ðŸ˜“ ì§€ì› ë¦¬ê·¸: EPL, LaLiga, Bundesliga, Serie A, Ligue 1"
        elif query_type == "league_scorers":
            league_key = extract_league_from_query(query)
            if league_key:
                league_info = LEAGUE_MAPPING[league_key]
                future = executor.submit(football_api.fetch_league_scorers, league_info["code"], league_info["name"])
                try:
                    result = future.result()
                    result = result["error"] if "error" in result else {
                        "header": f"{result['league_name']} ë¦¬ê·¸ ë“ì ìˆœìœ„ (ìƒìœ„ 10ëª…)",
                        "table": result["data"],
                        "footer": "ë” ê¶ê¸ˆí•œ ì  ìžˆë‚˜ìš”? ðŸ˜Š"
                    }
                except Exception as e:
                    result = f"ë¦¬ê·¸ ë“ì ìˆœìœ„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)} ðŸ˜“"
            else:
                result = "ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¦¬ê·¸ìž…ë‹ˆë‹¤. ðŸ˜“ ì§€ì› ë¦¬ê·¸: EPL, LaLiga, Bundesliga, Serie A, Ligue 1"
        elif query_type == "cl_knockout":
            try:
                future = executor.submit(football_api.fetch_championsleague_knockout_matches)
                results = future.result()
                if isinstance(results, str):  # ì—ëŸ¬ ë©”ì‹œì§€ì¸ ê²½ìš°
                    result = results
                elif not results:
                    result = "ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ í† ë„ˆë¨¼íŠ¸ ê²½ê¸° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
                else:
                    df = pd.DataFrame(results)
                    result = {
                        "header": "ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ Knockout Stage ê²°ê³¼",
                        "table": df,
                        "footer": "ë” ê¶ê¸ˆí•œ ì  ìžˆë‚˜ìš”? ðŸ˜Š"
                    }
            except Exception as e:
                result = f"ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ í† ë„ˆë¨¼íŠ¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)} ðŸ˜“"
        elif query_type == "cultural_event":
            # ë¬¸í™”í–‰ì‚¬ ì²˜ë¦¬ ë¡œì§ - ìˆ˜ì •ëœ ë¶€ë¶„
            future = executor.submit(culture_event_api.search_cultural_events, query)
            result = future.result()
        elif query_type == "drug":
            future = executor.submit(drug_api.get_drug_info, query)  # ìˆ˜ì •ëœ ë¶€ë¶„
            result = future.result()
        elif query_type == "arxiv_search":
            keywords = query.replace("ê³µí•™ë…¼ë¬¸", "").replace("arxiv", "").strip()
            future = executor.submit(paper_search_api.get_arxiv_papers, keywords)  # ìˆ˜ì •ëœ ë¶€ë¶„
            result = future.result()
        elif query_type == "pubmed_search":
            keywords = query.replace("ì˜í•™ë…¼ë¬¸", "").strip()
            future = executor.submit(paper_search_api.get_pubmed_papers, keywords)  # ìˆ˜ì •ëœ ë¶€ë¶„
            result = future.result()
        elif query_type == "naver_search":
            # ì›¹ ê²€ìƒ‰ ì²˜ë¦¬ ë¡œì§ - ìˆ˜ì •ëœ ë¶€ë¶„
            future = executor.submit(web_search_api.search_and_create_context, query, st.session_state)
            result = future.result()
        elif query_type == "mbti":
            result = (
                "MBTI ê²€ì‚¬ë¥¼ ì›í•˜ì‹œë‚˜ìš”? âœ¨ ì•„ëž˜ ì‚¬ì´íŠ¸ì—ì„œ ë¬´ë£Œë¡œ ì„±ê²© ìœ í˜• ê²€ì‚¬ë¥¼ í•  ìˆ˜ ìžˆì–´ìš”! ðŸ˜Š\n"
                "[16Personalities MBTI ê²€ì‚¬](https://www.16personalities.com/ko/%EB%AC%B4%EB%A3%8C-%EC%84%B1%EA%B2%A9-%EC%9C%A0%ED%98%95-%EA%B2%80%EC%82%AC) ðŸŒŸ\n"
                "ì´ ì‚¬ì´íŠ¸ëŠ” 16ê°€ì§€ ì„±ê²© ìœ í˜•ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ í…ŒìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ë©°, ê²°ê³¼ì— ë”°ë¼ ì„±ê²© ì„¤ëª…ê³¼ ì¸ê°„ê´€ê³„ ì¡°ì–¸ ë“±ì„ í™•ì¸í•  ìˆ˜ ìžˆì–´ìš”! ðŸ’¡"
            )
        elif query_type == "mbti_types":
            specific_type = query_lower.replace("mbti", "").replace("ìœ í˜•", "").replace("ì„¤ëª…", "").strip().upper()
            if specific_type in mbti_descriptions:
                result = f"### ðŸŽ­ {specific_type} í•œ ì¤„ ì„¤ëª…\n- âœ… **{specific_type}** {mbti_descriptions[specific_type]}"
            else:
                result = mbti_full_description
        elif query_type == "multi_iq":
            result = (
                "ë‹¤ì¤‘ì§€ëŠ¥ ê²€ì‚¬ë¥¼ ì›í•˜ì‹œë‚˜ìš”? ðŸŽ‰ ì•„ëž˜ ì‚¬ì´íŠ¸ì—ì„œ ë¬´ë£Œë¡œ ë‹¤ì¤‘ì§€ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³¼ ìˆ˜ ìžˆì–´ìš”! ðŸ˜„\n"
                "[Multi IQ Test](https://multiiqtest.com/) ðŸš€\n"
                "ì´ ì‚¬ì´íŠ¸ëŠ” í•˜ì›Œë“œ ê°€ë“œë„ˆì˜ ë‹¤ì¤‘ì§€ëŠ¥ ì´ë¡ ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ í…ŒìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ë©°, ë‹¤ì–‘í•œ ì§€ëŠ¥ ì˜ì—­ì„ í‰ê°€í•´ì¤ë‹ˆë‹¤! ðŸ“šâœ¨"
            )
        elif query_type == "multi_iq_types":
            specific_type = query_lower.replace("ë‹¤ì¤‘ì§€ëŠ¥", "").replace("multi_iq", "").replace("ìœ í˜•", "").replace("ì„¤ëª…", "").strip().replace(" ", "")
            if specific_type in multi_iq_descriptions:
                result = f"### ðŸŽ¨ {specific_type.replace('ì§€ëŠ¥', ' ì§€ëŠ¥')} í•œ ì¤„ ì„¤ëª…\n- ðŸ“– **{specific_type.replace('ì§€ëŠ¥', ' ì§€ëŠ¥')}** {multi_iq_descriptions[specific_type]['description']}"
            else:
                result = multi_iq_full_description
        elif query_type == "multi_iq_jobs":
            specific_type = query_lower.replace("ë‹¤ì¤‘ì§€ëŠ¥", "").replace("multi_iq", "").replace("ì§ì—…", "").replace("ì¶”ì²œ", "").strip().replace(" ", "")
            if specific_type in multi_iq_descriptions:
                result = f"### ðŸŽ¨ {specific_type.replace('ì§€ëŠ¥', ' ì§€ëŠ¥')} ì¶”ì²œ ì§ì—…\n- ðŸ“– **{specific_type.replace('ì§€ëŠ¥', ' ì§€ëŠ¥')}**: {multi_iq_descriptions[specific_type]['description']}- **ì¶”ì²œ ì§ì—…**: {multi_iq_descriptions[specific_type]['jobs']}"
            else:
                result = multi_iq_full_description
        elif query_type == "multi_iq_full":
            result = multi_iq_full_description
        elif query_type == "conversation":
            if query_lower in GREETINGS:
                result = GREETING_RESPONSE
            else:
                result = asyncio.run(get_conversational_response(query, st.session_state.messages))
        else:
            result = "ì•„ì§ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê¸°ëŠ¥ì´ì—ìš”. ðŸ˜…"
        
        cache_handler.setex(cache_key, 600, result)
        return result

# ê¸°ì¡´ show_chat_dashboard í•¨ìˆ˜ ë‚´ì—ì„œ ì‚¬ìš©ìž ìž…ë ¥ ì²˜ë¦¬ ë¶€ë¶„ ìˆ˜ì •
def show_chat_dashboard():
    st.title("Chat with AI ðŸ¤–")
    
    # ê²€ìƒ‰ í†µê³„ í‘œì‹œ (ì‚¬ì´ë“œë°”ì— ì¶”ê°€ ê°€ëŠ¥)
    with st.sidebar:
        if st.button("ê²€ìƒ‰ í†µê³„ ðŸ“Š"):
            stats = web_search_api.get_search_stats()
            st.info(f"ðŸ” **ê²€ìƒ‰ í†µê³„**\n\n"
                   f"â€¢ ì‚¬ìš©: {stats['request_count']}/{stats['daily_limit']}\n"
                   f"â€¢ ë‚¨ì€ íšŸìˆ˜: {stats['remaining']}\n"
                   f"â€¢ ì‚¬ìš©ë¥ : {stats['usage_percentage']}%")
    
    if st.button("ë„ì›€ë§ â„¹ï¸"):
        st.info(
            "ì±—ë´‡ê³¼ ë” ì‰½ê²Œ ëŒ€í™”í•˜ëŠ” ë°©ë²•ì´ì—ìš”! :\n"
            "1. **ë‚ ì”¨** â˜€ï¸: '[ë„ì‹œëª…] ë‚ ì”¨' (ì˜ˆ: ì„œìš¸ ë‚ ì”¨, ë‚´ì¼ ì„œìš¸ ë‚ ì”¨)\n"
            "2. **ì‹œê°„/ë‚ ì§œ** â±ï¸: '[ë„ì‹œëª…] ì‹œê°„' ë˜ëŠ” 'ì˜¤ëŠ˜ ë‚ ì§œ' (ì˜ˆ: ë§ˆë“œë¦¬ë“œ ì‹œê°„, ê¸ˆì¼ ë‚ ì§œ)\n"
            "3. **ê²€ìƒ‰** ðŸŒ: '[í‚¤ì›Œë“œ] ê²€ìƒ‰í•´' ë˜ëŠ” '[í‚¤ì›Œë“œ] ê²€ìƒ‰í•´ì¤˜' (ì˜ˆ: 2025ë…„ ì„œìš¸ ì „ì‹œíšŒ ê²€ìƒ‰í•´ì¤˜)\n"
            "   - ðŸ”— **ê²€ìƒ‰ í›„ ë§í¬ ë¶„ì„**: 'ì²« ë²ˆì§¸ ë§í¬ ìš”ì•½í•´ì¤˜', '3ë²ˆì§¸ ê²°ê³¼ ë¶„ì„í•´ì¤˜'\n"
            "4. **ì›¹íŽ˜ì´ì§€ ì§ì ‘ ë¶„ì„** ðŸ“„: 'URL ìš”ì•½í•´ì¤˜' ë˜ëŠ” 'URL ë¶„ì„í•´ì¤˜'\n"
            "   - ì˜ˆ: 'https://example.com ìš”ì•½í•´ì¤˜', 'https://deepmind.google/models/gemini/flash/ ë¶„ì„í•´ì¤˜'\n"
            "5. **ì•½í’ˆê²€ìƒ‰** ðŸ’Š: 'ì•½í’ˆê²€ìƒ‰ [ì•½ ì´ë¦„]' (ì˜ˆ: ì•½í’ˆê²€ìƒ‰ ê²Œë³´ë¦°)\n"
            "6. **ê³µí•™ë…¼ë¬¸** ðŸ“š: 'ê³µí•™ë…¼ë¬¸ [í‚¤ì›Œë“œ]' (ì˜ˆ: ê³µí•™ë…¼ë¬¸ Multimodal AI)\n"
            "7. **ì˜í•™ë…¼ë¬¸** ðŸ©º: 'ì˜í•™ë…¼ë¬¸ [í‚¤ì›Œë“œ]' (ì˜ˆ: ì˜í•™ë…¼ë¬¸ cancer therapy)\n"
            "8. **ì¶•êµ¬ ë¦¬ê·¸ ì •ë³´** âš½: '[ë¦¬ê·¸ ì´ë¦„] ë¦¬ê·¸ ìˆœìœ„ ë˜ëŠ” ë¦¬ê·¸ë“ì ìˆœìœ„' (ì˜ˆ: EPL ë¦¬ê·¸ìˆœìœ„, EPL ë¦¬ê·¸ë“ì ìˆœìœ„)\n"
            "   - ì§€ì› ë¦¬ê·¸: EPL, LaLiga, Bundesliga, Serie A, Ligue 1, ChampionsLeague\n"
            "   - **ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ ë¦¬ê·¸ ë‹¨ê³„**: 'ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ ë¦¬ê·¸ ìˆœìœ„' ë˜ëŠ” 'UCL ë¦¬ê·¸ìˆœìœ„'ë¡œ í™•ì¸\n"
            "   - **ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ í† ë„ˆë¨¼íŠ¸**: 'ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ í† ë„ˆë¨¼íŠ¸' ë˜ëŠ” 'UCL 16ê°•'(ì˜ˆ: ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸ 16ê°•)\n"
            "9. **MBTI** âœ¨: 'MBTI ê²€ì‚¬',  'MBTI ìœ í˜•', 'MBTI ì„¤ëª…' (ì˜ˆ: MBTI ê²€ì‚¬, INTJ ì„¤ëª…)\n"
            "10. **ë‹¤ì¤‘ì§€ëŠ¥** ðŸŽ‰: 'ë‹¤ì¤‘ì§€ëŠ¥ ê²€ì‚¬', 'ë‹¤ì¤‘ì§€ëŠ¥ ìœ í˜•', 'ë‹¤ì¤‘ì§€ëŠ¥ ì§ì—…', (ì˜ˆ: ë‹¤ì¤‘ì§€ëŠ¥ ê²€ì‚¬, ì–¸ì–´ì§€ëŠ¥ ì§ì—…)\n"
            "11. **ë¬¸í™”í–‰ì‚¬** ðŸŽ­: '[ì§€ì—­êµ¬] ë¬¸í™”í–‰ì‚¬' ë˜ëŠ” 'ë¬¸í™”í–‰ì‚¬' (ì˜ˆ: ê°•ë‚¨êµ¬ ë¬¸í™”í–‰ì‚¬, ë¬¸í™”í–‰ì‚¬)\n\n"
            "ðŸŒŸ **ê³ ê¸‰ ê¸°ëŠ¥**:\n"
            "- ê²€ìƒ‰ í›„ í›„ì† ì§ˆë¬¸ìœ¼ë¡œ íŠ¹ì • ë§í¬ì˜ ì „ì²´ ë‚´ìš© ë¶„ì„ ê°€ëŠ¥\n"
            "- ì›¹íŽ˜ì´ì§€ URLì„ ì§ì ‘ ì œê³µí•˜ì—¬ ë‚´ìš© ìš”ì•½/ë¶„ì„ ê°€ëŠ¥\n"
            "- ë©€í‹°í„´ ëŒ€í™”ë¡œ ì´ì „ ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ ì¶”ê°€ ì§ˆë¬¸ ê°€ëŠ¥\n\n"
            "ê¶ê¸ˆí•œ ì  ìžˆìœ¼ë©´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”! ðŸ˜Š"
        )
   
    for msg in st.session_state.messages[-10:]:
        with st.chat_message(msg['role']):
            if isinstance(msg['content'], dict) and "table" in msg['content']:
                st.markdown(f"### {msg['content']['header']}")
                st.dataframe(pd.DataFrame(msg['content']['table']), use_container_width=True, hide_index=True)
                st.markdown(msg['content']['footer'])
            else:
                st.markdown(msg['content'], unsafe_allow_html=True)
    
    if user_prompt := st.chat_input("ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!"):
        st.chat_message("user").markdown(user_prompt)
        st.session_state.messages.append({"role": "user", "content": user_prompt})
        
        with st.chat_message("assistant"):
            placeholder = st.empty()
            placeholder.markdown("ì‘ë‹µì„ ì¤€ë¹„ ì¤‘ì´ì—ìš”.. â³")
            try:
                start_time = time.time()
                
                # í›„ì† ì§ˆë¬¸ì¸ì§€ í™•ì¸
                if is_followup_question(user_prompt) and st.session_state.current_context:
                    # í›„ì† ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨ë˜ë©´ ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€í•˜ê³  LLMì— ì „ë‹¬
                    response = asyncio.run(get_conversational_response(user_prompt, st.session_state.messages))
                else:
                    # ìƒˆë¡œìš´ ì§ˆë¬¸ì´ë©´ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”í•˜ê³  ì¼ë°˜ ì²˜ë¦¬
                    if needs_search(user_prompt) is None:
                        st.session_state.current_context = None
                    response = process_query(user_prompt)
                
                time_taken = round(time.time() - start_time, 2)
                
                # ë¡œë”© ë©”ì‹œì§€ ì œê±°
                placeholder.empty()
                
                if isinstance(response, dict) and "table" in response:
                    st.markdown(f"### {response['header']}")
                    st.dataframe(response['table'], use_container_width=True, hide_index=True)
                    st.markdown(response['footer'])
                else:
                    st.markdown(response, unsafe_allow_html=True)
                
                st.session_state.messages.append({"role": "assistant", "content": response})
                async_save_chat_history(st.session_state.user_id, st.session_state.session_id, user_prompt, response, time_taken)
            
            except Exception as e:
                placeholder.empty()
                error_msg = f"ì‘ë‹µì„ ì¤€ë¹„í•˜ë‹¤ ë¬¸ì œ: {str(e)} ðŸ˜“"
                logger.error(f"ëŒ€í™” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
                st.markdown(error_msg, unsafe_allow_html=True)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})

def show_login_page():
    st.title("ë¡œê·¸ì¸ ðŸ¤—")
    with st.form("login_form"):
        nickname = st.text_input("ë‹‰ë„¤ìž„", placeholder="ì˜ˆ: í›„ì•ˆ")
        submit_button = st.form_submit_button("ì‹œìž‘í•˜ê¸° ðŸš€")

        if submit_button and nickname:
            try:
                user_id, is_existing = create_or_get_user(nickname)
                st.session_state.user_id = user_id
                st.session_state.is_logged_in = True
                st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ë„ì›€ë§ë„ í™œìš©í•´ ë³´ì„¸ìš” ðŸ˜Š"}]
                st.session_state.session_id = str(uuid.uuid4())
                st.toast(f"í™˜ì˜í•©ë‹ˆë‹¤, {nickname}ë‹˜! ðŸŽ‰")
                time.sleep(1)
                st.rerun()
            except Exception:
                st.toast("ë¡œê·¸ì¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", icon="âŒ")

# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
def main():
    init_session_state()
    
    if not st.session_state.is_logged_in:
        show_login_page()
    else:
        show_chat_dashboard()

if __name__ == "__main__":
    main()