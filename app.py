# set lib
from config.imports import *
from config.env import *
# from streamlit.runtime.scriptrunner import add_script_run_ctx

# Import utils modules
from utils.webpage_analyzer import (
    fetch_webpage_content, 
    summarize_webpage_content, 
    extract_urls_from_text,
    is_url_summarization_request,
    is_numbered_link_request,
    is_followup_question
)
from utils.providers import (
    select_best_provider_with_priority,
    select_random_available_provider,
    get_client
)
from utils.query_analyzer import (
    needs_search,
    extract_city_from_query,
    extract_city_from_time_query,
    extract_league_from_query,
    is_drug_inquiry,
    extract_drug_name,
    is_paper_search,
    extract_keywords_for_paper_search,
    is_time_query,
    LEAGUE_MAPPING
)
# Import weather, football, drug, paper search, culture event, and web search modules
from utils.weather import WeatherAPI
from utils.football import FootballAPI
from utils.drug_info import DrugAPI
from utils.paper_search import PaperSearchAPI
from utils.culture_event import CultureEventAPI
from utils.web_search import WebSearchAPI

# set logger
logging.basicConfig(level=logging.INFO)  # ÎîîÎ≤ÑÍπÖÏùÑ ÏúÑÌï¥ INFO Î†àÎ≤®Î°ú Î≥ÄÍ≤Ω
logger = logging.getLogger("HybridChat")
logging.getLogger("streamlit").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)

# set cach
cache = Cache("cache_directory")

class MemoryCache:
    def __init__(self):
        self.cache = {}
        self.expiry = {}
    
    def get(self, key):
        if key in self.cache and time.time() < self.expiry[key]:
            return self.cache[key]
        return cache.get(key)
    
    def setex(self, key, ttl, value):
        self.cache[key] = value
        self.expiry[key] = time.time() + ttl
        cache.set(key, value, expire=ttl)

cache_handler = MemoryCache()

# ÎÇ†Ïßú ÏùºÍ¥ÑÏ†Å ÏàòÏ†ï 
def format_date(fordate):
    if fordate == 'No date':
        return 'ÎÇ†Ïßú ÏóÜÏùå'
    try:
        date_obj = datetime.strptime(fordate, '%Y %b %d')
        return date_obj.strftime('%Y.%m.%d')
    except ValueError:
        return fordate

# JSON ÌååÏùºÏóêÏÑú MBTI Î∞è Îã§Ï§ëÏßÄÎä• Îç∞Ïù¥ÌÑ∞ Î°úÎìú (Ï∫êÏã± Ï†ÅÏö©)
def load_personality_data():
    cache_key = "personality_data"
    cached_data = cache_handler.get(cache_key)
    if cached_data:
        return cached_data
    
    try:
        with open("config/personality_multi_data.json", "r", encoding="utf-8") as f:
            data = json.load(f)
        cache_handler.setex(cache_key, 86400, data)  # 24ÏãúÍ∞Ñ Ï∫êÏã±
        return data
    except FileNotFoundError:
        logger.error("personality_multi_data.json ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
        raise
    except json.JSONDecodeError:
        logger.error("personality_multi_data.json ÌååÏùºÏùò ÌòïÏãùÏù¥ ÏûòÎ™ªÎêòÏóàÏäµÎãàÎã§.")
        raise

# Îç∞Ïù¥ÌÑ∞ Î°úÎìú
personality_data = load_personality_data()
mbti_descriptions = personality_data["mbti_descriptions"]
multi_iq_descriptions = personality_data["multi_iq_descriptions"]
mbti_full_description = personality_data["mbti_full_description"]
multi_iq_full_description = personality_data["multi_iq_full_description"]

# Ï¥àÍ∏∞Ìôî - API ÌÅ¥ÎûòÏä§Îì§ÏùÑ utilsÏóêÏÑú importÌïòÏó¨ ÏÇ¨Ïö©
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
weather_api = WeatherAPI(cache_handler=cache_handler, WEATHER_API_KEY=WEATHER_API_KEY)
football_api = FootballAPI(api_key=SPORTS_API_KEY, cache_handler=cache_handler)
drug_api = DrugAPI(api_key=DRUG_API_KEY, cache_handler=cache_handler)
paper_search_api = PaperSearchAPI(ncbi_key=NCBI_KEY, cache_handler=cache_handler)
culture_event_api = CultureEventAPI(api_key=CULTURE_API_KEY, cache_handler=cache_handler)
web_search_api = WebSearchAPI(client_id=NAVER_CLIENT_ID, client_secret=NAVER_CLIENT_SECRET, cache_handler=cache_handler)  # ÏÉàÎ°ú Ï∂îÍ∞Ä

st.set_page_config(page_title="AI Ï±óÎ¥á", page_icon="ü§ñ")

# ÏÑ∏ÏÖò ÏÉÅÌÉú Ï¥àÍ∏∞Ìôî Î∂ÄÎ∂ÑÏóê Í≤ÄÏÉâ Í≤∞Í≥º Ïª®ÌÖçÏä§Ìä∏ Ï∂îÍ∞Ä
def init_session_state():
    if "is_logged_in" not in st.session_state:
        st.session_state.is_logged_in = False
    if "user_id" not in st.session_state:
        st.session_state.user_id = None
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "ÏïàÎÖïÌïòÏÑ∏Ïöî! Î¨¥ÏóáÏùÑ ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî?üòä"}]
    if "session_id" not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    if "client" not in st.session_state or "provider_name" not in st.session_state:
        client, provider_name = select_random_available_provider()
        st.session_state.client = client
        st.session_state.provider_name = provider_name
    # Í≤ÄÏÉâ Í≤∞Í≥º Ïª®ÌÖçÏä§Ìä∏ Ï†ÄÏû•ÏùÑ ÏúÑÌïú Î≥ÄÏàò Ï∂îÍ∞Ä
    if "search_contexts" not in st.session_state:
        st.session_state.search_contexts = {}
    if "current_context" not in st.session_state:
        st.session_state.current_context = None

# ÏÇ¨Ïö©Ïûê Î∞è Ï±ÑÌåÖ Í∏∞Î°ù Í¥ÄÎ¶¨
def create_or_get_user(nickname):
    user = supabase.table("users").select("*").eq("nickname", nickname).execute()
    if user.data:
        return user.data[0]["id"], True
    new_user = supabase.table("users").insert({"nickname": nickname, "created_at": datetime.now().isoformat()}).execute()
    return new_user.data[0]["id"], False

def save_chat_history(user_id, session_id, question, answer, time_taken):
    if isinstance(answer, dict) and "table" in answer and isinstance(answer["table"], pd.DataFrame):
        answer_to_save = {
            "header": answer["header"],
            "table": answer["table"].to_dict(orient="records"),
            "footer": answer["footer"]
        }
    else:
        answer_to_save = answer
    
    supabase.table("chat_history").insert({
        "user_id": user_id,
        "session_id": session_id,
        "question": question,
        "answer": answer_to_save,
        "time_taken": time_taken,
        "created_at": datetime.now().isoformat()
    }).execute()

def async_save_chat_history(user_id, session_id, question, answer, time_taken):
    threading.Thread(target=save_chat_history, args=(user_id, session_id, question, answer, time_taken)).start()

# ÎåÄÌôîÌòï ÏùëÎãµ (ÎπÑÎèôÍ∏∞)
conversation_cache = MemoryCache()
_client_instance = None

# ÎåÄÌôîÌòï ÏùëÎãµ Ìï®Ïàò ÏàòÏ†ï
async def get_conversational_response(query, chat_history):
    logger.info(f"ÎåÄÌôîÌòï ÏùëÎãµ ÏãúÏûë - ÏøºÎ¶¨: '{query}'")
    logger.info(f"ÏÑ∏ÏÖò ÏÉÅÌÉú ÌôïÏù∏: {hasattr(st, 'session_state')}")
    if hasattr(st, 'session_state'):
        logger.info(f"current_context: {getattr(st.session_state, 'current_context', 'None')}")
        logger.info(f"search_contexts ÌÇ§ Ïàò: {len(getattr(st.session_state, 'search_contexts', {}))}")
    
    cache_key = f"conv:{needs_search(query)}:{query}"
    cached = conversation_cache.get(cache_key)
    if cached:
        return cached
    
    # ÌòÑÏû¨ Í≤ÄÏÉâ Ïª®ÌÖçÏä§Ìä∏ Í∞ÄÏ†∏Ïò§Í∏∞
    current_context = None
    if hasattr(st, 'session_state') and 'current_context' in st.session_state:
        current_context_id = st.session_state.current_context
        if current_context_id and current_context_id in st.session_state.search_contexts:
            current_context = st.session_state.search_contexts[current_context_id]
    
    # ÎîîÎ≤ÑÍπÖ Î°úÍ∑∏ Ï∂îÍ∞Ä
    logger.info(f"ÌòÑÏû¨ Ïª®ÌÖçÏä§Ìä∏ Ï°¥Ïû¨: {current_context is not None}")
    if current_context:
        logger.info(f"Ïª®ÌÖçÏä§Ìä∏ ÌÉÄÏûÖ: {current_context.get('type')}")
        logger.info(f"Ïª®ÌÖçÏä§Ìä∏ Í≤∞Í≥º Í∏∏Ïù¥: {len(str(current_context.get('result', '')))}")
    
    # ÏàúÏÑú Í∏∞Î∞ò ÎßÅÌÅ¨ ÏöîÏ≤≠ ÌôïÏù∏ (Ïòà: 3Î≤àÏß∏ ÎßÅÌÅ¨ ÏöîÏïΩÌï¥Ï§ò)
    try:
        is_numbered_request, numbered_url = is_numbered_link_request(query, current_context)
        logger.info(f"ÏàúÏÑú Í∏∞Î∞ò ÏöîÏ≤≠: {is_numbered_request}, URL: {numbered_url}")
        
        if is_numbered_request and numbered_url:
            try:
                logger.info(f"ÏõπÌéòÏù¥ÏßÄ ÏöîÏïΩ ÏãúÏûë: {numbered_url}")
                summary = summarize_webpage_content(numbered_url, query)
                conversation_cache.setex(cache_key, 600, summary)
                return summary
            except Exception as e:
                logger.error(f"ÏõπÌéòÏù¥ÏßÄ ÏöîÏïΩ Ïò§Î•ò: {str(e)}")
                return f"Ìï¥Îãπ ÎßÅÌÅ¨Ïùò ÎÇ¥Ïö©ÏùÑ Í∞ÄÏ†∏Ïò¨ Ïàò ÏóÜÏäµÎãàÎã§: {str(e)} üòì"
        
        # ÏùºÎ∞ò URL ÏöîÏïΩ ÏöîÏ≤≠ ÌôïÏù∏
        is_url_request, url = is_url_summarization_request(query)
        logger.info(f"URL ÏöîÏïΩ ÏöîÏ≤≠: {is_url_request}, URL: {url}")
        
        if is_url_request and url:
            try:
                logger.info(f"ÏßÅÏ†ë URL ÏöîÏïΩ ÏãúÏûë: {url}")
                summary = summarize_webpage_content(url, query)
                conversation_cache.setex(cache_key, 600, summary)
                return summary
            except Exception as e:
                logger.error(f"URL ÏöîÏïΩ Ïò§Î•ò: {str(e)}")
                return f"Ìï¥Îãπ ÎßÅÌÅ¨Ïùò ÎÇ¥Ïö©ÏùÑ Í∞ÄÏ†∏Ïò¨ Ïàò ÏóÜÏäµÎãàÎã§: {str(e)} üòì"
    
    except Exception as e:
        logger.error(f"ÎßÅÌÅ¨ ÏöîÏïΩ Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {str(e)}")
        # ÎßÅÌÅ¨ ÏöîÏïΩ Ïò§Î•ò ÏãúÏóêÎèÑ ÏùºÎ∞ò ÎåÄÌôîÎäî Í≥ÑÏÜç ÏßÑÌñâ
    
    # ÏùºÎ∞ò ÎåÄÌôî Ï≤òÎ¶¨
    messages = [
        {"role": "system", "content": "ÏπúÏ†àÌïú AI Ï±óÎ¥áÏûÖÎãàÎã§. Ï†ÅÏ†àÌïú Ïù¥Î™®ÏßÄ ÏÇ¨Ïö©: ‚úÖ(ÏôÑÎ£å), ‚ùì(ÏßàÎ¨∏), üòä(ÏπúÏ†à)"}
    ]
    
    # Í≤ÄÏÉâ Ïª®ÌÖçÏä§Ìä∏Í∞Ä ÏûàÏúºÎ©¥ ÏãúÏä§ÌÖú ÌîÑÎ°¨ÌîÑÌä∏Ïóê Ï∂îÍ∞Ä
    if current_context:
        context_type = current_context["type"]
        context_query = current_context["query"]
        context_result = current_context["result"]
        
        # Ïª®ÌÖçÏä§Ìä∏ Ïú†ÌòïÏóê Îî∞Îùº Îã§Î•∏ ÏßÄÏãú Ï∂îÍ∞Ä
        if context_type == "naver_search":
            # ÌÖåÏù¥Î∏î Îç∞Ïù¥ÌÑ∞Ïù∏ Í≤ΩÏö∞ Ï≤òÎ¶¨
            if isinstance(context_result, dict) and "table" in context_result:
                table_json = context_result["table"].to_json(orient="records")
                context_desc = f"ÏÇ¨Ïö©ÏûêÍ∞Ä '{context_query}'Ïóê ÎåÄÌï¥ Í≤ÄÏÉâÌñàÍ≥†, Îã§Ïùå ÌÖåÏù¥Î∏î ÌòïÌÉúÏùò Í≤∞Í≥ºÎ•º Î∞õÏïòÏäµÎãàÎã§: {table_json}"
            else:
                # Ï†ïÍ∑ú ÌëúÌòÑÏãùÏúºÎ°ú Ïõπ Í≤ÄÏÉâ Í≤∞Í≥ºÎßå Ï∂îÏ∂ú
                cleaned_results = re.findall(r"\*\*Í≤∞Í≥º \d+\*\*\s*\n\nüìÑ \*\*Ï†úÎ™©\*\*: (.*?)\n\nüìù \*\*ÎÇ¥Ïö©\*\*: (.*?)(?=\n\nüîó|\n\nÎçî Í∂ÅÍ∏àÌïú)", context_result, re.DOTALL)
                context_desc = f"ÏÇ¨Ïö©ÏûêÍ∞Ä '{context_query}'Ïóê ÎåÄÌï¥ Ïõπ Í≤ÄÏÉâÏùÑ ÌñàÍ≥†, Îã§Ïùå Í≤∞Í≥ºÎ•º Î∞õÏïòÏäµÎãàÎã§:\n\n"
                for i, (title, content) in enumerate(cleaned_results, 1):
                    context_desc += f"{i}. Ï†úÎ™©: {title.strip()}\n   ÎÇ¥Ïö©: {content.strip()}\n\n"
                
                # Í≤ÄÏÉâ Í≤∞Í≥ºÏóêÏÑú URLÏùÑ Ï∂îÏ∂úÌïòÏó¨ ÏõπÌéòÏù¥ÏßÄ ÏöîÏïΩ Ï†úÏïà
                urls_in_context = extract_urls_from_text(context_result)
                logger.info(f"Í≤ÄÏÉâ Í≤∞Í≥ºÏóêÏÑú Ï∂îÏ∂úÎêú URL Í∞úÏàò: {len(urls_in_context)}")
                if urls_in_context:
                    context_desc += f"\n\nÍ≤ÄÏÉâ Í≤∞Í≥ºÏóê Ï¥ù {len(urls_in_context)}Í∞úÏùò ÎßÅÌÅ¨Í∞Ä ÏûàÏäµÎãàÎã§:\n"
                    for i, url in enumerate(urls_in_context, 1):
                        context_desc += f"{i}. {url}\n"
                    context_desc += "\nÌäπÏ†ï ÎßÅÌÅ¨Ïùò Ï†ÑÏ≤¥ ÎÇ¥Ïö©Ïù¥ Í∂ÅÍ∏àÌïòÏãúÎ©¥ Îã§ÏùåÍ≥º Í∞ôÏù¥ ÏßàÎ¨∏Ìï¥Ï£ºÏÑ∏Ïöî:\n"
                    context_desc += "- 'Ï≤´ Î≤àÏß∏ ÎßÅÌÅ¨ ÏöîÏïΩÌï¥Ï§ò' ÎòêÎäî '3Î≤àÏß∏ ÎßÅÌÅ¨ ÏöîÏïΩÌï¥Ï§ò'\n"
                    context_desc += "- 'URL + ÏöîÏïΩÌï¥Ï§ò' ÌòïÌÉúÎ°ú ÏßÅÏ†ë URL ÏßÄÏ†ï"
        
        # Îã§Î•∏ Ïú†ÌòïÏùò Ïª®ÌÖçÏä§Ìä∏ Ï≤òÎ¶¨ (ÏïΩÌíà Ï†ïÎ≥¥, ÎÖºÎ¨∏ Îì±)
        elif context_type == "drug":
            context_desc = f"ÏÇ¨Ïö©ÏûêÍ∞Ä '{context_query}' ÏïΩÌíàÏóê ÎåÄÌïú Ï†ïÎ≥¥Î•º Í≤ÄÏÉâÌñàÏäµÎãàÎã§. ÏïΩÌíà Ï†ïÎ≥¥Î•º Í∏∞Î∞òÏúºÎ°ú ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏Ïóê ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî."
        else:
            context_desc = f"ÏÇ¨Ïö©ÏûêÍ∞Ä '{context_query}'Ïóê ÎåÄÌï¥ Í≤ÄÏÉâÌñàÏäµÎãàÎã§."
        
        # Í≥µÌÜµ ÏßÄÏãúÏÇ¨Ìï≠
        system_prompt = (
            "ÏπúÏ†àÌïú AI Ï±óÎ¥áÏûÖÎãàÎã§. Ï†ÅÏ†àÌïú Ïù¥Î™®ÏßÄ ÏÇ¨Ïö©: ‚úÖ(ÏôÑÎ£å), ‚ùì(ÏßàÎ¨∏), üòä(ÏπúÏ†à).\n\n"
            f"{context_desc}\n\n"
            "ÏÇ¨Ïö©ÏûêÏùò ÌõÑÏÜç ÏßàÎ¨∏ÏùÄ Ïù¥ Í≤ÄÏÉâ Í≤∞Í≥ºÏóê Í¥ÄÌïú Í≤ÉÏùº Ïàò ÏûàÏäµÎãàÎã§. Í≤ÄÏÉâ Í≤∞Í≥ºÏùò ÎÇ¥Ïö©ÏùÑ Í∏∞Î∞òÏúºÎ°ú ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.\n"
            "ÏöîÏïΩÏùÑ ÏöîÏ≤≠Î∞õÏúºÎ©¥ Ï§ëÏöîÌïú Ï†ïÎ≥¥Î•º Í∞ÑÍ≤∞ÌïòÍ≤å ÏöîÏïΩÌïòÍ≥†, ÏÑ§Î™ÖÏùÑ ÏöîÏ≤≠Î∞õÏúºÎ©¥ Îçî ÏûêÏÑ∏Ìïú Ï†ïÎ≥¥Î•º Ï†úÍ≥µÌïòÏÑ∏Ïöî.\n"
            "Í≤ÄÏÉâ Í≤∞Í≥ºÏóê Í¥ÄÎ†® Ï†ïÎ≥¥Í∞Ä ÏóÜÎã§Î©¥ Ï†ïÏßÅÌïòÍ≤å Î™®Î•∏Îã§Í≥† ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.\n"
            "ÏÇ¨Ïö©ÏûêÍ∞Ä 'Ï≤´ Î≤àÏß∏ ÎßÅÌÅ¨', '3Î≤àÏß∏ ÎßÅÌÅ¨' Îì± ÏàúÏÑúÎ°ú ÎßÅÌÅ¨Î•º Ïñ∏Í∏âÌïòÎ©¥ Ìï¥Îãπ ÏàúÏÑúÏùò ÏõπÌéòÏù¥ÏßÄ Ï†ÑÏ≤¥ ÎÇ¥Ïö©ÏùÑ ÏöîÏïΩÌï¥ÎìúÎ¶∞Îã§Í≥† ÏïàÎÇ¥ÌïòÏÑ∏Ïöî.\n"
            "URLÏù¥ÎÇò ÎßÅÌÅ¨Ïóê ÎåÄÌïú ÏßàÎ¨∏ÏùÑ Î∞õÏúºÎ©¥, Ìï¥Îãπ ÎßÅÌÅ¨Ïùò Ï†ÑÏ≤¥ ÎÇ¥Ïö©ÏùÑ ÌôïÏù∏ÌïòÍ≥† Ïã∂Îã§Î©¥ 'ÏàúÏÑú + ÎßÅÌÅ¨ ÏöîÏïΩÌï¥Ï§ò' ÎòêÎäî 'URL + ÏöîÏïΩÌï¥Ï§ò' ÌòïÌÉúÎ°ú ÏßàÎ¨∏ÌïòÎùºÍ≥† ÏïàÎÇ¥Ìï¥Ï£ºÏÑ∏Ïöî."
        )
        messages[0]["content"] = system_prompt
    
    # ÏµúÍ∑º ÎåÄÌôî Í∏∞Î°ù Ï∂îÍ∞Ä
    messages.extend([{"role": msg["role"], "content": msg["content"]} 
                    for msg in chat_history[-4:] if "Îçî Í∂ÅÍ∏àÌïú Ï†ê ÏûàÎÇòÏöî?" not in msg["content"]])
    
    # ÌòÑÏû¨ ÏßàÎ¨∏ Ï∂îÍ∞Ä
    messages.append({"role": "user", "content": query})
    
    # ÎπÑÎèôÍ∏∞ Ïã§Ìñâ Ï†ÑÏóê client Í∞ùÏ≤¥Î•º ÎØ∏Î¶¨ Í∞ÄÏ†∏Ïò¥
    try:
        if not hasattr(st, 'session_state') or 'client' not in st.session_state:
            client, _ = select_random_available_provider()
        else:
            client = st.session_state.client
            
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None, lambda: client.chat.completions.create(
                model="gpt-4o-mini", messages=messages
            )
        )
        result = response.choices[0].message.content if response.choices else "ÏùëÎãµÏùÑ ÏÉùÏÑ±Ìï† Ïàò ÏóÜÏäµÎãàÎã§."
    except Exception as e:
        logger.error(f"ÎåÄÌôî ÏùëÎãµ ÏÉùÏÑ± Ï§ë Ïò§Î•ò: {str(e)}", exc_info=True)
        result = "ÏùëÎãµÏùÑ ÏÉùÏÑ±ÌïòÎäî Ï§ë Î¨∏Ï†úÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§."
    
    conversation_cache.setex(cache_key, 600, result)
    return result

GREETINGS = ["ÏïàÎÖï", "ÌïòÏù¥", "Ìó¨Î°ú", "„Öé„Öá", "ÏôìÏóÖ", "Ìï†Î°±", "Ìó§Ïù¥"]
GREETING_RESPONSE = "ÏïàÎÖïÌïòÏÑ∏Ïöî! Î∞òÍ∞ëÏäµÎãàÎã§. Î¨¥ÏóáÏùÑ ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî? üòä"

def process_query(query):
    cache_key = f"query:{hash(query)}"
    cached = cache_handler.get(cache_key)
    if cached is not None:
        return cached
    
    query_type = needs_search(query)
    query_lower = query.strip().lower().replace(" ", "")
    
    with ThreadPoolExecutor() as executor:
        if query_type == "weather":
            future = executor.submit(weather_api.get_city_weather, extract_city_from_query(query))
            result = future.result()
        elif query_type == "tomorrow_weather":
            future = executor.submit(weather_api.get_forecast_by_day, extract_city_from_query(query), 1)
            result = future.result()
        elif query_type == "time":
            if "Ïò§ÎäòÎÇ†Ïßú" in query_lower or "ÌòÑÏû¨ÎÇ†Ïßú" in query_lower or "Í∏àÏùºÎÇ†Ïßú" in query_lower:
                result = get_kst_time()
            else:
                city = extract_city_from_time_query(query)
                future = executor.submit(get_time_by_city, city)
                result = future.result()
        elif query_type == "league_standings":
            league_key = extract_league_from_query(query)
            if league_key:
                league_info = LEAGUE_MAPPING[league_key]
                future = executor.submit(football_api.fetch_league_standings, league_info["code"], league_info["name"])
                result = future.result()
                result = result["error"] if "error" in result else {
                    "header": f"{result['league_name']} Î¶¨Í∑∏ ÏàúÏúÑ",
                    "table": result["data"],
                    "footer": "Îçî Í∂ÅÍ∏àÌïú Ï†ê ÏûàÎÇòÏöî? üòä"
                }
            else:
                result = "ÏßÄÏõêÌïòÏßÄ ÏïäÎäî Î¶¨Í∑∏ÏûÖÎãàÎã§. üòì ÏßÄÏõê Î¶¨Í∑∏: EPL, LaLiga, Bundesliga, Serie A, Ligue 1"
        elif query_type == "league_scorers":
            league_key = extract_league_from_query(query)
            if league_key:
                league_info = LEAGUE_MAPPING[league_key]
                future = executor.submit(football_api.fetch_league_scorers, league_info["code"], league_info["name"])
                try:
                    result = future.result()
                    result = result["error"] if "error" in result else {
                        "header": f"{result['league_name']} Î¶¨Í∑∏ ÎìùÏ†êÏàúÏúÑ (ÏÉÅÏúÑ 10Î™Ö)",
                        "table": result["data"],
                        "footer": "Îçî Í∂ÅÍ∏àÌïú Ï†ê ÏûàÎÇòÏöî? üòä"
                    }
                except Exception as e:
                    result = f"Î¶¨Í∑∏ ÎìùÏ†êÏàúÏúÑ Ï°∞Ìöå Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)} üòì"
            else:
                result = "ÏßÄÏõêÌïòÏßÄ ÏïäÎäî Î¶¨Í∑∏ÏûÖÎãàÎã§. üòì ÏßÄÏõê Î¶¨Í∑∏: EPL, LaLiga, Bundesliga, Serie A, Ligue 1"
        elif query_type == "cl_knockout":
            try:
                future = executor.submit(football_api.fetch_championsleague_knockout_matches)
                results = future.result()
                if isinstance(results, str):
                    result = results
                elif not results:
                    result = "Ï±îÌîºÏñ∏Ïä§Î¶¨Í∑∏ ÌÜ†ÎÑàÎ®ºÌä∏ Í≤ΩÍ∏∞ Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§."
                else:
                    df = pd.DataFrame(results)
                    result = {
                        "header": "Ï±îÌîºÏñ∏Ïä§Î¶¨Í∑∏ Knockout Stage Í≤∞Í≥º",
                        "table": df,
                        "footer": "Îçî Í∂ÅÍ∏àÌïú Ï†ê ÏûàÎÇòÏöî? üòä"
                    }
            except Exception as e:
                result = f"Ï±îÌîºÏñ∏Ïä§Î¶¨Í∑∏ ÌÜ†ÎÑàÎ®ºÌä∏ Ï°∞Ìöå Ï§ë Ïò§Î•ò: {str(e)} üòì"
        elif query_type == "cultural_event":
            future = executor.submit(culture_event_api.search_cultural_events, query)
            result = future.result()
        elif query_type == "drug":
            future = executor.submit(drug_api.get_drug_info, query)
            result = future.result()
        elif query_type == "arxiv_search":
            keywords = query.replace("Í≥µÌïôÎÖºÎ¨∏", "").replace("arxiv", "").strip()
            future = executor.submit(paper_search_api.get_arxiv_papers, keywords)
            result = future.result()
        elif query_type == "pubmed_search":
            keywords = query.replace("ÏùòÌïôÎÖºÎ¨∏", "").strip()
            future = executor.submit(paper_search_api.get_pubmed_papers, keywords)
            result = future.result()
        elif query_type == "naver_search":
            # Ïõπ Í≤ÄÏÉâ Ï≤òÎ¶¨ Î°úÏßÅ
            future = executor.submit(web_search_api.search_and_create_context, query, st.session_state)
            result = future.result()
            
            # Ïª®ÌÖçÏä§Ìä∏ Ï†ÄÏû• ÌôïÏù∏ Î°úÍ∑∏
            logger.info(f"Í≤ÄÏÉâ ÌõÑ Ïª®ÌÖçÏä§Ìä∏ ÏÉÅÌÉú: {st.session_state.current_context}")
            if hasattr(st.session_state, 'search_contexts'):
                logger.info(f"Ï†ÄÏû•Îêú Ïª®ÌÖçÏä§Ìä∏ Ïàò: {len(st.session_state.search_contexts)}")
        elif query_type == "mbti":
            result = (
                "MBTI Í≤ÄÏÇ¨Î•º ÏõêÌïòÏãúÎÇòÏöî? ‚ú® ÏïÑÎûò ÏÇ¨Ïù¥Ìä∏ÏóêÏÑú Î¨¥Î£åÎ°ú ÏÑ±Í≤© Ïú†Ìòï Í≤ÄÏÇ¨Î•º Ìï† Ïàò ÏûàÏñ¥Ïöî! üòä\n"
                "[16Personalities MBTI Í≤ÄÏÇ¨](https://www.16personalities.com/ko/%EB%AC%B4%EB%A3%8C-%EC%84%B1%EA%B2%A9-%EC%9C%A0%ED%98%95-%EA%B2%80%EC%82%AC) üåü\n"
                "Ïù¥ ÏÇ¨Ïù¥Ìä∏Îäî 16Í∞ÄÏßÄ ÏÑ±Í≤© Ïú†ÌòïÏùÑ Í∏∞Î∞òÏúºÎ°ú Ìïú ÌÖåÏä§Ìä∏Î•º Ï†úÍ≥µÌïòÎ©∞, Í≤∞Í≥ºÏóê Îî∞Îùº ÏÑ±Í≤© ÏÑ§Î™ÖÍ≥º Ïù∏Í∞ÑÍ¥ÄÍ≥Ñ Ï°∞Ïñ∏ Îì±ÏùÑ ÌôïÏù∏Ìï† Ïàò ÏûàÏñ¥Ïöî! üí°"
            )
        elif query_type == "mbti_types":
            specific_type = query_lower.replace("mbti", "").replace("Ïú†Ìòï", "").replace("ÏÑ§Î™Ö", "").strip().upper()
            if specific_type in mbti_descriptions:
                result = f"### üé≠ {specific_type} Ìïú Ï§Ñ ÏÑ§Î™Ö\n- ‚úÖ **{specific_type}** {mbti_descriptions[specific_type]}"
            else:
                result = mbti_full_description
        elif query_type == "multi_iq":
            result = (
                "Îã§Ï§ëÏßÄÎä• Í≤ÄÏÇ¨Î•º ÏõêÌïòÏãúÎÇòÏöî? üéâ ÏïÑÎûò ÏÇ¨Ïù¥Ìä∏ÏóêÏÑú Î¨¥Î£åÎ°ú Îã§Ï§ëÏßÄÎä• ÌÖåÏä§Ìä∏Î•º Ìï¥Î≥º Ïàò ÏûàÏñ¥Ïöî! üòÑ\n"
                "[Multi IQ Test](https://multiiqtest.com/) üöÄ\n"
                "Ïù¥ ÏÇ¨Ïù¥Ìä∏Îäî ÌïòÏõåÎìú Í∞ÄÎìúÎÑàÏùò Îã§Ï§ëÏßÄÎä• Ïù¥Î°†ÏùÑ Í∏∞Î∞òÏúºÎ°ú Ìïú ÌÖåÏä§Ìä∏Î•º Ï†úÍ≥µÌïòÎ©∞, Îã§ÏñëÌïú ÏßÄÎä• ÏòÅÏó≠ÏùÑ ÌèâÍ∞ÄÌï¥Ï§çÎãàÎã§! üìö‚ú®"
            )
        elif query_type == "multi_iq_types":
            specific_type = query_lower.replace("Îã§Ï§ëÏßÄÎä•", "").replace("multi_iq", "").replace("Ïú†Ìòï", "").replace("ÏÑ§Î™Ö", "").strip().replace(" ", "")
            if specific_type in multi_iq_descriptions:
                result = f"### üé® {specific_type.replace('ÏßÄÎä•', ' ÏßÄÎä•')} Ìïú Ï§Ñ ÏÑ§Î™Ö\n- üìñ **{specific_type.replace('ÏßÄÎä•', ' ÏßÄÎä•')}** {multi_iq_descriptions[specific_type]['description']}"
            else:
                result = multi_iq_full_description
        elif query_type == "multi_iq_jobs":
            specific_type = query_lower.replace("Îã§Ï§ëÏßÄÎä•", "").replace("multi_iq", "").replace("ÏßÅÏóÖ", "").replace("Ï∂îÏ≤ú", "").strip().replace(" ", "")
            if specific_type in multi_iq_descriptions:
                result = f"### üé® {specific_type.replace('ÏßÄÎä•', ' ÏßÄÎä•')} Ï∂îÏ≤ú ÏßÅÏóÖ\n- üìñ **{specific_type.replace('ÏßÄÎä•', ' ÏßÄÎä•')}**: {multi_iq_descriptions[specific_type]['description']}- **Ï∂îÏ≤ú ÏßÅÏóÖ**: {multi_iq_descriptions[specific_type]['jobs']}"
            else:
                result = multi_iq_full_description
        elif query_type == "multi_iq_full":
            result = multi_iq_full_description
        elif query_type == "conversation":
            if query_lower in GREETINGS:
                result = GREETING_RESPONSE
            else:
                result = asyncio.run(get_conversational_response(query, st.session_state.messages))
        else:
            result = "ÏïÑÏßÅ ÏßÄÏõêÌïòÏßÄ ÏïäÎäî Í∏∞Îä•Ïù¥ÏóêÏöî. üòÖ"
        
        cache_handler.setex(cache_key, 600, result)
        return result

# Í∏∞Ï°¥ show_chat_dashboard Ìï®Ïàò ÎÇ¥ÏóêÏÑú ÏÇ¨Ïö©Ïûê ÏûÖÎ†• Ï≤òÎ¶¨ Î∂ÄÎ∂Ñ ÏàòÏ†ï
def show_chat_dashboard():
    st.title("Chat with AI ü§ñ")
    
    # Í≤ÄÏÉâ Ïª®ÌÖçÏä§Ìä∏ Ï†ÄÏû•ÏùÑ ÏúÑÌïú Î≥ÄÏàò Ï∂îÍ∞Ä
    if "search_contexts" not in st.session_state:
        st.session_state.search_contexts = {}
    if "current_context" not in st.session_state:
        st.session_state.current_context = None
    
    # ÏÇ¨Ïù¥ÎìúÎ∞îÏóê ÎèÑÏõÄÎßê Ï∂îÍ∞Ä
    with st.sidebar:
        st.header("ÎèÑÏõÄÎßê üìö")
        
        # Í∏∞Î≥∏ Í∏∞Îä• ÏïàÎÇ¥
        with st.expander("üåü Í∏∞Î≥∏ Í∏∞Îä•"):
            st.markdown("""
            **ÎÇ†Ïî® Ï†ïÎ≥¥** üå§Ô∏è
            - "ÏÑúÏö∏ ÎÇ†Ïî®", "ÌååÎ¶¨ ÎÇ†Ïî® ÏïåÎ†§Ï§ò"
            - "ÎÇ¥Ïùº ÏÑúÏö∏ ÎÇ†Ïî®", "Îâ¥Ïöï ÎÇ¥Ïùº ÎÇ†Ïî®"
            
            **ÏãúÍ∞Ñ Ï†ïÎ≥¥** üïí
            - "ÌòÑÏû¨ ÏãúÍ∞Ñ", "Ïò§Îäò ÎÇ†Ïßú"
            - "Îü∞Îçò ÏãúÍ∞Ñ", "ÎèÑÏøÑ ÏãúÍ∞Ñ ÏïåÎ†§Ï§ò"
            
            **Ïõπ Í≤ÄÏÉâ** üîç
            - "ChatGPT Í≤ÄÏÉâ", "ÌååÏù¥Ïç¨ Í≤ÄÏÉâ"
            - Í≤ÄÏÉâ ÌõÑ "3Î≤àÏß∏ ÎßÅÌÅ¨ ÏöîÏïΩÌï¥Ï§ò"
            """)
        
        # Ï†ÑÎ¨∏ Ï†ïÎ≥¥ ÏïàÎÇ¥
        with st.expander("üéØ Ï†ÑÎ¨∏ Ï†ïÎ≥¥"):
            st.markdown("""
            **ÏùòÏïΩÌíà Ï†ïÎ≥¥** üíä
            - "ÌÉÄÏù¥Î†àÎÜÄ Ìö®Îä•", "ÏïÑÏä§ÌîºÎ¶∞ Î∂ÄÏûëÏö©"
            
            **ÎÖºÎ¨∏ Í≤ÄÏÉâ** üìö
            - "Ïù∏Í≥µÏßÄÎä• Í≥µÌïôÎÖºÎ¨∏"
            - "ÎãπÎá®Î≥ë ÏùòÌïôÎÖºÎ¨∏"
            
            **Î¨∏ÌôîÌñâÏÇ¨** üé≠
            - "ÏÑúÏö∏ Î¨∏ÌôîÌñâÏÇ¨", "Ïù¥Î≤à Ï£º Í≥µÏó∞"
            """)
        
        # Ï∂ïÍµ¨ Ï†ïÎ≥¥ ÏïàÎÇ¥
        with st.expander("‚öΩ Ï∂ïÍµ¨ Ï†ïÎ≥¥"):
            st.markdown("""
            **Î¶¨Í∑∏ ÏàúÏúÑ** üèÜ
            - "EPL ÏàúÏúÑ", "ÎùºÎ¶¨Í∞Ä ÏàúÏúÑ"
            - "Î∂ÑÎç∞Ïä§Î¶¨Í∞Ä ÏàúÏúÑ", "ÏÑ∏Î¶¨ÏóêA ÏàúÏúÑ"
            
            **ÎìùÏ†ê ÏàúÏúÑ** ‚öΩ
            - "EPL ÎìùÏ†êÏàúÏúÑ", "ÎùºÎ¶¨Í∞Ä ÎìùÏ†êÏôï"
            
            **Ï±îÌîºÏñ∏Ïä§Î¶¨Í∑∏** üèÖ
            - "Ï±îÌîºÏñ∏Ïä§Î¶¨Í∑∏ ÌÜ†ÎÑàÎ®ºÌä∏"
            """)
        
        # ÏÑ±Í≤© Í≤ÄÏÇ¨ ÏïàÎÇ¥
        with st.expander("üß† ÏÑ±Í≤© Í≤ÄÏÇ¨"):
            st.markdown("""
            **MBTI** üé≠
            - "MBTI Í≤ÄÏÇ¨", "MBTI Ïú†Ìòï"
            - "ENFP ÏÑ§Î™Ö", "INTJ ÌäπÏßï"
            
            **Îã§Ï§ëÏßÄÎä•** üé®
            - "Îã§Ï§ëÏßÄÎä• Í≤ÄÏÇ¨", "Îã§Ï§ëÏßÄÎä• Ïú†Ìòï"
            - "Ïñ∏Ïñ¥ÏßÄÎä• ÏÑ§Î™Ö", "ÏùåÏïÖÏßÄÎä• ÏßÅÏóÖ"
            """)
        
        # ÏÇ¨Ïö© ÌåÅ
        with st.expander("üí° ÏÇ¨Ïö© ÌåÅ"):
            st.markdown("""
            **Í≤ÄÏÉâ ÌõÑ ÌôúÏö©** üîç
            - Í≤ÄÏÉâ ÌõÑ "ÏöîÏïΩÌï¥Ï§ò"
            - "Ï≤´ Î≤àÏß∏ Í≤∞Í≥º ÏûêÏÑ∏Ìûà ÏÑ§Î™ÖÌï¥Ï§ò"
            - "3Î≤àÏß∏ ÎßÅÌÅ¨ ÏöîÏïΩÌï¥Ï§ò"
            
            **ÎåÄÌôî Ïó∞ÏÜçÏÑ±** üí¨
            - Ïù¥Ï†Ñ Í≤∞Í≥ºÏóê ÎåÄÌïú Ï∂îÍ∞Ä ÏßàÎ¨∏ Í∞ÄÎä•
            - Í≤ÄÏÉâ Í≤∞Í≥º Í∏∞Î∞ò ÏÉÅÏÑ∏ ÏÑ§Î™Ö ÏöîÏ≤≠
            
            **Ï†ïÌôïÌïú Í≤ÄÏÉâ** üéØ
            - Íµ¨Ï≤¥Ï†ÅÏù∏ ÌÇ§ÏõåÎìú ÏÇ¨Ïö©
            - ÎèÑÏãúÎ™ÖÏùÄ ÌïúÍµ≠Ïñ¥/ÏòÅÏñ¥ Î™®Îëê Í∞ÄÎä•
            """)
        
        # ÏßÄÏõê Ïñ∏Ïñ¥/ÏßÄÏó≠
        with st.expander("üåç ÏßÄÏõê Î≤îÏúÑ"):
            st.markdown("""
            **ÎÇ†Ïî® ÏßÄÏõê** üåç
            - Ï†ÑÏÑ∏Í≥Ñ Ï£ºÏöî ÎèÑÏãú
            - ÌïúÍµ≠Ïñ¥/ÏòÅÏñ¥ ÎèÑÏãúÎ™Ö Î™®Îëê ÏßÄÏõê
            
            **Ï∂ïÍµ¨ Î¶¨Í∑∏** ‚öΩ
            - EPL, ÎùºÎ¶¨Í∞Ä, Î∂ÑÎç∞Ïä§Î¶¨Í∞Ä
            - ÏÑ∏Î¶¨ÏóêA, Î¶¨Í∑∏1, Ï±îÌîºÏñ∏Ïä§Î¶¨Í∑∏
            
            **Í≤ÄÏÉâ Ïñ∏Ïñ¥** üí¨
            - ÌïúÍµ≠Ïñ¥ Ïö∞ÏÑ† ÏßÄÏõê
            - ÏòÅÏñ¥ Í≤ÄÏÉâ Í∞ÄÎä•
            """)
    
    # Í∏∞Ï°¥ Î©îÏãúÏßÄ ÌëúÏãú
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if isinstance(message["content"], dict) and "table" in message["content"]:
                st.markdown(message["content"]["header"])
                st.dataframe(message["content"]["table"])
                st.markdown(message["content"]["footer"])
            else:
                st.markdown(message["content"], unsafe_allow_html=True)

    # ÏÇ¨Ïö©Ïûê ÏûÖÎ†• Ï≤òÎ¶¨
    if user_prompt := st.chat_input("ÏßàÎ¨∏Ìï¥ Ï£ºÏÑ∏Ïöî!"):
        st.session_state.messages.append({"role": "user", "content": user_prompt})
        with st.chat_message("user"):
            st.markdown(user_prompt)

        with st.chat_message("assistant"):
            placeholder = st.empty()
            placeholder.markdown("ÎãµÎ≥ÄÏùÑ Ï§ÄÎπÑÌïòÍ≥† ÏûàÏäµÎãàÎã§... ü§î")
            
            try:
                start_time = time.time()
                
                # ÌõÑÏÜç ÏßàÎ¨∏Ïù∏ÏßÄ ÌôïÏù∏
                if is_followup_question(user_prompt) and st.session_state.current_context:
                    # ÌõÑÏÜç ÏßàÎ¨∏ÏúºÎ°ú ÌåêÎã®ÎêòÎ©¥ Í∏∞Ï°¥ Ïª®ÌÖçÏä§Ìä∏ Ïú†ÏßÄÌïòÍ≥† LLMÏóê Ï†ÑÎã¨
                    response = asyncio.run(get_conversational_response(user_prompt, st.session_state.messages))
                else:
                    # ÏÉàÎ°úÏö¥ ÏßàÎ¨∏Ïù¥Î©¥ Ïª®ÌÖçÏä§Ìä∏ Ï¥àÍ∏∞ÌôîÌïòÍ≥† ÏùºÎ∞ò Ï≤òÎ¶¨
                    if needs_search(user_prompt) is None:
                        st.session_state.current_context = None
                    response = process_query(user_prompt)
                
                end_time = time.time()
                time_taken = end_time - start_time
                
                placeholder.empty()
                
                if isinstance(response, dict) and "table" in response:
                    st.markdown(response["header"])
                    st.dataframe(response["table"])
                    st.markdown(response["footer"])
                else:
                    st.markdown(response, unsafe_allow_html=True)
                
                st.session_state.messages.append({"role": "assistant", "content": response})
                
                # ÎπÑÎèôÍ∏∞Î°ú Ï±ÑÌåÖ Í∏∞Î°ù Ï†ÄÏû•
                async_save_chat_history(
                    st.session_state.user_id,
                    st.session_state.session_id,
                    user_prompt,
                    response,
                    time_taken
                )
                
            except Exception as e:
                placeholder.empty()
                error_msg = f"ÏùëÎãµÏùÑ Ï§ÄÎπÑÌïòÎã§ Î¨∏Ï†ú: {str(e)} üòì"
                logger.error(f"ÎåÄÌôî Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {str(e)}", exc_info=True)
                st.markdown(error_msg, unsafe_allow_html=True)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})

def show_login_page():
    st.title("Î°úÍ∑∏Ïù∏ ü§ó")
    with st.form("login_form"):
        nickname = st.text_input("ÎãâÎÑ§ÏûÑ", placeholder="Ïòà: ÌõÑÏïà")
        submit_button = st.form_submit_button("ÏãúÏûëÌïòÍ∏∞ üöÄ")

        if submit_button and nickname:
            try:
                user_id, is_existing = create_or_get_user(nickname)
                st.session_state.user_id = user_id
                st.session_state.is_logged_in = True
                st.session_state.messages = [{"role": "assistant", "content": "ÏïàÎÖïÌïòÏÑ∏Ïöî! Î¨¥ÏóáÏùÑ ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî? ÎèÑÏõÄÎßêÎèÑ ÌôúÏö©Ìï¥ Î≥¥ÏÑ∏Ïöî üòä"}]
                st.session_state.session_id = str(uuid.uuid4())
                st.toast(f"ÌôòÏòÅÌï©ÎãàÎã§, {nickname}Îãò! üéâ")
                time.sleep(1)
                st.rerun()
            except Exception:
                st.toast("Î°úÍ∑∏Ïù∏ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§. Îã§Ïãú ÏãúÎèÑÌï¥Ï£ºÏÑ∏Ïöî.", icon="‚ùå")

# Î©îÏù∏ Ïã§Ìñâ Î∂ÄÎ∂Ñ
def main():
    init_session_state()
    
    if not st.session_state.is_logged_in:
        show_login_page()
    else:
        show_chat_dashboard()

if __name__ == "__main__":
    main()