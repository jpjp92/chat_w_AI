# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì •
from config.imports import *
from config.env import *

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.WARNING if os.getenv("ENV") == "production" else logging.INFO)
logger = logging.getLogger("HybridChat")
logging.getLogger("streamlit").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)

# ìºì‹œ ì„¤ì •
cache = Cache("cache_directory")

class MemoryCache:
    def __init__(self):
        self.cache = {}
        self.expiry = {}
    
    def get(self, key):
        if key in self.cache and time.time() < self.expiry[key]:
            return self.cache[key]
        return cache.get(key)
    
    def setex(self, key, ttl, value):
        self.cache[key] = value
        self.expiry[key] = time.time() + ttl
        cache.set(key, value, expire=ttl)

cache_handler = MemoryCache()

# WeatherAPI í´ë˜ìŠ¤
class WeatherAPI:
    def __init__(self, cache_ttl=600):
        self.cache = cache_handler
        self.cache_ttl = cache_ttl

    def fetch_weather(self, url, params):
        session = requests.Session()
        retry_strategy = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("https://", adapter)
        try:
            response = session.get(url, params=params, timeout=3)
            response.raise_for_status()
            return response.json()
        except:
            return self.cache.get(f"weather:{params.get('q', '')}") or "ë‚ ì”¨ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    @lru_cache(maxsize=100)
    def get_city_info(self, city_name):
        cache_key = f"city_info:{city_name}"
        cached = self.cache.get(cache_key)
        if cached:
            return cached
        url = "http://api.openweathermap.org/geo/1.0/direct"
        params = {'q': city_name, 'limit': 1, 'appid': WEATHER_API_KEY}
        data = self.fetch_weather(url, params)
        if data and isinstance(data, list) and len(data) > 0:
            city_info = {"name": data[0]["name"], "lat": data[0]["lat"], "lon": data[0]["lon"]}
            self.cache.setex(cache_key, 86400, city_info)
            return city_info
        return None

    def get_city_weather(self, city_name):
        cache_key = f"weather:{city_name}"
        cached_data = self.cache.get(cache_key)
        if cached_data:
            return cached_data
        
        city_info = self.get_city_info(city_name)
        if not city_info:
            return f"'{city_name}'ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        url = "https://api.openweathermap.org/data/2.5/weather"
        params = {'lat': city_info["lat"], 'lon': city_info["lon"], 'appid': WEATHER_API_KEY, 'units': 'metric', 'lang': 'kr'}
        data = self.fetch_weather(url, params)
        if isinstance(data, str):
            return data
        weather_emojis = {'Clear': 'â˜€ï¸', 'Clouds': 'â˜ï¸', 'Rain': 'ğŸŒ§ï¸', 'Snow': 'â„ï¸', 'Thunderstorm': 'â›ˆï¸', 'Drizzle': 'ğŸŒ¦ï¸', 'Mist': 'ğŸŒ«ï¸'}
        weather_emoji = weather_emojis.get(data['weather'][0]['main'], 'ğŸŒ¤ï¸')
        result = (
            f"í˜„ì¬ {data['name']}, {data['sys']['country']} ë‚ ì”¨ {weather_emoji}\n"
            f"ë‚ ì”¨: {data['weather'][0]['description']}\n"
            f"ì˜¨ë„: {data['main']['temp']}Â°C\n"
            f"ì²´ê°: {data['main']['feels_like']}Â°C\n"
            f"ìŠµë„: {data['main']['humidity']}%\n"
            f"í’ì†: {data['wind']['speed']}m/s\n"
            f"ë” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”? ğŸ˜Š"
        )
        self.cache.setex(cache_key, self.cache_ttl, result)
        return result

    def get_forecast_by_day(self, city_name, days_from_today=1):
        cache_key = f"forecast:{city_name}:{days_from_today}"
        cached_data = self.cache.get(cache_key)
        if cached_data:
            return cached_data
        
        city_info = self.get_city_info(city_name)
        if not city_info:
            return f"'{city_name}'ì˜ ë‚ ì”¨ ì˜ˆë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        url = "https://api.openweathermap.org/data/2.5/forecast"
        params = {'lat': city_info["lat"], 'lon': city_info["lon"], 'appid': WEATHER_API_KEY, 'units': 'metric', 'lang': 'kr'}
        data = self.fetch_weather(url, params)
        if isinstance(data, str):
            return data
        target_date = (datetime.now() + timedelta(days=days_from_today)).strftime('%Y-%m-%d')
        forecast_text = f"{city_info['name']}ì˜ {target_date} ë‚ ì”¨ ì˜ˆë³´ ğŸŒ¤ï¸\n\n"
        weather_emojis = {'Clear': 'â˜€ï¸', 'Clouds': 'â˜ï¸', 'Rain': 'ğŸŒ§ï¸', 'Snow': 'â„ï¸', 'Thunderstorm': 'â›ˆï¸', 'Drizzle': 'ğŸŒ¦ï¸', 'Mist': 'ğŸŒ«ï¸'}
        
        found = False
        for forecast in data['list']:
            dt = datetime.fromtimestamp(forecast['dt']).strftime('%Y-%m-%d')
            if dt == target_date:
                found = True
                time_only = datetime.fromtimestamp(forecast['dt']).strftime('%H:%M')
                weather_emoji = weather_emojis.get(forecast['weather'][0]['main'], 'ğŸŒ¤ï¸')
                forecast_text += (
                    f"â° {time_only} {forecast['weather'][0]['description']} {weather_emoji} "
                    f"{forecast['main']['temp']}Â°C ğŸ’§{forecast['main']['humidity']}% ğŸŒ¬ï¸{forecast['wind']['speed']}m/s\n\n"
                )
        
        result = forecast_text + "ë” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”? ğŸ˜Š" if found else f"'{city_name}'ì˜ {target_date} ë‚ ì”¨ ì˜ˆë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        self.cache.setex(cache_key, self.cache_ttl, result)
        return result

    def get_weekly_forecast(self, city_name):
        cache_key = f"weekly_forecast:{city_name}"
        cached_data = self.cache.get(cache_key)
        if cached_data:
            return cached_data
        
        city_info = self.get_city_info(city_name)
        if not city_info:
            return f"'{city_name}'ì˜ ì£¼ê°„ ì˜ˆë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        url = "https://api.openweathermap.org/data/2.5/forecast"
        params = {'lat': city_info["lat"], 'lon': city_info["lon"], 'appid': WEATHER_API_KEY, 'units': 'metric', 'lang': 'kr'}
        data = self.fetch_weather(url, params)
        if isinstance(data, str):
            return data
        today = datetime.now().date()
        week_end = today + timedelta(days=6)
        daily_forecast = {}
        weekdays_kr = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
        today_weekday = today.weekday()
        
        for forecast in data['list']:
            dt = datetime.fromtimestamp(forecast['dt']).date()
            if today <= dt <= week_end:
                dt_str = dt.strftime('%Y-%m-%d')
                if dt_str not in daily_forecast:
                    weekday_idx = (today_weekday + (dt - today).days) % 7
                    daily_forecast[dt_str] = {
                        'weekday': weekdays_kr[weekday_idx],
                        'temp_min': forecast['main']['temp_min'],
                        'temp_max': forecast['main']['temp_max'],
                        'weather': forecast['weather'][0]['description']
                    }
                else:
                    daily_forecast[dt_str]['temp_min'] = min(daily_forecast[dt_str]['temp_min'], forecast['main']['temp_min'])
                    daily_forecast[dt_str]['temp_max'] = max(daily_forecast[dt_str]['temp_max'], forecast['main']['temp_max'])
        
        today_str = today.strftime('%Y-%m-%d')
        today_weekday_str = weekdays_kr[today_weekday]
        forecast_text = f"{today_str}({today_weekday_str}) ê¸°ì¤€ {city_info['name']}ì˜ ì£¼ê°„ ë‚ ì”¨ ì˜ˆë³´ ğŸŒ¤ï¸\n"
        weather_emojis = {'Clear': 'â˜€ï¸', 'Clouds': 'â˜ï¸', 'Rain': 'ğŸŒ§ï¸', 'Snow': 'â„ï¸', 'Thunderstorm': 'â›ˆï¸', 'Drizzle': 'ğŸŒ¦ï¸', 'Mist': 'ğŸŒ«ï¸'}
        
        for date, info in daily_forecast.items():
            weather_emoji = weather_emojis.get(info['weather'].split()[0], 'ğŸŒ¤ï¸')
            forecast_text += (
                f"\n{info['weekday']}: {info['weather']} {weather_emoji} "
                f"ìµœì € {info['temp_min']}Â°C ìµœê³  {info['temp_max']}Â°C\n\n"
            )
        
        result = forecast_text + "\në” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”? ğŸ˜Š"
        self.cache.setex(cache_key, self.cache_ttl, result)
        return result

# FootballAPI í´ë˜ìŠ¤
class FootballAPI:
    def __init__(self, api_key, cache_ttl=600):
        self.api_key = api_key
        self.base_url = "https://api.football-data.org/v4/competitions"
        self.cache = cache_handler
        self.cache_ttl = cache_ttl

    def fetch_league_standings(self, league_code, league_name):
        cache_key = f"league_standings:{league_code}"
        cached_data = self.cache.get(cache_key)
        if cached_data is not None:
            return cached_data

        url = f"{self.base_url}/{league_code}/standings"
        headers = {'X-Auth-Token': self.api_key}
        
        try:
            time.sleep(1)  # API ìš”ì²­ ê°„ê²© ì¡°ì ˆ
            response = requests.get(url, headers=headers, timeout=3)
            response.raise_for_status()
            data = response.json()
            
            standings = data['standings'][0]['table'] if league_code not in ["CL"] else data['standings']
            if league_code in ["CL"]:  # ì±”í”¼ì–¸ìŠ¤ ë¦¬ê·¸ëŠ” ê·¸ë£¹ ìŠ¤í…Œì´ì§€ ì²˜ë¦¬
                standings_data = []
                for group in standings:
                    for team in group['table']:
                        standings_data.append({
                            'ìˆœìœ„': team['position'],
                            'ê·¸ë£¹': group['group'],
                            'íŒ€': team['team']['name'],
                            'ê²½ê¸°': team['playedGames'],
                            'ìŠ¹': team['won'],
                            'ë¬´': team['draw'],
                            'íŒ¨': team['lost'],
                            'ë“ì ': team['goalsFor'],
                            'ì‹¤ì ': team['goalsAgainst'],
                            'ë“ì‹¤ì°¨': team['goalsFor'] - team['goalsAgainst'],
                            'í¬ì¸íŠ¸': team['points']
                        })
                df = pd.DataFrame(standings_data)
            else:  # ì¼ë°˜ ë¦¬ê·¸
                df = pd.DataFrame([
                    {
                        'ìˆœìœ„': team['position'],
                        'íŒ€': team['team']['name'],
                        'ê²½ê¸°': team['playedGames'],
                        'ìŠ¹': team['won'],
                        'ë¬´': team['draw'],
                        'íŒ¨': team['lost'],
                        'ë“ì ': team['goalsFor'],
                        'ì‹¤ì ': team['goalsAgainst'],
                        'ë“ì‹¤ì°¨': team['goalsFor'] - team['goalsAgainst'],
                        'í¬ì¸íŠ¸': team['points']
                    } for team in standings
                ])
            
            result = {"league_name": league_name, "data": df}
            self.cache.setex(cache_key, self.cache_ttl, result)
            return result
        
        except requests.exceptions.RequestException as e:
            return {"league_name": league_name, "error": f"{league_name} ë¦¬ê·¸ ìˆœìœ„ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)} ğŸ˜“"}

    def fetch_league_scorers(self, league_code, league_name):
        cache_key = f"league_scorers:{league_code}"
        cached_data = self.cache.get(cache_key)
        if cached_data is not None:
            return cached_data

        url = f"{self.base_url}/{league_code}/scorers"
        headers = {'X-Auth-Token': self.api_key}
        
        try:
            time.sleep(1)  # API ìš”ì²­ ê°„ê²© ì¡°ì ˆ
            response = requests.get(url, headers=headers, timeout=3)
            response.raise_for_status()
            data = response.json()
            
            scorers = [{"ìˆœìœ„": i+1, "ì„ ìˆ˜": s['player']['name'], "íŒ€": s['team']['name'], "ë“ì ": s['goals']} 
                       for i, s in enumerate(data['scorers'][:10])]  # ìƒìœ„ 10ëª…
            df = pd.DataFrame(scorers)
            result = {"league_name": league_name, "data": df}
            self.cache.setex(cache_key, self.cache_ttl, result)
            return result
        
        except requests.exceptions.RequestException as e:
            return {"league_name": league_name, "error": f"{league_name} ë¦¬ê·¸ ë“ì ìˆœìœ„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)} ğŸ˜“"}
    

# ì´ˆê¸°í™”
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
client = Client(exclude_providers=["OpenaiChat", "Copilot", "Liaobots", "Jmuz", "PollinationsAI", "ChatGptEs"])  # ë¬¸ì œ ì œê³µì ì œì™¸
weather_api = WeatherAPI()
football_api = FootballAPI(api_key=SPORTS_API_KEY)
naver_request_count = 0
NAVER_DAILY_LIMIT = 25000
st.set_page_config(page_title="AI ì±—ë´‡", page_icon="ğŸ¤–")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def init_session_state():
    if "is_logged_in" not in st.session_state:
        st.session_state.is_logged_in = False
    if "user_id" not in st.session_state:
        st.session_state.user_id = None
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "session_id" not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())

# ë„ì‹œ ë° ì‹œê°„ ì¶”ì¶œ
CITY_PATTERNS = [
    re.compile(r'(?:ì˜¤ëŠ˜|ë‚´ì¼|ëª¨ë ˆ|ì´ë²ˆ ì£¼|ì£¼ê°„)?\s*([ê°€-í£a-zA-Z\s]{2,20}(?:ì‹œ|êµ°|city)?)ì˜?\s*ë‚ ì”¨', re.IGNORECASE),
    re.compile(r'(?:ì˜¤ëŠ˜|ë‚´ì¼|ëª¨ë ˆ|ì´ë²ˆ ì£¼|ì£¼ê°„)?\s*([ê°€-í£a-zA-Z\s]{2,20}(?:ì‹œ|êµ°|city)?)\s*ë‚ ì”¨', re.IGNORECASE),
]
def extract_city_from_query(query):
    for pattern in CITY_PATTERNS:
        match = pattern.search(query)
        if match:
            city = match.group(1).strip()
            if city not in ["ì˜¤ëŠ˜", "ë‚´ì¼", "ëª¨ë ˆ", "ì´ë²ˆ ì£¼", "ì£¼ê°„", "í˜„ì¬"]:
                return city
    return "ì„œìš¸"

TIME_CITY_PATTERNS = [
    re.compile(r'([ê°€-í£a-zA-Z]{2,20}(?:ì‹œ|êµ°)?)ì˜?\s*ì‹œê°„'),
    re.compile(r'([ê°€-í£a-zA-Z]{2,20}(?:ì‹œ|êµ°)?)\s*ì‹œê°„'),
]
def extract_city_from_time_query(query):
    for pattern in TIME_CITY_PATTERNS:
        match = pattern.search(query)
        if match:
            city = match.group(1).strip()
            if city != "í˜„ì¬":
                return city
    return "ì„œìš¸"

LEAGUE_MAPPING = {
    "epl": {"name": "í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ (ì˜êµ­)", "code": "PL"},
    "laliga": {"name": "ë¼ë¦¬ê°€ (ìŠ¤í˜ì¸)", "code": "PD"},
    "bundesliga": {"name": "ë¶„ë°ìŠ¤ë¦¬ê°€ (ë…ì¼)", "code": "BL1"},
    "seriea": {"name": "ì„¸ë¦¬ì— A (ì´íƒˆë¦¬ì•„)", "code": "SA"},
    "ligue1": {"name": "ë¦¬ê·¸ 1 (í”„ë‘ìŠ¤)", "code": "FL1"},
    "championsleague": {"name": "ì±”í”¼ì–¸ìŠ¤ ë¦¬ê·¸", "code": "CL"}
}

# ë¦¬ê·¸ ì¶”ì¶œ í•¨ìˆ˜ ìˆ˜ì • (ë„ì–´ì“°ê¸° ìœ ì—°ì„± ê°œì„ )
def extract_league_from_query(query):
    query_lower = query.lower().replace(" ", "")  # ê³µë°± ì œê±°
    league_keywords = {
        "epl": ["epl", "í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸"],
        "laliga": ["laliga", "ë¼ë¦¬ê°€"],
        "bundesliga": ["bundesliga", "ë¶„ë°ìŠ¤ë¦¬ê°€"],
        "seriea": ["seriea", "ì„¸ë¦¬ì—a"],
        "ligue1": ["ligue1", "ë¦¬ê·¸1"],
        "championsleague": ["championsleague", "ì±”í”¼ì–¸ìŠ¤ë¦¬ê·¸", "ucl"]
    }
    for league_key, keywords in league_keywords.items():
        if any(keyword in query_lower for keyword in keywords):
            return league_key
    return None

# KST ì‹œê°„ ë°˜í™˜ í•¨ìˆ˜ ì¶”ê°€
def get_kst_time():
    kst_timezone = pytz.timezone("Asia/Seoul")
    kst_time = datetime.now(kst_timezone)
    return f"ëŒ€í•œë¯¼êµ­ ê¸°ì¤€ : {kst_time.strftime('%Yë…„ %mì›” %dì¼ %p %I:%M')}ì…ë‹ˆë‹¤. â°\n\n ë” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”? ğŸ˜Š"

# ì‹œê°„ ì •ë³´
def get_time_by_city(city_name="ì„œìš¸"):
    city_info = weather_api.get_city_info(city_name)
    if not city_info:
        return f"'{city_name}'ì˜ ì‹œê°„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    tf = TimezoneFinder()
    timezone_str = tf.timezone_at(lng=city_info["lon"], lat=city_info["lat"]) or "Asia/Seoul"
    timezone = pytz.timezone(timezone_str)
    city_time = datetime.now(timezone)
    return f"í˜„ì¬ {city_name} ì‹œê°„: {city_time.strftime('%Yë…„ %mì›” %dì¼ %p %I:%M')}ì…ë‹ˆë‹¤. â°\n\n ë” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”? ğŸ˜Š"

# ì‚¬ìš©ì ë° ì±„íŒ… ê¸°ë¡ ê´€ë¦¬
def create_or_get_user(nickname):
    user = supabase.table("users").select("*").eq("nickname", nickname).execute()
    if user.data:
        return user.data[0]["id"], True
    new_user = supabase.table("users").insert({"nickname": nickname, "created_at": datetime.now().isoformat()}).execute()
    return new_user.data[0]["id"], False

def save_chat_history(user_id, session_id, question, answer, time_taken):
    if isinstance(answer, dict) and "table" in answer and isinstance(answer["table"], pd.DataFrame):
        answer_to_save = {
            "header": answer["header"],
            "table": answer["table"].to_dict(orient="records"),  # DataFrame ì§ë ¬í™”
            "footer": answer["footer"]
        }
    else:
        answer_to_save = answer
    
    supabase.table("chat_history").insert({
        "user_id": user_id,
        "session_id": session_id,
        "question": question,
        "answer": answer_to_save,
        "time_taken": time_taken,
        "created_at": datetime.now().isoformat()
    }).execute()

def async_save_chat_history(user_id, session_id, question, answer, time_taken):
    threading.Thread(target=save_chat_history, args=(user_id, session_id, question, answer, time_taken)).start()

# ì˜ì•½í’ˆ ê²€ìƒ‰
def get_drug_info(drug_query):
    drug_name = drug_query.replace("ì•½í’ˆê²€ìƒ‰", "").strip()
    cache_key = f"drug:{drug_name}"
    cached = cache_handler.get(cache_key)
    if cached:
        return cached
    
    url = 'http://apis.data.go.kr/1471000/DrbEasyDrugInfoService/getDrbEasyDrugList'
    params = {'serviceKey': DRUG_API_KEY, 'pageNo': '1', 'numOfRows': '1', 'itemName': urllib.parse.quote(drug_name), 'type': 'json'}
    try:
        response = requests.get(url, params=params, timeout=3)
        response.raise_for_status()
        data = response.json()
        if 'body' in data and 'items' in data['body'] and data['body']['items']:
            item = data['body']['items'][0]
            efcy = item.get('efcyQesitm', 'ì •ë³´ ì—†ìŒ')[:150] + ("..." if len(item.get('efcyQesitm', '')) > 150 else "")
            use_method = item.get('useMethodQesitm', 'ì •ë³´ ì—†ìŒ')[:150] + ("..." if len(item.get('useMethodQesitm', '')) > 150 else "")
            atpn = item.get('atpnQesitm', 'ì •ë³´ ì—†ìŒ')[:150] + ("..." if len(item.get('atpnQesitm', '')) > 150 else "")
            
            result = (
                f"ğŸ’Š **ì˜ì•½í’ˆ ì •ë³´** ğŸ’Š\n\n"
                f"âœ… **ì•½í’ˆëª…**: {item.get('itemName', 'ì •ë³´ ì—†ìŒ')}\n\n"
                f"âœ… **ì œì¡°ì‚¬**: {item.get('entpName', 'ì •ë³´ ì—†ìŒ')}\n\n"
                f"âœ… **íš¨ëŠ¥**: {efcy}\n\n"
                f"âœ… **ìš©ë²•ìš©ëŸ‰**: {use_method}\n\n"
                f"âœ… **ì£¼ì˜ì‚¬í•­**: {atpn}\n\n"
                f"ë” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”? ğŸ˜Š"
            )
            cache_handler.setex(cache_key, 86400, result)
            return result
        return f"'{drug_name}'ì˜ ê³µì‹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        logger.error(f"ì•½í’ˆ API ì˜¤ë¥˜: {str(e)}")
        return f"'{drug_name}'ì˜ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ğŸ˜“"

# Naver API ê²€ìƒ‰ (ì›¹ ê²€ìƒ‰)
def get_naver_api_results(query):
    global naver_request_count
    cache_key = f"naver:{query}"
    cached = cache_handler.get(cache_key)
    if cached:
        return cached
    
    if naver_request_count >= NAVER_DAILY_LIMIT:
        return "ê²€ìƒ‰ í•œë„ ì´ˆê³¼ë¡œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ˜“"
    enc_text = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/webkr?query={enc_text}&display=5&sort=date"
    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
    request.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
    try:
        response = urllib.request.urlopen(request, timeout=3)
        naver_request_count += 1
        if response.getcode() == 200:
            data = json.loads(response.read().decode('utf-8'))
            results = data.get('items', [])
            if not results:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ğŸ˜“"
            
            response_text = "ğŸŒ **ì›¹ ê²€ìƒ‰ ê²°ê³¼** ğŸŒ\n\n"
            response_text += "\n\n".join(
                [f"**ê²°ê³¼ {i}**\n\nğŸ“„ **ì œëª©**: {re.sub(r'<b>|</b>', '', item['title'])}\n\nğŸ“ **ë‚´ìš©**: {re.sub(r'<b>|</b>', '', item.get('description', 'ë‚´ìš© ì—†ìŒ'))[:100]}...\n\nğŸ”— **ë§í¬**: {item.get('link', '')}"
                 for i, item in enumerate(results, 1)]
            ) + "\n\në” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”? ğŸ˜Š"
            cache_handler.setex(cache_key, 3600, response_text)
            return response_text
    except Exception as e:
        logger.error(f"Naver API ì˜¤ë¥˜: {str(e)}")
        return "ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ğŸ˜“"

# ArXiv ë…¼ë¬¸ ê²€ìƒ‰
def fetch_arxiv_paper(paper):
    return {
        "title": paper.title,
        "authors": ", ".join(str(a) for a in paper.authors),
        "summary": paper.summary[:200],
        "entry_id": paper.entry_id,
        "pdf_url": paper.pdf_url,
        "published": paper.published.strftime('%Y-%m-%d')
    }

def get_arxiv_papers(query, max_results=3):
    cache_key = f"arxiv:{query}:{max_results}"
    cached = cache_handler.get(cache_key)
    if cached:
        return cached
    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.SubmittedDate)
    with ThreadPoolExecutor() as executor:
        results = list(executor.map(fetch_arxiv_paper, search.results()))
    if not results:
        return "í•´ë‹¹ í‚¤ì›Œë“œë¡œ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    response = "ğŸ“š **Arxiv ë…¼ë¬¸ ê²€ìƒ‰ ê²°ê³¼** ğŸ“š\n\n"
    response += "\n\n".join(
        [f"**ë…¼ë¬¸ {i}**\n\nğŸ“„ **ì œëª©**: {r['title']}\n\nğŸ‘¥ **ì €ì**: {r['authors']}\n\nğŸ“ **ì´ˆë¡**: {r['summary']}...\n\nğŸ”— **ë…¼ë¬¸ í˜ì´ì§€**: {r['entry_id']}\n\nğŸ“… **ì¶œíŒì¼**: {r['published']}"
         for i, r in enumerate(results, 1)]
    ) + "\n\në” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”? ğŸ˜Š"
    cache_handler.setex(cache_key, 3600, response)
    return response

# PubMed ë…¼ë¬¸ ê²€ìƒ‰
base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"

def search_pubmed(query, max_results=5):
    search_url = f"{base_url}esearch.fcgi"
    params = {"db": "pubmed", "term": query, "retmode": "json", "retmax": max_results, "api_key": NCBI_KEY}
    response = requests.get(search_url, params=params, timeout=3)
    return response.json()

def get_pubmed_summaries(id_list):
    summary_url = f"{base_url}esummary.fcgi"
    params = {"db": "pubmed", "id": ",".join(id_list), "retmode": "json", "api_key": NCBI_KEY}
    response = requests.get(summary_url, params=params, timeout=3)
    return response.json()

def get_pubmed_abstract(id_list):
    fetch_url = f"{base_url}efetch.fcgi"
    params = {"db": "pubmed", "id": ",".join(id_list), "retmode": "xml", "rettype": "abstract", "api_key": NCBI_KEY}
    response = requests.get(fetch_url, params=params, timeout=3)
    return response.text

def extract_first_two_sentences(abstract_text):
    if not abstract_text or abstract_text.isspace():
        return "No abstract available"
    sentences = [s.strip() for s in abstract_text.split('.') if s.strip()]
    return " ".join(sentences[:2]) + "." if sentences else "No abstract available"

def parse_abstracts(xml_text):
    abstract_dict = {}
    try:
        root = ET.fromstring(xml_text)
        for article in root.findall(".//PubmedArticle"):
            pmid = article.find(".//MedlineCitation/PMID").text
            abstract_elem = article.find(".//Abstract/AbstractText")
            abstract = abstract_elem.text if abstract_elem is not None else "No abstract available"
            abstract_dict[pmid] = extract_first_two_sentences(abstract)
    except ET.ParseError:
        return {}
    return abstract_dict

def get_pubmed_papers(query, max_results=5):
    cache_key = f"pubmed:{query}:{max_results}"
    cached = cache_handler.get(cache_key)
    if cached:
        return cached
    
    search_results = search_pubmed(query, max_results)
    pubmed_ids = search_results["esearchresult"]["idlist"]
    if not pubmed_ids:
        return "í•´ë‹¹ í‚¤ì›Œë“œë¡œ ì˜í•™ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    summaries = get_pubmed_summaries(pubmed_ids)
    abstracts_xml = get_pubmed_abstract(pubmed_ids)
    abstract_dict = parse_abstracts(abstracts_xml)
    
    response = "ğŸ“š **PubMed ë…¼ë¬¸ ê²€ìƒ‰ ê²°ê³¼** ğŸ“š\n\n"
    response += "\n\n".join(
        [f"**ë…¼ë¬¸ {i}**\n\nğŸ†” **PMID**: {pmid}\n\nğŸ“– **ì œëª©**: {summaries['result'][pmid].get('title', 'No title')}\n\nğŸ“… **ì¶œíŒì¼**: {summaries['result'][pmid].get('pubdate', 'No date')}\n\nâœï¸ **ì €ì**: {', '.join([author.get('name', '') for author in summaries['result'][pmid].get('authors', [])])}\n\nğŸ“ **ì´ˆë¡**: {abstract_dict.get(pmid, 'No abstract')}"
         for i, pmid in enumerate(pubmed_ids, 1)]
    ) + "\n\në” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”? ğŸ˜Š"
    cache_handler.setex(cache_key, 3600, response)
    return response

# ëŒ€í™”í˜• ì‘ë‹µ (ë¹„ë™ê¸°)
conversation_cache = MemoryCache()
async def get_conversational_response(query, chat_history):
    cache_key = f"conv:{needs_search(query)}:{query}"
    cached = conversation_cache.get(cache_key)
    if cached:
        return cached
    
    messages = [
        {"role": "system", "content": "ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤. ì ì ˆí•œ ì´ëª¨ì§€ ì‚¬ìš©: âœ…(ì™„ë£Œ), â“(ì§ˆë¬¸), ğŸ˜Š(ì¹œì ˆ)"},
        {"role": "user", "content": query}
    ] + [{"role": msg["role"], "content": msg["content"]} 
         for msg in chat_history[-2:] if "ë” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”?" not in msg["content"]]
    
    loop = asyncio.get_event_loop()
    try:
        response = await loop.run_in_executor(None, lambda: client.chat.completions.create(
            model="gpt-4o", messages=messages))
        result = response.choices[0].message.content if response.choices else "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except (IndexError, Exception) as e:  # IndexError ë° ê¸°íƒ€ ì˜ˆì™¸ ì²˜ë¦¬
        logger.error(f"ëŒ€í™” ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        result = "ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    conversation_cache.setex(cache_key, 600, result)
    return result

# GREETING_RESPONSES ê°œì„ 
GREETINGS = ["ì•ˆë…•", "í•˜ì´", "í—¬ë¡œ", "ã…ã…‡", "ì™“ì—…", "í• ë¡±", "í—¤ì´"]
GREETING_RESPONSE = "ì•ˆë…•í•˜ì„¸ìš”! ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š"

# ì¿¼ë¦¬ ë¶„ë¥˜
@lru_cache(maxsize=100)
def needs_search(query):
    query_lower = query.strip().lower().replace(" ", "")  # ê³µë°± ì œê±°ë¡œ ìœ ì—°ì„± í™•ë³´
    if "ë‚ ì”¨" in query_lower:
        return "weather" if "ë‚´ì¼" not in query_lower else "tomorrow_weather"
    if "ì‹œê°„" in query_lower or "ë‚ ì§œ" in query_lower:
        return "time"
    if "ë¦¬ê·¸ìˆœìœ„" in query_lower:
        return "league_standings"
    if "ë¦¬ê·¸ë“ì ìˆœìœ„" in query_lower or "ë“ì ìˆœìœ„" in query_lower:  # ë„ì–´ì“°ê¸° ì—†ì´ë„ ì¸ì‹
        return "league_scorers"
    if "ì•½í’ˆê²€ìƒ‰" in query_lower:
        return "drug"
    if "ê³µí•™ë…¼ë¬¸" in query_lower or "arxiv" in query_lower:
        return "arxiv_search"
    if "ì˜í•™ë…¼ë¬¸" in query_lower:
        return "pubmed_search"
    if "ê²€ìƒ‰" in query_lower:
        return "naver_search"
    if any(greeting in query_lower for greeting in GREETINGS):
        return "conversation"
    return "conversation"

# ì¿¼ë¦¬ ì²˜ë¦¬ (ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”)
def process_query(query):
    cache_key = f"query:{hash(query)}"
    cached = cache_handler.get(cache_key)
    if cached is not None:
        return cached
    
    query_type = needs_search(query)
    query_lower = query.strip().lower()
    query_no_space = query_lower.replace(" ", "")  # ë„ì–´ì“°ê¸° ì œê±° ì¶”ê°€
    
    with ThreadPoolExecutor() as executor:
        if query_type == "weather":
            future = executor.submit(weather_api.get_city_weather, extract_city_from_query(query))
            result = future.result()
        elif query_type == "tomorrow_weather":
            future = executor.submit(weather_api.get_forecast_by_day, extract_city_from_query(query), 1)
            result = future.result()
        elif query_type == "time":
            # ë„ì–´ì“°ê¸° ì œê±°ëœ ì¿¼ë¦¬ë¡œ í‚¤ì›Œë“œ ê²€ìƒ‰
            if "ì˜¤ëŠ˜ë‚ ì§œ" in query_no_space or "í˜„ì¬ë‚ ì§œ" in query_no_space or "ê¸ˆì¼ë‚ ì§œ" in query_no_space:
                result = get_kst_time()
            else:
                city = extract_city_from_time_query(query)
                future = executor.submit(get_time_by_city, city)
                result = future.result()
        elif query_type == "league_standings":
            league_key = extract_league_from_query(query)
            if league_key:
                league_info = LEAGUE_MAPPING[league_key]
                future = executor.submit(football_api.fetch_league_standings, league_info["code"], league_info["name"])
                result = future.result()
                result = result["error"] if "error" in result else {
                    "header": f"{result['league_name']} ë¦¬ê·¸ ìˆœìœ„",
                    "table": result["data"],
                    "footer": "ë” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”? ğŸ˜Š"
                }
            else:
                result = "ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¦¬ê·¸ì…ë‹ˆë‹¤. ğŸ˜“ ì§€ì› ë¦¬ê·¸: EPL, LaLiga, Bundesliga, Serie A, Ligue 1"
        elif query_type == "league_scorers":
            league_key = extract_league_from_query(query)
            if league_key:
                league_info = LEAGUE_MAPPING[league_key]
                future = executor.submit(football_api.fetch_league_scorers, league_info["code"], league_info["name"])
                try:
                    result = future.result()
                    result = result["error"] if "error" in result else {
                        "header": f"{result['league_name']} ë¦¬ê·¸ ë“ì ìˆœìœ„ (ìƒìœ„ 10ëª…)",
                        "table": result["data"],
                        "footer": "ë” ê¶ê¸ˆí•œ ì  ìˆë‚˜ìš”? ğŸ˜Š"
                    }
                except Exception as e:
                    result = f"ë¦¬ê·¸ ë“ì ìˆœìœ„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)} ğŸ˜“"
            else:
                result = "ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¦¬ê·¸ì…ë‹ˆë‹¤. ğŸ˜“ ì§€ì› ë¦¬ê·¸: EPL, LaLiga, Bundesliga, Serie A, Ligue 1"
        elif query_type == "drug":
            future = executor.submit(get_drug_info, query)
            result = future.result()
        elif query_type == "arxiv_search":
            keywords = query.replace("ê³µí•™ë…¼ë¬¸", "").replace("arxiv", "").strip()
            future = executor.submit(get_arxiv_papers, keywords)
            result = future.result()
        elif query_type == "pubmed_search":
            keywords = query.replace("ì˜í•™ë…¼ë¬¸", "").strip()
            future = executor.submit(get_pubmed_papers, keywords)
            result = future.result()
        elif query_type == "naver_search":
            search_query = query_lower.replace("ê²€ìƒ‰", "").strip()
            future = executor.submit(get_naver_api_results, search_query)
            result = future.result()
        elif query_type == "conversation":
            if query_lower in GREETINGS:
                result = GREETING_RESPONSE
            # ë„ì–´ì“°ê¸° ì œê±°ëœ ì¿¼ë¦¬ë¡œ í‚¤ì›Œë“œ ê²€ìƒ‰
            elif "ì˜¤ëŠ˜ë‚ ì§œ" in query_no_space or "í˜„ì¬ë‚ ì§œ" in query_no_space or "ê¸ˆì¼ë‚ ì§œ" in query_no_space:
                result = get_kst_time()
            else:
                result = asyncio.run(get_conversational_response(query, st.session_state.chat_history))
        else:
            result = "ì•„ì§ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê¸°ëŠ¥ì´ì—ìš”. ğŸ˜…"
        
        cache_handler.setex(cache_key, 600, result)
        return result

# UI í•¨ìˆ˜ (ë„ì›€ë§ ì—…ë°ì´íŠ¸)
def show_chat_dashboard():
    st.title("AI ì±—ë´‡ ğŸ¤–")
    
    if st.button("ë„ì›€ë§ â„¹ï¸"):
        st.info(
            "ì±—ë´‡ê³¼ ë” ì‰½ê²Œ ëŒ€í™” í•˜ëŠ” ë°©ë²•ì´ì—ìš”! ğŸ‘‡:\n"
            "1. **ë‚ ì”¨** â˜€ï¸: '[ë„ì‹œëª…] ë‚ ì”¨' (ì˜ˆ: ì„œìš¸ ë‚ ì”¨)\n"
            "2. **ì‹œê°„/ë‚ ì§œ** â±ï¸: '[ë„ì‹œëª…] ì‹œê°„' ë˜ëŠ” 'ì˜¤ëŠ˜ ë‚ ì§œ' (ì˜ˆ: ë¶€ì‚° ì‹œê°„, ê¸ˆì¼ ë‚ ì§œ)\n"
            "3. **ë¦¬ê·¸ìˆœìœ„** âš½: '[ë¦¬ê·¸ ì´ë¦„] ë¦¬ê·¸ ìˆœìœ„ ë˜ëŠ” ë¦¬ê·¸ë“ì ìˆœìœ„'(ì˜ˆ: EPL ë¦¬ê·¸ìˆœìœ„, EPL ë¦¬ê·¸ë“ì ìˆœìœ„)\n"
            "   - ì§€ì› ë¦¬ê·¸: EPL, LaLiga, Bundesliga, Serie A, Ligue 1, ChampionsLeague\n"
            "4. **ì•½í’ˆê²€ìƒ‰** ğŸ’Š: 'ì•½í’ˆê²€ìƒ‰ [ì•½ ì´ë¦„]' (ì˜ˆ: ì•½í’ˆê²€ìƒ‰ ê²Œë³´ë¦°)\n"
            "5. **ê³µí•™ë…¼ë¬¸** ğŸ“š: 'ê³µí•™ë…¼ë¬¸ [í‚¤ì›Œë“œ]' (ì˜ˆ: ê³µí•™ë…¼ë¬¸ Multimodal AI)\n"
            "6. **ì˜í•™ë…¼ë¬¸** ğŸ©º: 'ì˜í•™ë…¼ë¬¸ [í‚¤ì›Œë“œ]' (ì˜ˆ: ì˜í•™ë…¼ë¬¸ cancer therapy)\n"
            "7. **ê²€ìƒ‰** ğŸŒ: 'ê²€ìƒ‰ í‚¤ì›Œë“œ' (ì˜ˆ: ê²€ìƒ‰ ìµœê·¼ ì „ì‹œíšŒ ì¶”ì²œ)\n\n"
            "ê¶ê¸ˆí•œ ì  ìˆìœ¼ë©´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”! ğŸ˜Š"
        )
    
    for msg in st.session_state.chat_history[-10:]:
        with st.chat_message(msg['role']):
            if isinstance(msg['content'], dict) and "table" in msg['content']:
                st.markdown(f"### {msg['content']['header']}")
                st.dataframe(pd.DataFrame(msg['content']['table']), use_container_width=True, hide_index=True)
                st.markdown(msg['content']['footer'])
            else:
                st.markdown(msg['content'], unsafe_allow_html=True)
    
    if user_prompt := st.chat_input("ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!"):
        st.chat_message("user").markdown(user_prompt)
        st.session_state.chat_history.append({"role": "user", "content": user_prompt})
        with st.chat_message("assistant"):
            placeholder = st.empty()
            placeholder.markdown("ì‘ë‹µì„ ì¤€ë¹„ ì¤‘ì´ì—ìš”.. â³")
            try:
                start_time = time.time()
                response = process_query(user_prompt)
                time_taken = round(time.time() - start_time, 2)
                
                placeholder.empty()
                if isinstance(response, dict) and "table" in response:
                    st.markdown(f"### {response['header']}")
                    st.dataframe(response['table'], use_container_width=True, hide_index=True)
                    st.markdown(response['footer'])
                else:
                    st.markdown(response, unsafe_allow_html=True)
                
                st.session_state.chat_history.append({"role": "assistant", "content": response})
                async_save_chat_history(st.session_state.user_id, st.session_state.session_id, user_prompt, response, time_taken)
            
            except Exception as e:
                placeholder.empty()
                error_msg = f"ì‘ë‹µì„ ì¤€ë¹„í•˜ë‹¤ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”: {str(e)} ğŸ˜“"
                logger.error(f"ëŒ€í™” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
                st.markdown(error_msg, unsafe_allow_html=True)
                st.session_state.chat_history.append({"role": "assistant", "content": error_msg})

def show_login_page():
    st.title("ë¡œê·¸ì¸ ğŸ¤—")
    with st.form("login_form"):
        nickname = st.text_input("ë‹‰ë„¤ì„", placeholder="ì˜ˆ: í›„ì•ˆ")
        submit_button = st.form_submit_button("ì‹œì‘í•˜ê¸° ğŸš€")
        
        if submit_button and nickname:
            try:
                user_id, is_existing = create_or_get_user(nickname)
                st.session_state.user_id = user_id
                st.session_state.is_logged_in = True
                st.session_state.chat_history = []
                st.session_state.session_id = str(uuid.uuid4())
                st.toast(f"í™˜ì˜í•©ë‹ˆë‹¤, {nickname}ë‹˜! ğŸ‰")
                time.sleep(1)
                st.rerun()
            except Exception:
                st.toast("ë¡œê·¸ì¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", icon="âŒ")

# ë©”ì¸ ì‹¤í–‰
def main():
    init_session_state()
    if not st.session_state.is_logged_in:
        show_login_page()
    else:
        show_chat_dashboard()

if __name__ == "__main__":
    main()
